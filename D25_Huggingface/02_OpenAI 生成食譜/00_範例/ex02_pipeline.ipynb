{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好,我是小朱,請多多指教\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 推薦使用 Whisper ，這個模型在多語言和不同口音的語音識別任務中表現更好\n",
    "transcriber = pipeline(model=\"openai/whisper-large-v2\")\n",
    "\n",
    "# 轉換\n",
    "result = transcriber(\"demo.flac\")\n",
    "# 輸出\n",
    "print(result['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "檢查緩存位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TRANSFORMERS_CACHE\n",
    "\n",
    "print(f\"緩存位置在：{TRANSFORMERS_CACHE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "輸入多個音頻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 推薦使用 Whisper ，這個模型在多語言和不同口音的語音識別任務中表現更好\n",
    "transcriber = pipeline(\n",
    "    model=\"openai/whisper-large-v2\"\n",
    ")\n",
    "\n",
    "# 轉換\n",
    "results = transcriber(\n",
    "    [\"demo.wav\", \"demo.flac\"]\n",
    ")\n",
    "# 遍歷結果並打印\n",
    "for result in results:\n",
    "    print(result['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指定使用 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 推薦使用 Whisper ，這個模型在多語言和不同口音的語音識別任務中表現更好\n",
    "transcriber = pipeline(\n",
    "    model=\"openai/whisper-large-v2\",\n",
    "    device=0\n",
    ")\n",
    "\n",
    "# 轉換\n",
    "result = transcriber(\"demo.flac\")\n",
    "# 輸出\n",
    "print(result['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自動檢測系統硬件配置，包括 CPU 和 GPU，並決定如何分配模型的不同部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 推薦使用 Whisper ，這個模型在多語言和不同口音的語音識別任務中表現更好\n",
    "transcriber = pipeline(\n",
    "    model=\"openai/whisper-large-v2\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# 轉換\n",
    "result = transcriber(\"demo.flac\")\n",
    "# 輸出\n",
    "print(result['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "設置批次大小以提高推理速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好,我是小朱,請多多指教\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 推薦使用 Whisper ，這個模型在多語言和不同口音的語音識別任務中表現更好\n",
    "transcriber = pipeline(\n",
    "    model=\"openai/whisper-large-v2\",\n",
    "    batch_size=4\n",
    ")\n",
    "\n",
    "# 轉換\n",
    "result = transcriber(\"demo.flac\")\n",
    "# 輸出\n",
    "print(result['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "處理大量數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 假設 my_data 是一個包含 1000 筆文本數據的列表\n",
    "my_data = [f\"My example {i}\" for i in range(1000)]\n",
    "\n",
    "# 創建 GPT-2 文本生成 pipeline\n",
    "pipe = pipeline(model=\"openai-community/gpt2\")\n",
    "\n",
    "# 定義數據生成器\n",
    "def data_generator(data):\n",
    "    for item in data:\n",
    "        yield item\n",
    "\n",
    "# 使用 pipeline 處理數據生成器\n",
    "generated_characters = 0\n",
    "for output in pipe(data_generator(my_data)):\n",
    "    # 假設輸出是包含生成文本的字典\n",
    "    generated_text = output['generated_text']\n",
    "    generated_characters += len(generated_text)\n",
    "\n",
    "print(f\"Total generated characters: {generated_characters}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假設是文本也是相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 假設 my_data 是一個包含 1000 筆文本數據的列表\n",
    "my_data = [f\"My example {i}\" for i in range(1000)]\n",
    "\n",
    "# 創建 GPT-2 文本生成 pipeline\n",
    "pipe = pipeline(model=\"openai-community/gpt2\")\n",
    "\n",
    "# 定義數據生成器\n",
    "def data_generator(data):\n",
    "    for item in data:\n",
    "        yield item\n",
    "\n",
    "# 使用 pipeline 處理數據生成器\n",
    "generated_characters = 0\n",
    "for output in pipe(data_generator(my_data)):\n",
    "    # 假設輸出是包含生成文本的字典\n",
    "    generated_text = output['generated_text']\n",
    "    generated_characters += len(generated_text)\n",
    "\n",
    "print(f\"Total generated characters: {generated_characters}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "圖像分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tiger, Panthera tigris, Confidence: 0.959\n",
      "Label: tiger cat, Confidence: 0.0306\n",
      "Label: jaguar, panther, Panthera onca, Felis onca, Confidence: 0.0028\n",
      "Label: leopard, Panthera pardus, Confidence: 0.0017\n",
      "Label: lion, king of beasts, Panthera leo, Confidence: 0.0011\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "vision_classifier = pipeline(\n",
    "    model=\"google/vit-base-patch16-224\"\n",
    ")\n",
    "\n",
    "results = vision_classifier(images=\"tiger.jpeg\")\n",
    "# 優化輸出格式\n",
    "formatted_results = [\n",
    "    {\"Label\": result[\"label\"], \"Confidence\": round(result[\"score\"], 4)}\n",
    "    for result in results\n",
    "]\n",
    "# 輸出結果\n",
    "for res in formatted_results:\n",
    "    print(f\"Label: {res['Label']}, Confidence: {res['Confidence']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多張相片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for tiger.jpeg:\n",
      "  Label: tiger, Panthera tigris, Confidence: 0.959\n",
      "  Label: tiger cat, Confidence: 0.0306\n",
      "  Label: jaguar, panther, Panthera onca, Felis onca, Confidence: 0.0028\n",
      "  Label: leopard, Panthera pardus, Confidence: 0.0017\n",
      "  Label: lion, king of beasts, Panthera leo, Confidence: 0.0011\n",
      "\n",
      "Results for lion.jpeg:\n",
      "  Label: lion, king of beasts, Panthera leo, Confidence: 0.758\n",
      "  Label: leopard, Panthera pardus, Confidence: 0.0372\n",
      "  Label: cougar, puma, catamount, mountain lion, painter, panther, Felis concolor, Confidence: 0.0365\n",
      "  Label: lynx, catamount, Confidence: 0.0261\n",
      "  Label: cheetah, chetah, Acinonyx jubatus, Confidence: 0.0248\n",
      "\n",
      "Results for cat.jpeg:\n",
      "  Label: Egyptian cat, Confidence: 0.669\n",
      "  Label: tabby, tabby cat, Confidence: 0.1815\n",
      "  Label: tiger cat, Confidence: 0.1011\n",
      "  Label: lynx, catamount, Confidence: 0.0097\n",
      "  Label: Persian cat, Confidence: 0.0073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 創建圖像分類的 pipeline\n",
    "vision_classifier = pipeline(model=\"google/vit-base-patch16-224\")\n",
    "\n",
    "# 處理多張圖像\n",
    "image_files = [\"tiger.jpeg\", \"lion.jpeg\", \"cat.jpeg\"]\n",
    "results = vision_classifier(images=image_files)\n",
    "\n",
    "# 優化輸出格式\n",
    "for i, image_results in enumerate(results):\n",
    "    print(f\"Results for {image_files[i]}:\")\n",
    "    formatted_results = [\n",
    "        {\"Label\": result[\"label\"], \"Confidence\": round(result[\"score\"], 4)}\n",
    "        for result in image_results\n",
    "    ]\n",
    "    for res in formatted_results:\n",
    "        print(f\"  Label: {res['Label']}, Confidence: {res['Confidence']}\")\n",
    "    # 添加一個空行以便區分不同圖片的結果\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "展示相片的腳本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vm/_zft15050r7cfh47y6v5z4k40000gn/T/ipykernel_18742/3266308836.py:26: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  image = image.resize((size, size), Image.ANTIALIAS)\n",
      "/var/folders/vm/_zft15050r7cfh47y6v5z4k40000gn/T/ipykernel_18742/3266308836.py:56: DeprecationWarning: getsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use getbbox or getlength instead.\n",
      "  draw.text((x_offset + target_size // 2 - font.getsize(name)[0] // 2, max_height + 5), name, font=font, fill=(0, 0, 0))\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# 圖片文件路徑和標註名稱\n",
    "image_files = [\n",
    "    (\"tiger.jpeg\", \"Tiger\"),\n",
    "    (\"lion.jpeg\", \"Lion\"),\n",
    "    (\"cat.jpeg\", \"Cat\")\n",
    "]\n",
    "\n",
    "# 設定統一的圖片大小\n",
    "target_size = 300\n",
    "\n",
    "# 定義函數來調整和裁剪圖片\n",
    "def resize_and_crop(image, size):\n",
    "    width, height = image.size\n",
    "    # 取最小邊作為裁剪基準\n",
    "    new_size = min(width, height)\n",
    "    left = (width - new_size) / 2\n",
    "    top = (height - new_size) / 2\n",
    "    right = (width + new_size) / 2\n",
    "    bottom = (height + new_size) / 2\n",
    "\n",
    "    # 裁剪圖片\n",
    "    image = image.crop((left, top, right, bottom))\n",
    "    # 調整圖片大小\n",
    "    image = image.resize((size, size), Image.ANTIALIAS)\n",
    "    return image\n",
    "\n",
    "# 打開所有圖片並調整大小\n",
    "images = [\n",
    "    resize_and_crop(Image.open(file), target_size)\n",
    "    for file, _ in image_files\n",
    "]\n",
    "\n",
    "# 計算總寬度和最大高度\n",
    "total_width = target_size * len(images)\n",
    "max_height = target_size\n",
    "\n",
    "# 創建一個新的空白圖像（考慮到標註文字的高度）\n",
    "combined_image = Image.new(\n",
    "    'RGB',\n",
    "    (total_width, max_height + 30),\n",
    "    (255, 255, 255)\n",
    ")\n",
    "\n",
    "# 設置字體（你可以選擇系統中的其他字體）\n",
    "font = ImageFont.load_default()\n",
    "\n",
    "# 初始化繪圖對象\n",
    "draw = ImageDraw.Draw(combined_image)\n",
    "\n",
    "# 將每張圖片貼到新圖像上\n",
    "x_offset = 0\n",
    "for img, (file, name) in zip(images, image_files):\n",
    "    combined_image.paste(img, (x_offset, 0))\n",
    "    draw.text(\n",
    "        (x_offset + target_size // 2 - font.getsize(name)[0] // 2, max_height + 5),\n",
    "        name,\n",
    "        font=font,\n",
    "        fill=(0, 0, 0)\n",
    "    )\n",
    "    x_offset += target_size\n",
    "\n",
    "# 保存最終合成的圖像\n",
    "combined_image.save('combined_image.jpeg')\n",
    "\n",
    "# 顯示合成的圖像\n",
    "combined_image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "檢查圖像並回答問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: us-001\n",
      "Confidence: 0.0035401417408138514\n",
      "start: 15\n",
      "end: 15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 確保你已經安裝了 pytesseract\n",
    "import pytesseract\n",
    "\n",
    "# 創建文件問答的 pipeline\n",
    "vqa = pipeline(model=\"impira/layoutlm-document-qa\")\n",
    "\n",
    "# 處理圖片並提出問題\n",
    "result = vqa(\n",
    "    image=\"invoice.png\",\n",
    "    question=\"請問這一張發票的號碼？\"\n",
    ")\n",
    "\n",
    "# 格式化輸出結果\n",
    "if result:\n",
    "    for answer in result:\n",
    "        text = answer.get('answer', 'N/A')\n",
    "        confidence = answer.get('score', 'N/A')\n",
    "        start = answer.get('start', 'N/A')\n",
    "        end = answer.get('end', 'N/A')\n",
    "        print(\n",
    "            f\"Answer: {text}\\nConfidence: {confidence}\\n\"\n",
    "            f\"start: {start}\\nend: {end}\\n\"\n",
    "        )\n",
    "else:\n",
    "    print(\"No answer found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "問題組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 請問 Bill To 誰？\n",
      "Answer: John Smith\n",
      "Confidence: 0.9599351286888123\n",
      "Start: 16\n",
      "End: 17\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Question: 請問 Invoice Date？\n",
      "Answer: 1102/2019\n",
      "Confidence: 0.9988793730735779\n",
      "Start: 22\n",
      "End: 22\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Question: 請問 Invoice Number？\n",
      "Answer: us-001\n",
      "Confidence: 0.9999278783798218\n",
      "Start: 15\n",
      "End: 15\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 確保你已經安裝了 pytesseract\n",
    "import pytesseract\n",
    "\n",
    "# 創建文件問答的 pipeline\n",
    "vqa = pipeline(model=\"impira/layoutlm-document-qa\")\n",
    "\n",
    "# 定義圖片和問題組\n",
    "image_path = \"invoice.png\"\n",
    "questions = [\n",
    "    \"請問 Bill To 誰？\",\n",
    "    \"請問 Invoice Date？\",\n",
    "    \"請問 Invoice Number？\"\n",
    "]\n",
    "\n",
    "# 處理每個問題並格式化輸出結果\n",
    "for question in questions:\n",
    "    result = vqa(image=image_path, question=question)\n",
    "\n",
    "    if result:\n",
    "        print(f\"Question: {question}\")\n",
    "        for answer in result:\n",
    "            text = answer.get('answer', 'N/A')\n",
    "            confidence = answer.get('score', 'N/A')\n",
    "            start = answer.get('start', 'N/A')\n",
    "            end = answer.get('end', 'N/A')\n",
    "            print(\n",
    "                f\"Answer: {text}\\nConfidence: {confidence}\\n\"\n",
    "                f\"Start: {start}\\nEnd: {end}\\n\"\n",
    "            )\n",
    "    else:\n",
    "        print(f\"No answer found for question: {question}\")\n",
    "    # 分隔不同問題的結果\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自然語言處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分類結果：\n",
      "Label: urgent, Score: 0.6274\n",
      "Label: phone, Score: 0.365\n",
      "Label: computer, Score: 0.0037\n",
      "Label: not urgent, Score: 0.0027\n",
      "Label: tablet, Score: 0.0012\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    model=\"facebook/bart-large-mnli\"\n",
    ")\n",
    "result = classifier(\n",
    "    \"I have a problem with my iPhone and need it fixed ASAP!\",\n",
    "    candidate_labels=[\n",
    "        \"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"\n",
    "    ]\n",
    ")\n",
    "# 格式化輸出結果\n",
    "# 檢查結果格式是否為字典，然後提取每個標籤及其對應的分數\n",
    "if isinstance(result, dict):\n",
    "    formatted_results = sorted(\n",
    "        [\n",
    "            # 根據分數對結果進行排序並四捨五入，以便顯示最相關的標籤\n",
    "            {\"label\": label, \"score\": round(score, 4)}\n",
    "            for label, score in zip(result[\"labels\"], result[\"scores\"])\n",
    "        ],\n",
    "        key=lambda x: x[\"score\"],\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    # 打印格式化的結果\n",
    "    print(\"分類結果：\")\n",
    "    for res in formatted_results:\n",
    "        print(f\"Label: {res['label']}, Score: {res['score']}\")\n",
    "else:\n",
    "    print(\"Unexpected result format:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 Gradio 上創建 Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"image-classification\",\n",
    "    model=\"google/vit-base-patch16-224\"\n",
    ")\n",
    "gr.Interface.from_pipeline(pipe).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envllmChatBot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
