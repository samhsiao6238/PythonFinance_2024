# LLaMA 

[官網](https://llama.meta.com/)

<br>

## 簡介

1. LLaMA (Large Language Model Meta AI) 是 Meta 開發的一系列大型語言模型（Large Language Models, LLMs），這些模型旨在執行各種自然語言處理（NLP）任務，如文本生成、翻譯、摘要、問題回答等。

<br>

2. LLaMA 模型是基於 Transformer 架構的語言模型，所謂的 Transformer 架構是一種用於自然語言處理任務的神經網絡模型架構，由 Vaswani 等人在 2017 年的論文《Attention is All You Need》中提出；Transformer 引入名為 `自注意力機制（Self-Attention Mechanism）` 的創新方法，改變 NLP 領域的模型設計方式。

<br>

3. LLaMA 模型相當大，需要相當的 GPU 記憶體和計算能力，建議使用高性能 GPU 設備來運行這些模型，LLaMA 的不同版本有不同的參數數量，越大的模型通常效果更好，但同時需要更多的資源來運行。

<br>

## LLaMA 的主要特點

1. 大規模參數：擁有數十億個參數，可以捕捉語言中的複雜模式。

<br>

2. 開源性：Meta 將 LLaMA 作為開源模型提供給研究人員和開發者，使其能夠在不同的應用場景中進行測試和優化。

<br>

3. 多功能性：能夠處理從文本分類到生成任務的各種 NLP 任務。

<br>

## 應用

_以下使用 Python 和 PyTorch 庫來應用 LLaMA 模型進行文本生成。_

<br>

1. 安裝所需的 Python 庫：PyTorch 和 Transformers。

    ```bash
    pip install torch transformers
    ```

<br>

2. 因為 LLaMA 模型不是像其他模型一樣托管在 Hugging Face 的公共模型庫中，而是由 Meta 開發和管理的，需要先通過授權和下載步驟，所以先 [登入官網申請授權](https://huggingface.co/meta-llama/Llama-2-7b)。

    ![](images/img_07.png)

<br>

3. 申請後等候審核。

    ![](images/img_08.png)

<br>

4. 可以進入 `Settings` 查看。

    ![](images/img_09.png)

<br>

5. 使用 Python 和 Hugging Face Transformers 庫來載入和使用 LLaMA 模型進行簡單的文本生成任務。

    ```python
    # 載入 LLaMA 的預訓練模型和相應的 tokenizer
    from transformers import AutoTokenizer, AutoModelForCausalLM

    # 載入預訓練的 LLaMA 模型和 tokenizer
    # 這裡使用 LLaMA-7B 作為範例
    model_name = "meta-llama/LLaMA-7B"  
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(model_name)

    # 將模型設置為評估模式（`model.eval()`）
    # 防止模型在生成時進行梯度更新
    model.eval()

    # 定義初始的輸入文本（`input_text`）
    input_text = "Once upon a time"
    # 將其轉換為模型可處理的 ID 格式
    input_ids = tokenizer.encode(input_text, return_tensors='pt')

    # 生成文本
    # 設置最大生成長度為 50 個 token
    output = model.generate(
        input_ids, max_length=50, 
        num_return_sequences=1
    )

    # 解碼生成的文本
    # 將生成的 ID 序列轉換回可讀的文本格式並輸出
    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)

    print("Generated Text:")
    print(generated_text)
    ```

<br>

___

_END_

