{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# 載入 secrets.toml 文件\n",
    "secrets = toml.load(\"secrets.toml\")\n",
    "\n",
    "# MongoDB URI\n",
    "ATLAS_CONNECTION_STRING = secrets[\"MONGODB_URL\"]\n",
    "# 設置環境變數\n",
    "os.environ[\"OPENAI_API_KEY\"] = secrets[\"OPENAI_API_KEY\"]\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "# Use streaming=True to load the dataset without downloading it fully\n",
    "data = load_dataset(\n",
    "    \"MongoDB/cosmopedia-wikihow-chunked\",\n",
    "    split=\"train\",\n",
    "    streaming=True\n",
    ")\n",
    "# Get first 25k records from the dataset\n",
    "data_head = data.take(25000)\n",
    "df = pd.DataFrame(data_head)\n",
    "\n",
    "# Use this if you want the full dataset\n",
    "# data = load_dataset(\"MongoDB/cosmopedia-wikihow-chunked\", split=\"train\")\n",
    "# df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text_token_length</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>Title: How to Create and Maintain a Compost Pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>**Step 2: Gather Materials**\\nGather brown (ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>_Key guideline:_ For every volume of green mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>188</td>\n",
       "      <td>_Key tip:_ Chop large items like branches and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>157</td>\n",
       "      <td>**Step 7: Maturation and Use**\\nAfter 3-4 mont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>4334</td>\n",
       "      <td>2</td>\n",
       "      <td>178</td>\n",
       "      <td>Guideline: Make copies of all original documen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>4334</td>\n",
       "      <td>3</td>\n",
       "      <td>183</td>\n",
       "      <td>In Texas, the bond amount must equal either 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>4334</td>\n",
       "      <td>4</td>\n",
       "      <td>191</td>\n",
       "      <td>Bond premium costs vary depending on factors s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>4334</td>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>Or deliver it in person during business hours ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>4334</td>\n",
       "      <td>6</td>\n",
       "      <td>69</td>\n",
       "      <td>Key Tips:\\n\\n* Maintain accurate records throu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_id  chunk_id  text_token_length  \\\n",
       "0           0         0                180   \n",
       "1           0         1                141   \n",
       "2           0         2                182   \n",
       "3           0         3                188   \n",
       "4           0         4                157   \n",
       "...       ...       ...                ...   \n",
       "24995    4334         2                178   \n",
       "24996    4334         3                183   \n",
       "24997    4334         4                191   \n",
       "24998    4334         5                136   \n",
       "24999    4334         6                 69   \n",
       "\n",
       "                                                    text  \n",
       "0      Title: How to Create and Maintain a Compost Pi...  \n",
       "1      **Step 2: Gather Materials**\\nGather brown (ca...  \n",
       "2      _Key guideline:_ For every volume of green mat...  \n",
       "3      _Key tip:_ Chop large items like branches and ...  \n",
       "4      **Step 7: Maturation and Use**\\nAfter 3-4 mont...  \n",
       "...                                                  ...  \n",
       "24995  Guideline: Make copies of all original documen...  \n",
       "24996  In Texas, the bond amount must equal either 1....  \n",
       "24997  Bond premium costs vary depending on factors s...  \n",
       "24998  Or deliver it in person during business hours ...  \n",
       "24999  Key Tips:\\n\\n* Maintain accurate records throu...  \n",
       "\n",
       "[25000 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4335"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensuring length of dataset is what we expect i.e. 25k\n",
    "len(df)\n",
    "\n",
    "# Previewing the contents of the data\n",
    "df.head()\n",
    "\n",
    "# Only keep records where the text field is not null\n",
    "df = df[df[\"text\"].notna()]\n",
    "\n",
    "# Number of unique documents in the dataset\n",
    "df.doc_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "\n",
    "def get_embeddings(docs: List[str], input_type: str, model:str=\"voyage-lite-02-instruct\") -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Get embeddings using the Voyage AI API.\n",
    "\n",
    "    Args:\n",
    "        docs (List[str]): List of texts to embed\n",
    "        input_type (str): Type of input to embed. Can be \"document\" or \"query\".\n",
    "        model (str, optional): Model name. Defaults to \"voyage-lite-02-instruct\".\n",
    "\n",
    "    Returns:\n",
    "        List[List[float]]: Array of embedddings\n",
    "    \"\"\"\n",
    "    response = voyage_client.embed(docs, model=model, input_type=input_type)\n",
    "    return response.embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5 Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(docs: List[str], model: str=\"text-embedding-3-large\") -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Generate embeddings using the OpenAI API.\n",
    "\n",
    "    Args:\n",
    "        docs (List[str]): List of texts to embed\n",
    "        model (str, optional): Model name. Defaults to \"text-embedding-3-large\".\n",
    "\n",
    "    Returns:\n",
    "        List[float]: Array of embeddings\n",
    "    \"\"\"\n",
    "    # replace newlines, which can negatively affect performance.\n",
    "    docs = [doc.replace(\"\\n\", \" \") for doc in docs]\n",
    "    response = openai_client.embeddings.create(input=docs, model=model)\n",
    "    response = [r.embedding for r in response.data]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349ba50ac5754d85a03d5330a18c610e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/655 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a77993e46340c39edc45e4b48af200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce7a3d1feb743b2b06ee8b56fc5e4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6137e8d6bb154ea188990ce59263163e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d59ffb35ae14a9289a5ddafb8bd9e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57491ee429174ded8a4ce838f85d64b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import List\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Instruction to append to user queries, to improve retrieval\n",
    "RETRIEVAL_INSTRUCT = \"Represent this sentence for searching relevant passages:\"\n",
    "\n",
    "# Check if CUDA (GPU support) is available, and set the device accordingly\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# Load the UAE-Large-V1 model from the Hugging Face \n",
    "model = AutoModel.from_pretrained('WhereIsAI/UAE-Large-V1').to(device)\n",
    "# Load the tokenizer associated with the UAE-Large-V1 model\n",
    "tokenizer = AutoTokenizer.from_pretrained('WhereIsAI/UAE-Large-V1')\n",
    "\n",
    "# Decorator to disable gradient calculations\n",
    "@torch.no_grad()\n",
    "def get_embeddings(docs: List[str], input_type: str) -> List[List[float]]:\n",
    "\n",
    "    # Prepend retrieval instruction to queries\n",
    "    if input_type == \"query\":\n",
    "        docs = [\"{}{}\".format(RETRIEVAL_INSTRUCT, q) for q in docs]\n",
    "    # Tokenize input texts\n",
    "    inputs = tokenizer(docs, padding=True, truncation=True, return_tensors='pt', max_length=512).to(device)\n",
    "    # Pass tokenized inputs to the model, and obtain the last hidden state\n",
    "    last_hidden_state = model(**inputs, return_dict=True).last_hidden_state\n",
    "    # Extract embeddings from the last hidden state\n",
    "    embeddings = last_hidden_state[:, 0]\n",
    "    return embeddings.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9187fe3f88e740fbbb4e992d157c57b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "get_embeddings() missing 1 required positional argument: 'input_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m batch \u001b[38;5;241m=\u001b[39m texts[i:end]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Generate embeddings for current batch\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m batch_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Add to the list of embeddings\u001b[39;00m\n\u001b[1;32m     17\u001b[0m embeddings\u001b[38;5;241m.\u001b[39mextend(batch_embeddings)\n",
      "File \u001b[0;32m~/Documents/PythonVenv/envllmChatBot/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_embeddings() missing 1 required positional argument: 'input_type'"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Get all the texts in the dataset\n",
    "texts = df[\"text\"].tolist()\n",
    "\n",
    "# Number of samples in a single batch\n",
    "batch_size = 128\n",
    "\n",
    "embeddings = []\n",
    "# Generate embeddings in batches\n",
    "for i in tqdm(range(0, len(texts), batch_size)):\n",
    "    end = min(len(texts), i+batch_size)\n",
    "    batch = texts[i:end]\n",
    "    # Generate embeddings for current batch\n",
    "    batch_embeddings = get_embeddings(batch)\n",
    "    # Add to the list of embeddings\n",
    "    embeddings.extend(batch_embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envllmChatBot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
