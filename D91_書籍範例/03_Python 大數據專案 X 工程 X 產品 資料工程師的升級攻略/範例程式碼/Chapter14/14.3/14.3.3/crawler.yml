version: '3.8'
services:
  crawler_twse:
    image: linsamtw/crawler:7.2.1
    hostname: "twse"
    command: pipenv run celery -A financialdata.tasks.worker worker --loglevel=info --concurrency=1  --hostname=%h -Q twse
    restart: always
    # swarm 設定
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.labels.crawler_twse == true]
    environment:
      - TZ=Asia/Taipei
    networks:
        - my_network

  crawler_tpex:
    image: linsamtw/crawler:7.2.1
    hostname: "tpex"
    command: pipenv run celery -A financialdata.tasks.worker worker --loglevel=info --concurrency=1  --hostname=%h -Q tpex
    restart: always
    # swarm 設定
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.labels.crawler_tpex == true]
    environment:
      - TZ=Asia/Taipei
    networks:
        - my_network

  sent_task:
    image: linsamtw/crawler:7.2.1
    hostname: "sent_task"
    command: pipenv run python financialdata/producer.py taiwan_stock_price 2021-04-01 2023-04-12
    restart: on-failure
    # swarm 設定
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.labels.sent_task == true]
    environment:
      - TZ=Asia/Taipei
    networks:
        - my_network

networks:
  my_network:
    # 加入已經存在的網路
    external: true
