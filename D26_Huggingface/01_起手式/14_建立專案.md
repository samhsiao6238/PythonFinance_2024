# 建立 Hugging Face 專案

_以下簡介並說明如果要建立一個專案該如何進行_

<br>

## 背景

1. 假設正在開發一個自然語言處理（NLP）專案，目的是建立一個自訂的情感分析模型，這個模型將根據中文文本資料判斷情感是正面的、負面的還是中性的。

<br>

2. 以下的操作將使用 Hugging Face 平台來訓練模型，先準備一組已標註的中文情感分析資料集，接著使用 Hugging Face 的 `transformers` 庫進行模型訓練，最終並將訓練好的模型上傳到 Hugging Face 的模型儲存庫，以便於其他開發者或應用程式使用。

<br>

## 步驟

1. 首先，準備一個已標註的中文情感分析資料集，資料集包含兩列 `text` 和 `label`；其中 `text` 是一段中文文本，`label` 是該文本的情感標註，即 `正面`、`負面` 或 `中性`。

    ```python
    import pandas as pd

    # 一個簡單的資料集
    data = {
        "text": ["這個產品非常好", "我不喜歡這個服務", "體驗很一般"],
        "label": ["正面", "負面", "中性"]
    }
    df = pd.DataFrame(data)

    # 儲存為 CSV 供後續使用
    df.to_csv("chinese_sentiment_dataset.csv", index=False)
    ```

<br>

2. 接下來使用 Hugging Face 的 `transformers` 庫來訓練一個簡單的情感分析模型；這裡選用一個預訓練的 `BERT` 模型，並使用資料集進行 `微調（Fine-tuning）`。

    ```python
    from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments
    from datasets import load_dataset

    # 載入資料集
    dataset = load_dataset('csv', data_files='chinese_sentiment_dataset.csv')

    # 使用 Hugging Face 提供的預訓練 BERT 模型
    model_name = "bert-base-chinese"
    tokenizer = BertTokenizer.from_pretrained(model_name)
    model = BertForSequenceClassification.from_pretrained(model_name, num_labels=3)

    # 將資料集進行預處理
    def preprocess_function(examples):
        return tokenizer(examples['text'], truncation=True, padding=True)

    encoded_dataset = dataset.map(preprocess_function, batched=True)

    # 設置訓練參數
    training_args = TrainingArguments(
        output_dir="./results",
        evaluation_strategy="epoch",
        learning_rate=2e-5,
        per_device_train_batch_size=16,
        per_device_eval_batch_size=16,
        num_train_epochs=3,
        weight_decay=0.01,
    )

    # 使用 Trainer 進行訓練
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=encoded_dataset["train"],
        eval_dataset=encoded_dataset["train"]
    )

    trainer.train()
    ```

<br>

## 訓練完成後

_將模型儲存到 Hugging Face 模型儲存庫中，並進行分享。_

<br>

1. 使用 CLI 建立新的儲存庫來存放模型。

    ```bash
    huggingface-cli repo create chinese-sentiment-model --type model
    ```

<br>

2. 將訓練好的模型和分詞器保存到本地。

    ```python
    model.save_pretrained("./chinese_sentiment_model")
    tokenizer.save_pretrained("./chinese_sentiment_model")
    ```

<br>

3. 將模型推送到 Hugging Face 儲存庫。

    ```bash
    # 初始化 Git 並安裝 git-lfs
    git init
    git lfs install

    # 將模型推送到 Hugging Face
    git remote add origin https://huggingface.co/username/chinese-sentiment-model
    git add .
    git commit -m "Initial commit of Chinese sentiment model"
    git push -u origin main
    ```

<br>

## 使用模型

1. 任何開發者皆可通過以下方式使用這個上傳的情感分析模型。

    ```python
    from transformers import AutoTokenizer, AutoModelForSequenceClassification

    tokenizer = AutoTokenizer.from_pretrained("username/chinese-sentiment-model")
    model = AutoModelForSequenceClassification.from_pretrained("username/chinese-sentiment-model")

    # 使用模型進行推理
    inputs = tokenizer("這是個好產品", return_tensors="pt")
    outputs = model(inputs)
    predictions = outputs.logits.argmax(-1)
    ```

<br>

## 部署模型

_可進一步將模型部署到 Hugging Face 的 `Space`，通過使用 Streamlit 或 Gradio 來建立一個簡單的網頁應用，讓用戶可以在線輸入文本並得到情感分析結果。_

<br>

___

_END_