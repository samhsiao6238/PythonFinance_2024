# 物件追蹤

## 說明

1. 從指定的影片檔案中讀取影格，使用 YOLOv8 模型進行物件追蹤，並在每個影格上繪製追蹤線條，最終將結果儲存到新的影片檔案中。

2. 每個被追蹤的物件都有一個唯一的 track_id，當 YOLO 模型識別並追蹤到物件時，代碼會記錄每個物件的中心點座標 (x, y) 到 track_history 字典中，接著，使用這些座標點來繪製出物件的運動軌跡、形成線條，這些線條用於顯示物件在最近 30 幀中的移動路徑，藉此觀察物件的移動軌跡。

## 範例

1. 背景處理。

```python
from collections import defaultdict
import cv2
import numpy as np
from ultralytics import YOLO


def track_video(video_path):
    """
    使用 YOLOv8 模型追蹤影片中的物件並將結果儲存到新影片中。

    :param video_path: 要處理的影片檔案路徑
    :return: 輸出影片的檔案路徑
    """
    # 加載 YOLO 模型 (yolov8n.pt 是一個預訓練的 YOLOv8 模型)
    model = YOLO("yolov8n.pt")

    # 打開影片檔案
    cap = cv2.VideoCapture(video_path)

    # 檢查影片是否成功打開
    if not cap.isOpened():
        print(f"Error opening video file: {video_path}")
        return

    # 使用 defaultdict 初始化一個空的追蹤歷史紀錄，以便儲存每個追蹤物件的軌跡
    track_history = defaultdict(lambda: [])

    # 取得影片的幀率 (FPS)
    fps = int(cap.get(cv2.CAP_PROP_FPS))

    # 取得影片的寬度和高度
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    # 定義影片的編碼器和建立 VideoWriter 物件，用於輸出影片
    # 輸出影片的檔案路徑
    output_path = "output_tracked_video.mp4"
    out = cv2.VideoWriter(
        output_path,
        cv2.VideoWriter_fourcc(*"mp4v"),
        fps,
        (frame_width, frame_height)
    )

    # 迴圈處理影片的每一幀
    while cap.isOpened():
        # 讀取一幀影片
        success, frame = cap.read()

        if success:
            # 使用 YOLO 模型進行物件追蹤，並保持追蹤結果（persist=True）
            results = model.track(frame, persist=True)

            # 取得追蹤物件的邊界框 (xywh: 中心點 x, 中心點 y, 寬度, 高度)
            boxes = results[0].boxes.xywh.cpu()

            # 取得追蹤物件的 ID，如果有的話
            track_ids = (
                results[0].boxes.id.int().cpu().tolist()
                if results[0].boxes.id is not None
                else None
            )

            # 在影格上繪製追蹤結果
            annotated_frame = results[0].plot()

            # 如果有追蹤 ID，則處理每個追蹤 ID 的軌跡
            if track_ids:
                for box, track_id in zip(boxes, track_ids):
                    x, y, w, h = box  # 取得邊界框的座標

                    # 取得特定物件的追蹤歷史
                    track = track_history[track_id]

                    # 將當前中心點加入追蹤歷史
                    # x, y 中心點
                    track.append((float(x), float(y)))

                    # 保留最近 30 幀的軌跡記錄
                    # 保留 30 幀的追蹤記錄
                    if len(track) > 30:
                        track.pop(0)

                    # 繪製追蹤線條
                    points = np.array(track).astype(np.int32).reshape(
                        (-1, 1, 2)
                    )
                    cv2.polylines(
                        annotated_frame,
                        [points],
                        isClosed=False,
                        color=(230, 230, 230),
                        thickness=2,
                    )

            # 將標註的影格寫入輸出影片
            out.write(annotated_frame)

            # 如果按下 "q" 鍵，則退出迴圈
            if cv2.waitKey(1) & 0xFF == ord("q"):
                break
        else:
            break

    # 釋放影片捕獲物件並關閉所有視窗
    cap.release()
    out.release()
    cv2.destroyAllWindows()

    # 返回輸出影片的檔案路徑
    return output_path


# 提供 "downloaded_video.mp4" 作為要追蹤的影片
input_video_path = "downloaded_video.mp4"
output_video_path = track_video(input_video_path)

print(f"輸出影片已儲存到: {output_video_path}")
```

2. 使用 cv2.imshow("YOLOv8 Object Tracking", annotated_frame) 即時顯示處理後的影格，這樣就能在追蹤的同時播放影片。

```python
from collections import defaultdict
import cv2
import numpy as np
from ultralytics import YOLO


def track_video(video_path):
    """
    使用 YOLOv8 模型追蹤影片中的物件並將結果儲存到新影片中。

    :param video_path: 要處理的影片檔案路徑
    :return: 輸出影片的檔案路徑
    """
    # 加載 YOLO 模型 (yolov8n.pt 是一個預訓練的 YOLOv8 模型)
    model = YOLO("yolov8n.pt")

    # 打開影片檔案
    cap = cv2.VideoCapture(video_path)

    # 檢查影片是否成功打開
    if not cap.isOpened():
        print(f"Error opening video file: {video_path}")
        return

    # 使用 defaultdict 初始化一個空的追蹤歷史紀錄，以便儲存每個追蹤物件的軌跡
    track_history = defaultdict(lambda: [])

    # 取得影片的幀率 (FPS)
    fps = int(cap.get(cv2.CAP_PROP_FPS))

    # 取得影片的寬度和高度
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    # 定義影片的編碼器和建立 VideoWriter 物件，用於輸出影片
    # 輸出影片的檔案路徑
    output_path = "output_tracked_video.mp4"
    out = cv2.VideoWriter(
        output_path,
        cv2.VideoWriter_fourcc(*"mp4v"),
        fps,
        (frame_width, frame_height)
    )

    # 迴圈處理影片的每一幀
    while cap.isOpened():
        success, frame = cap.read()  # 讀取一幀影片

        if success:
            # 使用 YOLO 模型進行物件追蹤，並保持追蹤結果（persist=True）
            results = model.track(frame, persist=True)

            # 取得追蹤物件的邊界框 (xywh: 中心點 x, 中心點 y, 寬度, 高度)
            boxes = results[0].boxes.xywh.cpu()

            # 取得追蹤物件的 ID，如果有的話
            track_ids = (
                results[0].boxes.id.int().cpu().tolist()
                if results[0].boxes.id is not None
                else None
            )

            # 在影格上繪製追蹤結果
            annotated_frame = results[0].plot()

            # 如果有追蹤 ID，則處理每個追蹤 ID 的軌跡
            if track_ids:
                for box, track_id in zip(boxes, track_ids):
                    x, y, w, h = box  # 取得邊界框的座標

                    # 取得特定物件的追蹤歷史
                    track = track_history[track_id]

                    # 將當前中心點加入追蹤歷史
                    track.append((float(x), float(y)))  # x, y 中心點

                    # 保留最近 30 幀的軌跡記錄
                    if len(track) > 30:  # 保留 30 幀的追蹤記錄
                        track.pop(0)

                    # 繪製追蹤線條
                    points = np.array(track).astype(np.int32).reshape(
                        (-1, 1, 2)
                    )
                    cv2.polylines(
                        annotated_frame,
                        [points],
                        isClosed=False,
                        color=(230, 230, 230),
                        thickness=2,
                    )

            # 將標註的影格寫入輸出影片
            out.write(annotated_frame)

            # 在這裡即時顯示影片
            cv2.imshow("YOLOv8 Object Tracking", annotated_frame)

            # 如果按下 "q" 鍵，則退出迴圈
            if cv2.waitKey(1) & 0xFF == ord("q"):
                break
        else:
            break

    # 釋放影片捕獲物件並關閉所有視窗
    cap.release()
    out.release()
    cv2.destroyAllWindows()

    # 返回輸出影片的檔案路徑
    return output_path


# 提供 "downloaded_video.mp4" 作為要追蹤的影片
input_video_path = "downloaded_video.mp4"
output_video_path = track_video(input_video_path)

print(f"輸出影片已儲存到: {output_video_path}")
```