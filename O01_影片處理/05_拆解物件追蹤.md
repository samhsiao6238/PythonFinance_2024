# 拆解物件追蹤

<br>

## 說明

1. 這個範例主要目的是使用 YOLO 模型進行物件偵測和追蹤，並在影片中標註出偵測到的物件、其分類和距離中心點的距離。

<br>

## 拆解

1. 安裝。

   ```bash
   pip install cvzone
   ```

<br>

2. 導入必要的庫。

   ```python
   # OpenCV 庫，用於處理影像和影片
   import cv2
   # 數學計算
   import math
   # OpenCV 的高級功能
   import cvzone
   # YOLO 模型
   from ultralytics import YOLO
   ```

<br>

3. 設定變數。

   ```python
   # 是否將結果儲存為影片
   SAVE_RESULT_AS_VIDEO = False
   # 輸出影片的文件名
   RESULT_FILE_NAME = "result.mp4"
   ```

<br>

4. 定義影像處理函數。

   ```python
   # 使用預訓練的 YOLO 模型 `model.pt` 來檢測物件
   def process_image(img, model=YOLO('model.pt'), stream=True):
      # 略 ...
   ```

<br>

5. 物件偵測和標註。

   ```python
   # 使用 YOLO 模型來檢測影像中的物件，並返回結果
   results = model(img, stream)

   # 迭代所有偵測到的物件，並對每個物件進行標註
   for result in results:
      # 取得每個物件的邊界框 `(x1, y1)` 和 `(x2, y2)`，並計算物件中心 `(cx, cy)`
      for box in result.boxes:
         # 取得物件邊界框座標
         x1, y1, x2, y2 = box.xyxy[0].int().tolist()
         ...
   ```

<br>

6. 計算與標註。

   ```python
   # 計算影像中心與物件中心的歐幾里德距離
   cdist = int(math.sqrt((icx - cx)  2 + (icy - cy)  2))
   # 繪製邊界框、中心點、文字標註等
   cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 1)
   # 略 ...
   ```

<br>

7. 處理影片輸入和輸出。

   ```python
   # 使用 `cv2.VideoCapture` 讀取輸入影片
   videoCapture = cv2.VideoCapture('<要輸入的影片>')
   # 如果 `SAVE_RESULT_AS_VIDEO` 為 True
   # 使用 `cv2.VideoWriter` 儲存處理後的影片
   videoWriter = None
   ```

<br>

8. 影片幀處理循環。

   ```python
   while videoCapture.isOpened():
      success, img = videoCapture.read()
      if success:
         # 使用 `process_image` 函數來處理每一幀，並根據設定顯示或儲存結果。
         process_image(img)
         # ...
   ```

<br>

9. 顯示或儲存結果。

   ```python
   # 如果 `SAVE_RESULT_AS_VIDEO` 為 True，則將處理後的影像寫入影片文件
   if SAVE_RESULT_AS_VIDEO:
      videoWriter.write(img)
   # 否則，將處理後的影像顯示在 OpenCV 視窗中。用戶可以按 `q` 鍵來退出
   else:
      cv2.imshow("Image", img)
      if cv2.waitKey(1) & 0xFF == ord('q'):
         break
   ```

<br>

10. 釋放資源。

   ```python
   if SAVE_RESULT_AS_VIDEO:
      videoWriter.release()
   else:
      # 完成處理後，釋放所有資源
      cv2.destroyAllWindows()
   ```

<br>

11. 完整腳本。

   ```python
   import cv2
   import math
   import cvzone
   from ultralytics import YOLO

   SAVE_RESULT_AS_VIDEO = False
   RESULT_FILE_NAME = "result.mp4"


   def process_image(img, model=YOLO("model.pt"), stream=True):
      results = model(img, stream)

      for result in results:
         for box in result.boxes:
               x1, y1, x2, y2 = box.xyxy[0].int().tolist()
               cx, cy = x1 + (x2 - x1) // 2, y1 + (y2 - y1) // 2
               iw, ih = img.shape[:2][::-1]
               icx, icy = iw // 2, ih // 2
               cdist = int(math.sqrt((icx - cx) ** 2 + (icy - cy) ** 2))
               conf = math.ceil((box.conf[0] * 100)) / 100
               cls = result.names[int(box.cls[0])]
               cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 1)
               cvzone.putTextRect(
                  img,
                  f"{cls} {conf}",
                  (max(0, x1 + 5), max(0, y1 - 15)),
                  scale=1,
                  thickness=1,
               )
               cv2.circle(img, (cx, cy), 5, (255, 0, 255), cv2.FILLED)
               cvzone.putTextRect(
                  img,
                  f"{cdist}",
                  (max(0, x1 + 5), min(ih - 25, y2 + 25)),
                  scale=1,
                  thickness=1,
               )
               cv2.circle(img, (icx, icy), 5, (255, 0, 255), cv2.FILLED)
               cv2.rectangle(
                  img,
                  (int(iw * 0.1), int(ih * 0.1)),
                  (int(iw * 0.9), int(ih * 0.9)),
                  (255, 0, 255),
                  1,
               )

               cv2.line(img, (icx, icy), (cx, cy), (255, 0, 255), 1)

   videoCapture = cv2.VideoCapture("downloaded_video.mp4")
   videoWriter = None

   while videoCapture.isOpened():
      success, img = videoCapture.read()
      if success:
         process_image(img)

         if SAVE_RESULT_AS_VIDEO:
            if videoWriter is None:
               cv2_fourcc = cv2.VideoWriter.fourcc(*"mp4v")
               videoWriter = cv2.VideoWriter(
                  RESULT_FILE_NAME, cv2_fourcc, 24, img.shape[:2][::-1]
               )

               videoWriter.write(img)
         else:
               cv2.imshow("Image", img)

               if cv2.waitKey(1) & 0xFF == ord("q"):
                  break

      else:
         break

   if SAVE_RESULT_AS_VIDEO:
      videoWriter.release()
   else:
      cv2.destroyAllWindows()

   print("Video processing completed!")
   ```

<br>

## 優化

1. 這個腳本會下載 YouTube 影片，然後使用 YOLOv8 模型進行物件偵測和追蹤，並在影片中標註物件類別、置信度以及物件中心點與影像中心點的距離。

   ```python
   import yt_dlp
   import cv2
   import math
   import cvzone
   import numpy as np
   import re
   from ultralytics import YOLO
   import pytesseract

   # 設定常數
   # 如果為 True，則儲存結果為影片
   SAVE_RESULT_AS_VIDEO = False
   # 輸出影片的檔案名稱
   RESULT_FILE_NAME = "result.mp4"
   # 使用的 YOLO 模型文件
   YOLO_MODEL_PATH = "yolov8n.pt"

   # 下載 YouTube 影片
   URL = "https://www.youtube.com/watch?v=sBdUc7hO_9I"
   output_path = "downloaded_video.mp4"

   ydl_opts = {
      "format": "best",
      "outtmpl": output_path,
   }

   with yt_dlp.YoutubeDL(ydl_opts) as ydl:
      ydl.download([URL])

   # 設置影片路徑
   video_path = output_path


   def is_team_color(image, color):
      """
      檢查圖像中的球衣顏色。
      """
      hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

      if color == "yellow":
         lower_yellow = np.array([20, 100, 100])
         upper_yellow = np.array([30, 255, 255])
         mask = cv2.inRange(hsv_image, lower_yellow, upper_yellow)
      elif color == "blue":
         lower_blue = np.array([100, 100, 100])
         upper_blue = np.array([140, 255, 255])
         mask = cv2.inRange(hsv_image, lower_blue, upper_blue)
      else:
         return False

      return cv2.countNonZero(mask) > 0


   def detect_number(image):
      """
      使用 Tesseract OCR 來偵測圖像中的數字（背號）
      """
      gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
      _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)

      # 使用 pytesseract 提取數字
      text = pytesseract.image_to_string(thresh, config="--psm 6 digits")
      numbers = re.findall(r"\d+", text)

      return numbers[0] if numbers else None


   def process_image(img, model, stream=True):
      """
      處理單張影像，進行物件偵測和標註。

      :param img: 要處理的影像。
      :param model: 用於物件偵測的 YOLO 模型。
      :param stream: 如果為 True，則使用模型的流處理模式。
      """
      results = model(img, stream)

      for result in results:
         for box in result.boxes:
            # 取得物件邊界框座標
            x1, y1, x2, y2 = box.xyxy[0].int().tolist()

            # 取得物件中心點
            cx, cy = x1 + (x2 - x1) // 2, y1 + (y2 - y1) // 2

            # 取得影像的寬度和高度
            iw, ih = img.shape[:2][::-1]

            # 影像中心的座標
            icx, icy = iw // 2, ih // 2

            # 計算物件中心與影像中心的歐幾里德距離
            cdist = int(math.sqrt((icx - cx) ** 2 + (icy - cy) ** 2))

            # 置信度
            conf = math.ceil((box.conf[0] * 100)) / 100

            # 偵測到的物件類別名稱
            cls = result.names[int(box.cls[0])]

            # 繪製物件的邊界框
            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 1)

            # 在影像中物件位置放置類別和置信度
            cvzone.putTextRect(
               img,
               f"{cls} {conf}",
               (max(0, x1 + 5), max(0, y1 - 15)),
               scale=1,
               thickness=1,
            )

            # 在物件中心畫一個圓圈
            cv2.circle(img, (cx, cy), 5, (255, 0, 255), cv2.FILLED)

            # 在物件框下方放置距離
            cvzone.putTextRect(
               img,
               f"{cdist}",
               (max(0, x1 + 5), min(ih - 25, y2 + 25)),
               scale=1,
               thickness=1,
            )

            # 在影像中心畫一個圓圈
            cv2.circle(img, (icx, icy), 5, (255, 0, 255), cv2.FILLED)

            # 繪製影像邊界框（以 10% 的內縮）
            cv2.rectangle(
               img,
               (int(iw * 0.1), int(ih * 0.1)),
               (int(iw * 0.9), int(ih * 0.9)),
               (255, 0, 255),
               1,
            )

            # 繪製從影像中心到物件中心的線
            cv2.line(
               img,
               (icx, icy), (cx, cy),
               (255, 0, 255), 1
            )


   # 加載 YOLOv8 模型
   model = YOLO(YOLO_MODEL_PATH)

   # 設置視頻來源
   videoCapture = cv2.VideoCapture(video_path)
   videoWriter = None

   while videoCapture.isOpened():
      success, img = videoCapture.read()
      if success:
         process_image(img, model)

         if SAVE_RESULT_AS_VIDEO:
               if videoWriter is None:
                  cv2_fourcc = cv2.VideoWriter.fourcc(*"mp4v")
                  videoWriter = cv2.VideoWriter(
                     RESULT_FILE_NAME,
                     cv2_fourcc,
                     24,
                     img.shape[:2][::-1]
                  )

               videoWriter.write(img)
         else:
               # 顯示處理結果
               cv2.imshow("Image", img)

               if cv2.waitKey(1) & 0xFF == ord("q"):
                  break

      else:
         break

   if SAVE_RESULT_AS_VIDEO:
      videoWriter.release()
   else:
      # 關閉所有 OpenCV 視窗
      cv2.destroyAllWindows()

   print("Video processing completed!")
   ```

<br>

___

_END_