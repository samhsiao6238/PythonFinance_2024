# 機器學習

_從 `數據` 中學習 `模式和規律` 來進行 `預測或決策`_

<br>

## 主要類型

_`監督式學習` 依賴標註數據進行訓練，而 `非監督式學習` 則在無標註數據中尋找內在結構；`強化學習` 是一種通過試錯和獎勵機制來學習最佳行為策略的方法，同樣是不依賴於標註數據或數據內在結構。_

<br>

1. 監督式學習（Supervised Learning）：利用 `標註數據` 進行訓練，模型學習 _輸入與輸出之間的映射關係_，適用於分類（如垃圾郵件檢測）或迴歸（如房價預測）問題。

<br>

2. 非監督式學習（Unsupervised Learning）：在 `無標註數據` 的情況下，模型嘗試學習 _數據的內在結構_，用於聚類（如客戶細分）或降維（如主成分分析）問題。

<br>

3. 強化學習（Reinforcement Learning）：強化學習是通過 `代理（agent）` 與環境進行互動來學習，代理會根據環境的狀態做出動作，然後根據動作的結果獲得 `回饋（獎勵或懲罰）`，並根據這些回饋來更新策略，以最大化長期回報；常用於遊戲AI、機器人控制、自動駕駛等需要決策和控制的任務；所謂 `最大化長期回報` 指的是在強化學習中，代理通過選擇一系列動作，使得在未來的整個過程中累積的回報總和達到最大，這表示代理不僅關注當前的回報，更考慮長期的回報，因此會選擇那些可能在未來帶來更高回報的策略，而不是僅僅追求短期的利益。

<br>

4. 半監督式學習（Semi-supervised learning）：結合了監督式和非監督式學習的元素，模型使用少量的標註數據來引導學習過程，同時利用大量未標註數據來學習數據的內在結構和模式；這種方法有助於提高模型在標註數據有限時的性能，特別是在標註成本高昂或標註過程耗時的情況下，常應用於語音識別、文本分類、圖像標註和生物信息學等領域。

<br>

## 分佈假設

1. 參數模型：此類模型的數據會服從某種特定的分佈假設，例如數據服從常態分佈的演算法有線性迴歸、邏輯迴歸等，由於數據分佈具有一定的假設基礎，模型相對有較強的可解釋性，這與統計學的概念是一致的。

<br>

2. 非參數模型：非參數模型不依賴於對數據的任何明確分佈假設。模型更靈活，可以適應更複雜的數據分佈，與統計學小樣本適用非參數統計方法不同，機器學習中的非參數模型通常需要更多的訓練數據，並且訓練和預測過程耗時更長；常見的非參數模型如 k-NN、決策樹、SVM、隨機森林等。

<br>

## 任務類別

1. 分類（Classification）：監督式學習任務，識別數據所屬的類別標籤，例如垃圾郵件檢測、圖片分類、醫學診斷等。

<br>

2. 迴歸（Regression）：監督式學習任務，使用帶有標籤的訓練數據來學習輸入特徵和連續數值之間的映射關係，然後對新數據進行數值預測，例如房價預測、股票價格預測。

<br>

3. 聚類（Clustering）：非監督式學習任務，在無需標籤的情況下，將相似數據點分組，例如市場客戶細分、圖像分割、文檔分組等。

<br>

4. 降維（Dimensionality Reduction）：非監督式學習任務，不需要標籤來學習數據的特徵表示，透過簡化數據特徵空間，保留重要信息，例如 PCA、t-SNE。

<br>

5. 異常檢測（Anomaly Detection）：用以識別數據集中與大多數數據不同的 `異常數據點`，例如金融欺詐檢測、網絡入侵檢測；這種任務類別也就是某種應用場景，它不是具體的算法或模型，而是可使用多種不同算法或模型來因應，例如使用 `K-means、Isolation Forest、One-Class SVM` 等，根據是否有標註數據，可以採用監督或非監督的方式進行。

<br>

6. 強化學習（Reinforcement Learning）：既不是監督式也不是非監督式學習。它是一種基於試錯法和獎勵機制的學習方式；通過試驗和錯誤學習策略，在動態環境中獲得最大化回報，例如機器人控制、遊戲AI。

<br>

___

_END_