# Hugging Face 服務簡介

<br>

## 簡介

1. Hugging Face 是一家專注於人工智能和機器學習的公司，特別是在 `自然語言處理（NLP）` 領域，提供了多種開源工具、模型和平台服務，幫助開發者更容易地構建、訓練、部署和共享機器學習模型。

<br>

2. 隨著 `大型語言模型（LLM）` 的普及，Hugging Face 已經成為許多開發者和研究人員進行 NLP 和相關任務的標準平台。

<br>

## 自然語言處理應庫 `transformers`

1. Hugging Face 的 `transformers` 是一個開源庫，提供了對多種預訓練模型的支援，這些模型可以用於各種 NLP 任務，如文本分類、情感分析、翻譯、摘要生成等

<br>

2. `transformers` 庫的核心功能是簡化了複雜模型的使用，使得開發者能夠在幾行代碼內調用並應用這些強大的模型，具備多種模型支持，如 BERT、GPT、T5 等，另外也提供數百個預訓練模型，開發者可以直接使用或進行微調，同時也支持 PyTorch 和 TensorFlow 平台。

<br>

3. 此範例展示了如何在幾行代碼內使用 `transformers` 庫進行情感分析，預訓練模型會自動下載並應用於輸入文本的分析。

```python
from transformers import pipeline

# 使用預訓練的情感分析模型
classifier = pipeline("sentiment-analysis")

result = classifier("I love using Hugging Face's transformers library!")
print(result)
```

<br>

## Hugging Face Hub

_共享機器學習模型和資料集的平台_

<br>

1. Hugging Face Hub 是一個社群驅動的共享平台，用於儲存和分享機器學習模型、資料集和應用程序，這個平台提供了許多開源模型，並允許開發者上傳自己的模型進行分享，它已經成為 LLM 開發的標準平台，許多公司和研究機構都會將其開源的模型上傳至 Hugging Face Hub，供他人下載和使用。

<br>

2. 開發者可以在 `Hugging Face Hub` 分享和下載模型，共享和使用各種標註資料集，使用 Gradio 或 Streamlit 建立和部署 Web 應用。

<br>

3. 以下範例示範如何從 Hugging Face Hub 上載入預訓練的 GPT 模型，並使用它來生成文本。
。

```python
from transformers import AutoTokenizer, AutoModelForCausalLM

# 載入 GPT-3 模型
tokenizer = AutoTokenizer.from_pretrained("gpt2")
model = AutoModelForCausalLM.from_pretrained("gpt2")

input_text = "Once upon a time"
input_ids = tokenizer(input_text, return_tensors='pt').input_ids

# 生成文本
output = model.generate(input_ids, max_length=50)
print(tokenizer.decode(output[0], skip_special_tokens=True))
```

<br>

## `datasets`：數據集管理工具

1. `datasets` 是一個強大的工具集，專為管理和處理大型數據集而設計。它支持從 Hugging Face Hub 或本地文件加載數據集，並提供了高效的處理方式來清理、轉換和分割數據。

<br>

2. 支持 CSV、JSON、Text 等多種格式，同時支持高效的數據處理，包括分割、過濾、轉換等操作，並且與 `transformers` 完美集成：可直接用於模型訓練。

<br>

3. 以下示範如何使用 `datasets` 庫來載入 IMDb 電影評論資料集，並簡單地進行分割和展示。

```python
from datasets import load_dataset

# 從 Hugging Face Hub 載入 IMDb 電影評論資料集
dataset = load_dataset("imdb")

# 分割成訓練集和測試集
train_dataset = dataset['train']
test_dataset = dataset['test']

# 顯示一些樣本
print(train_dataset[0])
```

<br>

## `Gradio` 和 `Streamlit`

_快速部署機器學習應用_

<br>

1. Hugging Face 提供了與 `Gradio` 和 `Streamlit` 的集成，允許開發者快速地將機器學習模型包裝成 Web 應用，並部署在 Hugging Face `Space` 上。這些工具非常適合演示和分享你的模型成果。

<br>

2. 可進行快速部署，幾乎不需要 Web 開發經驗即可構建 Web 應用。用戶可以通過 Web 介面直接與模型進行互動。

<br>

3. 以下範例展示如何使用 Gradio 建立一個簡單的 Web 應用，用戶可以通過介面輸入文本並取得情感分析結果。

```python
import gradio as gr
from transformers import pipeline

# 使用 Hugging Face 的情感分析模型
classifier = pipeline("sentiment-analysis")

def analyze_sentiment(text):
    return classifier(text)

# 使用 Gradio 建立一個 Web 應用
gr.Interface(fn=analyze_sentiment, inputs="text", outputs="label").launch()
```

<br>

## `accelerate`

_高效訓練分布式模型_

<br>

1. `accelerate` 是 Hugging Face 提供的一個工具，用於簡化多 GPU 或多 TPU 環境下的分布式模型訓練。它允許開發者輕鬆管理和加速大規模的模型訓練。

<br>

2. 簡化分布式訓練，減少配置和程式碼複雜度。支持多種硬件，包括 GPU、TPU 等。

<br>

3. 這段代碼展示了如何使用 `accelerate` 來管理和加速模型的訓練過程。

```python
from accelerate import Accelerator

# 初始化加速器
accelerator = Accelerator()

# 將模型和資料移動到加速器上
model, optimizer, train_dataloader = accelerator.prepare(model, optimizer, train_dataloader)

# 訓練迴圈
for epoch in range(num_epochs):
    for batch in train_dataloader:
        outputs = model(batch)
        loss = outputs.loss
        accelerator.backward(loss)
        optimizer.step()
        optimizer.zero_grad()
```

<br>

___

_END_