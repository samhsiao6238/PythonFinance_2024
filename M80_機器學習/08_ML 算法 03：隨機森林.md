# 隨機森林（Random Forest）

_隨機森林是一種集成學習方法（Ensemble Learning Method），通過建構多個 `決策樹`，並將他們的預測結果進行 `平均（迴歸問題）` 或 `投票（分類問題）` 來提高模型的準確性和穩定性。_

<br>

## 說明

1. 隨機森林通過訓練多棵決策樹並結合它們的輸出結果來提高模型的穩定性和預測能力。每棵樹在分裂節點時，隨機選擇特徵進行分裂，這樣可以降低模型的偏差並減少過擬合。

<br>

2. 隨機森林可以應用於迴歸和分類任務，並且可以處理多維數據，相比其他算法，隨機森林的參數調整較為簡單，主要是樹的數量和最大深度。

<br>

3. 由於隨機森林是基於多棵決策樹的集成，因此對於異常值和噪聲數據具有更強的抵抗能力。

<br>

4. 隨機森林的缺點主要是計算成本高，這是因為需要構建大量的決策樹，計算開銷較大；另外，由於是多棵樹的集成，難以解釋每個單獨的預測，模型解釋性較低。

<br>

## 範例

1. 之前在簡介時使用了 `Iris 數據集`，在這裏將使用 `wine 數據集` 演示隨機森林演算法的分類。

    ```python
    # 引入所需的庫
    import numpy as np
    import matplotlib.pyplot as plt
    from sklearn.datasets import load_wine
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.metrics import (
        classification_report, 
        confusion_matrix, 
        ConfusionMatrixDisplay, 
        accuracy_score
    )

    # 設定支持中文的字體，避免顯示錯誤
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']
    plt.rcParams['axes.unicode_minus'] = False

    # 加載數據集
    data = load_wine()
    X = data.data
    y = data.target

    # 將數據集拆分為訓練集和測試集，分成訓練集80%和測試集20%
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, 
        test_size=0.2, random_state=42
    )

    # 初始化隨機森林分類器
    model = RandomForestClassifier(
        # 設置樹的數量為 100
        n_estimators=100, 
        random_state=42
    )

    # 訓練模型
    model.fit(X_train, y_train)

    # 使用訓練好的模型進行預測
    y_pred = model.predict(X_test)

    # 計算混淆矩陣
    cm = confusion_matrix(y_test, y_pred)

    # 可視化混淆矩陣
    disp = ConfusionMatrixDisplay(
        confusion_matrix=cm, 
        display_labels=data.target_names
    )
    disp.plot(cmap=plt.cm.Blues)
    plt.title('隨機森林模型的混淆矩陣')
    plt.show()

    # 計算分類報告
    report = classification_report(
        y_test, y_pred, 
        target_names=data.target_names
    )
    print("分類報告：")
    print(report)

    # 計算整體準確率
    accuracy = accuracy_score(y_test, y_pred)
    print(f"整體準確率（Overall Accuracy）: {accuracy:.2f}")

    # 顯示特徵的重要性
    feature_importances = model.feature_importances_
    indices = np.argsort(feature_importances)[::-1]
    print("特徵的重要性排序：")
    for f in range(X.shape[1]):
        print(
            f"{data.feature_names[indices[f]]}:"
            f" {feature_importances[indices[f]]:.4f}"
        )

    # 可視化特徵的重要性
    plt.figure(figsize=(10, 6))
    plt.title('特徵的重要性')
    plt.bar(
        range(X.shape[1]), 
        feature_importances[indices], 
        color='b', 
        align='center'
    )
    plt.xticks(
        range(X.shape[1]),
        [data.feature_names[i] for i in indices],
        rotation=90
    )
    plt.xlabel('特徵')
    plt.ylabel('重要性分數')
    plt.grid(True)
    plt.show()
    ```

<br>

2. 從輸出混淆矩陣可見模型對於所有類別的分類都是 100% 正確的。

    ![](images/img_100.png)

<br>

3. 輸出報表，其中每個類別的支持數（support）表示每個類別中的實際數據點數量，其中 class_0 和 class_1 的支持數都是 `14`，而 class_2 是 `8`，分類報告中的所有評估指標也都達到了1.00，表示模型完美地分類了所有的數據點；然而這種完美的結果在現實數據集上並不常見，可能需要進一步的模型驗證或交叉驗證來確認模型的穩定性和泛化能力。

    ![](images/img_101.png)

<br>

4. 特徵的重要性排序圖示。

    ![](images/img_116.png)

<br>

## 驗證

1. 對數據集進行隨機抽樣後使用模型進行推論與驗證，直到發生錯誤停止；因為隨機森林算法在 `Wine 資料集` 表現很好，所以設置了在迴圈 `200 次` 後強制停止。

    ```python
    # 引入所需的庫
    import numpy as np
    import matplotlib.pyplot as plt
    from sklearn.datasets import load_wine
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.metrics import (
        classification_report, 
        confusion_matrix, 
        ConfusionMatrixDisplay, 
        accuracy_score
    )

    # 設定支持中文的字體，避免顯示錯誤
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']
    plt.rcParams['axes.unicode_minus'] = False

    # 加載數據集
    data = load_wine()
    X = data.data
    y = data.target

    # 將數據集拆分為訓練集和測試集，分成訓練集80%和測試集20%
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, 
        test_size=0.2, random_state=42
    )

    # 初始化隨機森林分類器
    model = RandomForestClassifier(
        # 設置樹的數量為 100
        n_estimators=100, 
        random_state=42
    )

    # 訓練模型
    model.fit(X_train, y_train)

    # 使用訓練好的模型進行預測
    y_pred = model.predict(X_test)

    # 計算混淆矩陣
    cm = confusion_matrix(y_test, y_pred)

    # 可視化混淆矩陣
    disp = ConfusionMatrixDisplay(
        confusion_matrix=cm, 
        display_labels=data.target_names
    )
    disp.plot(cmap=plt.cm.Blues)
    plt.title('隨機森林模型的混淆矩陣')
    plt.show()

    # 計算分類報告
    report = classification_report(
        y_test, y_pred, 
        target_names=data.target_names
    )
    print("分類報告：")
    print(report)

    # 計算整體準確率
    accuracy = accuracy_score(y_test, y_pred)
    print(f"整體準確率（Overall Accuracy）: {accuracy:.2f}")

    # 顯示特徵的重要性
    feature_importances = model.feature_importances_
    indices = np.argsort(feature_importances)[::-1]
    print("特徵的重要性排序：")
    for f in range(X.shape[1]):
        print(
            f"{data.feature_names[indices[f]]}:"
            f" {feature_importances[indices[f]]:.4f}"
        )

    # 可視化特徵的重要性
    plt.figure(figsize=(10, 6))
    plt.title('特徵的重要性')
    plt.bar(
        range(X.shape[1]), 
        feature_importances[indices], 
        color='b', 
        align='center'
    )
    plt.xticks(
        range(X.shape[1]),
        [data.feature_names[i] for i in indices],
        rotation=90
    )
    plt.xlabel('特徵')
    plt.ylabel('重要性分數')
    plt.grid(True)
    plt.show()

    # 進行隨機抽樣驗證直到發生錯誤
    count = 0
    while True:
        # 隨機選取一個測試樣本進行預測
        sample_index = np.random.randint(0, len(X_test))
        sample = X_test[sample_index].reshape(1, -1)
        true_value = y_test[sample_index]

        # 使用模型進行預測
        predicted_value = model.predict(sample)

        print(f"\n第 {count + 1} 次抽樣:")
        print("選取的測試樣本索引:", sample_index)
        print("選取的測試樣本的真實類別:", data.target_names[true_value])
        print("模型預測的類別:", data.target_names[predicted_value[0]])

        # 比較預測值和真實值
        if predicted_value == true_value:
            print("模型預測正確！")
        else:
            print("模型預測錯誤。")
            print("\n預測錯誤的樣本特徵內容：")
            for feature_name, feature_value in zip(data.feature_names, X_test[sample_index]):
                print(f"{feature_name}: {feature_value:.4f}")
            # 退出迴圈，因為預測錯誤
            break

        count += 1

        # 假如超過200次就強制停止
        if count > 199:
            break

    print(f"\n總共抽取了 {count} 次樣本。")
    ```

<br>

___

_END_