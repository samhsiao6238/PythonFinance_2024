{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基礎範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            combined  \\\n",
      "0  Good Quality Dog Food. I have bought several o...   \n",
      "1  Not as Advertised. Product arrived labeled as ...   \n",
      "2  Delicious. These are the best cookies I have e...   \n",
      "3  Terrible customer service. The product was oka...   \n",
      "4  Just okay. The product was neither great nor b...   \n",
      "\n",
      "                                           embedding  \n",
      "0  [0.015021142549812794, -0.007734853308647871, ...  \n",
      "1  [-0.014828150160610676, -0.005706844385713339,...  \n",
      "2  [0.03156798705458641, -0.06490229815244675, -0...  \n",
      "3  [-0.03399420902132988, -0.01097179763019085, -...  \n",
      "4  [-0.04210306704044342, 0.019184265285730362, -...  \n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 載入環境變數\n",
    "load_dotenv()\n",
    "\n",
    "# 從環境變數中取得 API 密鑰\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input=[text], model=model).data[0].embedding\n",
    "\n",
    "# 假設有一個包含文本數據的 DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'combined': [\n",
    "        'Good Quality Dog Food. I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than most.',\n",
    "        'Not as Advertised. Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. The vendor refused to refund my purchase or send me the correct product.',\n",
    "        'Delicious. These are the best cookies I have ever eaten! I highly recommend them to anyone who loves chocolate.',\n",
    "        'Terrible customer service. The product was okay, but the customer service was terrible. I will not be buying from this company again.',\n",
    "        'Just okay. The product was neither great nor bad. It was just okay. I might buy it again if there are no better options.',\n",
    "    ]\n",
    "})\n",
    "\n",
    "# 將文本轉換為嵌入\n",
    "df['embedding'] = df.combined.apply(lambda x: get_embedding(x, model='text-embedding-3-small'))\n",
    "\n",
    "# 儲存結果到 CSV 文件\n",
    "df.to_csv('embedded_reviews.csv', index=False)\n",
    "\n",
    "# 從儲存的文件中載入嵌入數據\n",
    "df = pd.read_csv('embedded_reviews.csv')\n",
    "df['embedding'] = df.embedding.apply(eval).apply(np.array)\n",
    "\n",
    "# 顯示結果\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搜尋 Search\n",
    "\n",
    "根據查詢字串找到最相關的文本，通過計算嵌入向量之間的餘弦相似度來實現。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            combined  similarity\n",
      "2  Delicious. These are the best cookies I have e...    0.545966\n",
      "0  Good Quality Dog Food. I have bought several o...    0.195261\n",
      "1  Not as Advertised. Product arrived labeled as ...    0.129095\n",
      "4  Just okay. The product was neither great nor b...    0.079523\n",
      "3  Terrible customer service. The product was oka...    0.065597\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input=[text], model=model).data[0].embedding\n",
    "\n",
    "def find_similar_reviews(query, df, model=\"text-embedding-3-small\"):\n",
    "    query_embedding = get_embedding(query, model=model)\n",
    "    df['similarity'] = df.embedding.apply(lambda x: np.dot(query_embedding, x) / (np.linalg.norm(query_embedding) * np.linalg.norm(x)))\n",
    "    similar_reviews = df.sort_values('similarity', ascending=False)\n",
    "    return similar_reviews\n",
    "\n",
    "# 查詢範例\n",
    "query = \"best cookies\"\n",
    "similar_reviews = find_similar_reviews(query, df)\n",
    "print(similar_reviews[['combined', 'similarity']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 聚類 Clustering\n",
    "\n",
    "將相似的文本分組，以使用 `K-means` 或 `DBSCAN` 等算法來實現。\n",
    "\n",
    "`pip install scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            combined  cluster\n",
      "0  Good Quality Dog Food. I have bought several o...        0\n",
      "1  Not as Advertised. Product arrived labeled as ...        2\n",
      "2  Delicious. These are the best cookies I have e...        0\n",
      "3  Terrible customer service. The product was oka...        1\n",
      "4  Just okay. The product was neither great nor b...        1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 假設 df 中的嵌入向量列名為 'embedding'\n",
    "embeddings = np.array(df['embedding'].tolist())\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(embeddings)\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "print(df[['combined', 'cluster']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推薦 Recommendations\n",
    "\n",
    "根據用戶的興趣推薦相似的內容，可以使用餘弦相似度來實現。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            combined  similarity\n",
      "0  Good Quality Dog Food. I have bought several o...    1.000000\n",
      "4  Just okay. The product was neither great nor b...    0.240480\n",
      "2  Delicious. These are the best cookies I have e...    0.199340\n",
      "1  Not as Advertised. Product arrived labeled as ...    0.164630\n",
      "3  Terrible customer service. The product was oka...    0.123355\n"
     ]
    }
   ],
   "source": [
    "def recommend_similar_items(item_index, df):\n",
    "    item_embedding = df.iloc[item_index]['embedding']\n",
    "    df['similarity'] = df.embedding.apply(lambda x: np.dot(item_embedding, x) / (np.linalg.norm(item_embedding) * np.linalg.norm(x)))\n",
    "    recommended_items = df.sort_values('similarity', ascending=False)\n",
    "    return recommended_items\n",
    "\n",
    "# 假設推薦與第一條評論相似的項目\n",
    "recommended_items = recommend_similar_items(0, df)\n",
    "print(recommended_items[['combined', 'similarity']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 異常檢測 Anomaly Detection\n",
    "\n",
    "識別與大多數文本不同的異常點，可以使用 Isolation Forest 或 One-Class SVM 來實現。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            combined  anomaly  anomaly_score\n",
      "0  Good Quality Dog Food. I have bought several o...        1       0.034910\n",
      "1  Not as Advertised. Product arrived labeled as ...        1       0.040418\n",
      "2  Delicious. These are the best cookies I have e...        1       0.017985\n",
      "3  Terrible customer service. The product was oka...        1       0.036293\n",
      "4  Just okay. The product was neither great nor b...        1       0.055233\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "embeddings = np.array(df['embedding'].tolist())\n",
    "clf = IsolationForest(random_state=0).fit(embeddings)\n",
    "df['anomaly_score'] = clf.decision_function(embeddings)\n",
    "df['anomaly'] = clf.predict(embeddings)\n",
    "\n",
    "print(df[['combined', 'anomaly', 'anomaly_score']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多樣性測量 Diversity Measurement\n",
    "\n",
    "分析文本之間的相似性分佈，可以通過計算嵌入向量之間的距離分佈來實現。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Matrix:\n",
      " [[0.         0.8353697  0.80065967 0.87664512 0.75951974]\n",
      " [0.8353697  0.         0.88520441 0.62127699 0.73445364]\n",
      " [0.80065967 0.88520441 0.         0.88961617 0.88532285]\n",
      " [0.87664512 0.62127699 0.88961617 0.         0.4774982 ]\n",
      " [0.75951974 0.73445364 0.88532285 0.4774982  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "embeddings = np.array(df['embedding'].tolist())\n",
    "distance_matrix = squareform(pdist(embeddings, metric='cosine'))\n",
    "\n",
    "print(\"Distance Matrix:\\n\", distance_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分類 Classification\n",
    "\n",
    "根據最相似的標籤對文本進行分類，可以使用邏輯迴歸、支持向量機或神經網絡等分類器來實現。\n",
    "\n",
    "為 DataFrame 添加一個 label 列，可以用來標記每個評論的情感，比如 `正面（1）` 或`負面（0）`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "交叉驗證分數:  [0.5 0.5 1. ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         3\n",
      "   macro avg       1.00      1.00      1.00         3\n",
      "weighted avg       1.00      1.00      1.00         3\n",
      "\n",
      "新文本的預測標籤為: 1\n",
      "新文本的預測標籤為: 0\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 載入環境變數\n",
    "load_dotenv()\n",
    "\n",
    "# 從環境變數中取得 API 密鑰\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input=[text], model=model).data[0].embedding\n",
    "\n",
    "# 增加更多的訓練數據\n",
    "df = pd.DataFrame({\n",
    "    'combined': [\n",
    "        '優質狗糧。 我買了幾款 Vitality 罐裝狗糧產品，發現它們的品質都很好。 該產品看起來更像是燉菜，而不是加工過的肉，而且味道更好。 我的拉布拉多很挑剔，她比大多數人都更欣賞這個產品。',\n",
    "        '不像廣告中那樣。 產品到達時標記為巨型鹹花生……花生實際上是小尺寸的未加鹽的。 供應商拒絕退還我購買的商品或向我發送正確的產品。',\n",
    "        '可口的。 這是我吃過的最好的餅乾！ 我強烈推薦給所有喜歡巧克力的人。',\n",
    "        '糟糕的客戶服務。 產品還可以，但客戶服務很糟糕。 我不會再從這家公司購買產品。',\n",
    "        '就這樣吧。 該產品既不好也不壞。 沒關係。 如果沒有更好的選擇，我可能會再次購買。',\n",
    "        '非常滿意的購物體驗。 產品質量很高，物流也很快。',\n",
    "        '糟糕的產品質量。 產品不到一周就壞了，我很失望。',\n",
    "        '超級好吃的零食。 每次吃都讓我很開心，真是太棒了。',\n",
    "        '客戶服務非常棒。 他們非常熱心，解決了我的所有問題。',\n",
    "        '我很失望。 產品與描述不符，我不會再購買了。',\n",
    "        '這是我吃過的最好的一頓飯。 我真的很喜歡。',\n",
    "        '這是我見過的最糟糕的產品。 我再也不會買了。',\n",
    "        '味道很好。 我會再次購買。',\n",
    "        '質量很差。 我很不滿意。'\n",
    "    ],\n",
    "    'label': [1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0]  # 添加更多的標籤：1 表示正面評論，0 表示負面評論\n",
    "})\n",
    "\n",
    "# 將文本轉換為嵌入\n",
    "df['embedding'] = df.combined.apply(lambda x: get_embedding(x, model='text-embedding-3-small'))\n",
    "\n",
    "# 分割數據集為訓練集和測試集\n",
    "X = np.array(df['embedding'].tolist())\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 使用邏輯迴歸進行分類\n",
    "clf = LogisticRegression(random_state=0)\n",
    "# 使用交叉驗證來評估模型性能，使用 StratifiedKFold 來確保每個折中的類別分布均勻\n",
    "cv = StratifiedKFold(n_splits=3)\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=cv)\n",
    "print(\"交叉驗證分數: \", cv_scores)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 顯示分類報告\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 定義一個函數來預測新文本的分類\n",
    "def classify_new_text(text):\n",
    "    # 將新文本轉換為嵌入\n",
    "    embedding = get_embedding(text, model='text-embedding-3-small')\n",
    "    # 使用訓練好的模型進行預測\n",
    "    prediction = clf.predict([embedding])\n",
    "    return prediction[0]\n",
    "\n",
    "# 新文本範例\n",
    "# new_text_1 = \"這款產品真的很棒，我會再次購買。\"\n",
    "new_text_1 = \"我覺得這款產品還不錯耶。\"\n",
    "# new_text_0 = \"這款產品真的不太好，我不會再買了。\"\n",
    "new_text_0 = \"這款產品有點讓人不太滿意。\"\n",
    "predicted_label_1 = classify_new_text(new_text_1)\n",
    "predicted_label_0 = classify_new_text(new_text_0)\n",
    "print(f\"新文本的預測標籤為: {predicted_label_1}\")\n",
    "print(f\"新文本的預測標籤為: {predicted_label_0}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envStllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
