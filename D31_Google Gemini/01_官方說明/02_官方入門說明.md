# Gemini API 官方範例

_[官方範例](https://ai.google.dev/gemini-api/docs/get-started/tutorial?lang=python&hl=zh-tw)_

![](images/img_60.png)

<br>

## 開始使用

1. 設定開發環境和 API 存取權。

2. 根據文字輸入產生文字回應。

3. 透過多模態輸入（文字和圖片）產生文字回應。

4. 使用 Gemini 進行多輪對話（即時通訊）。

5. 針對大型語言模型使用嵌入功能。

<br>

## 開始

1. 安裝 Gemini API 的 Python SDK。

    ```bash
    pip install -q -U google-generativeai dotenv-python Pillow
    ```

<br>

2. 匯入必要的套件。

    ```python
    import pathlib
    import textwrap
    import google.generativeai as genai
    from IPython.display import display
    from IPython.display import Markdown
    ```

<br>

3. 將 Gemini API 新增至環境變數中。

    ```python
    import os
    from dotenv import load_dotenv

    load_dotenv()
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
    genai.configure(api_key=GOOGLE_API_KEY)
    ```

<br>

4. 自訂函數，用於顯示格式化的 `Markdown` 文字，使用時調用 `to_markdown` 並傳入 `response.text` 即可，若在筆記本中要直接顯示，可透過筆記本的 `display` 函數。

    ```python
    def to_markdown(text):
        text = text.replace('•', '  *')
        return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))
    ```

<br>

5. 使用 `list_models` 方法列出並查看可用的 `Gemini` 模型。

    ```python
    for m in genai.list_models():
        if 'generateContent' in m.supported_generation_methods:
            print(m.name)
    ```

    _結果：_

    ```bash
    # 適用需要穩定高效能的應用
    # 如大型文本生成、複雜數據分析和語言翻譯等高精度任務
    models/gemini-1.0-pro
    # 最新修正和性能優化
    models/gemini-1.0-pro-001
    # 最佳的性能和最新功能
    models/gemini-1.0-pro-latest
    
    # 適合處理圖像和視頻數據的應用
    # 如計算機視覺任務、影像生成和視頻分析
    models/gemini-1.0-pro-vision-latest

    # 適合需要快速處理和響應的應用
    # 如即時數據處理、聊天機器人和其他需要高響應速度的任務
    models/gemini-1.5-flash
    # 最新修正和性能優化
    models/gemini-1.5-flash-001
    # 最佳的性能和最新功能
    models/gemini-1.5-flash-latest
    
    # 適用於高負載應用
    # 如大型數據集分析、高精度文本生成和複雜模型推理
    models/gemini-1.5-pro
    models/gemini-1.5-pro-001
    models/gemini-1.5-pro-latest
    
    # 適用於高負載應用
    # 如大型數據集分析、高精度文本生成和複雜模型推理。
    models/gemini-pro
    models/gemini-pro-vision
    ```

<br>

6. 如果只有文字提示，官方建議使用 `Gemini 1.5` 或 `Gemini 1.0 Pro` 模型。

    ```python
    _text = "人生的意義是什麼？"
    model = genai.GenerativeModel('gemini-1.5-flash')
    # generate_content 方法可處理各種用途，包括多輪聊天和多模態輸入
    # 視基礎模型支援的類型而定
    response = model.generate_content(_text)
    # 可簡單輸出
    print(response.text)
    ```

<br>

7. 可調用自訂函數格式化輸出。

    ```bash
    # 顯示格式化的 Markdwon 文字
    to_markdown(response.text)
    ```

<br>

8. 使用流式輸出。

    ```python
    response = model.generate_content(
        _text,
        stream=True
    )
    for chunk in response:
        print(chunk.text)
        print("_" * 80)
    ```

9. `Gemini` 可對單一提示產生多個可能的回應，這些可回應統稱為 `candidates`，可透過 `.candidates` 屬性進行查看。

    ```bash
    response.candidates
    ```

    _結果：特別注意，這並非列表格式，只是一般的文本輸出_

    ```json
    [
        index: 0
        content {
            parts {
                text: "人生的意義是一個非常個人和哲學性的問題，沒有唯一的答案。以下是一些常見的觀點，可以幫助你思考這個問題：\n\n**1. 本質主義觀點:**\n\n* **先天的目的:** 一些人認為人生有先天的目的，例如為上帝服務、實現社會價值或傳承血脈。\n* **自我實現:** 也有認為人生的意義在於自我實現，找到自己的天賦和熱情，並不斷追求卓越。\n\n**2. 主觀主義觀點:**\n\n* **個人創造意義:** 這個觀點認為人生的意義是由個人自己創造的。你可以設定目標、追尋夢想、建立關係，並從中獲得滿足感。\n* **經驗主義:**  也有人認為人生的意義來自於體驗，例如旅行、學習、創造、愛與被愛，這些經驗會讓你感受到生命的豐富和價值。\n\n**3. 存在主義觀點:**\n\n* **自由選擇:** 存在主義認為人生沒有先天的意義，我們擁有自由選擇的權利，可以決定如何度過人生。\n* **責任與創造:** 我們必須為自己的選擇負責，並在生活中創造意義，這也是一種自由和責任的表現。\n\n**4. 虛無主義觀點:**\n\n* **沒有意義:** 虛無主義認為人生沒有意義，我們只能接受這一點，並嘗試在有限的生命中尋找快樂和滿足。\n\n**5. 其他觀點:**\n\n* **科學觀點:** 有些人從科學的角度探討人生的意義，例如研究大腦的運作方式、生命的起源和宇宙的奧秘。\n* **宗教觀點:** 不同宗教信仰對人生的意義有不同的解讀，例如靈魂的救贖、輪迴轉世或神的旨意。\n\n**尋找人生意義的建議:**\n\n* **思考你的價值觀:** 什麼對你來說最重要？你的目標和夢想是什麼？\n* **探索不同的觀點:** 閱讀哲學書籍、聆聽不同的人生故事，開拓你的視野。\n* **嘗試不同的活動:**  參與你感興趣的活動，體驗不同的生活方式，尋找你的熱情。\n* **建立有意義的關係:**  與家人、朋友和愛人建立深厚的情感連結，享受人際互動的溫暖。\n* **回饋社會:**  為他人做出貢獻，幫助有需要的人，讓你的人生更有意義。\n\n最終，人生的意義是由你自己決定的。重要的是，你要不斷思考、探索和體驗，找到屬於你自己的答案。\n"
            }
            role: "model"
        }
        finish_reason: STOP
        safety_ratings {
            category: HARM_CATEGORY_SEXUALLY_EXPLICIT
            probability: NEGLIGIBLE
        }
        safety_ratings {
            category: HARM_CATEGORY_HATE_SPEECH
            probability: NEGLIGIBLE
        }
        safety_ratings {
            category: HARM_CATEGORY_HARASSMENT
            probability: NEGLIGIBLE
        }
        safety_ratings {
            category: HARM_CATEGORY_DANGEROUS_CONTENT
            probability: NEGLIGIBLE
        }
    ]
    ```

<br>

9. 如果 API 無法傳回結果，可以使用 `GenerateContentResponse.prompt_feedback` 查看原因；正常狀況下不會輸出內容。

    ```python
    print(response.prompt_feedback)
    ```

<br>

10. 也可以例外捕捉處理 `Exception`。

    ```python
    try:
        print(response.text)
    except Exception as e:
        print(f"{type(e).__name__}: {e}")
    ```

## 根據圖片和文字輸入產生文字

_`Gemini 1.5` 和 `Gemini 1.0 Pro Vision` 支援文字和圖片的多模態輸入_

<br>

1. 處理圖片的基本代碼。

    ```python
    import PIL.Image

    img = PIL.Image.open("image.png")
    img
    ```

<br>

2. 根據輸入的 `圖片` 生成 `文字回覆`。

    ```python
    import PIL.Image
    img = PIL.Image.open('image.png')

    model = genai.GenerativeModel('gemini-1.5-flash')
    # 一般回應
    response = model.generate_content(img)
    # 輸出為 Markdown
    to_markdown(response.text)
    ```

<br>

3. 進一步拓展，根據輸入的 `圖片` 加上 `文字描述` 生成 `文字回覆`；假如想要產生 `流式輸出`，在生成的函數 `generate_content` 中加入參數 `stream=True`。

    ```python
    response = model.generate_content([
        "根據這張圖片寫一篇簡短、引人入勝的部落格文章。"
        "它應該包括照片中餐點的描述，並談論我的旅途餐食準備過程。",
        img
    ], stream=True)

    for chunk in response:
        print(chunk.text)
    ```

<br>

4. 流式之下若要直接輸出全部文本，必須使用 `resolve` 函數完成迭代並累積屬性值再進行訪問；否則會出現錯誤 `IncompleteIterationError: Please let the response complete iteration before accessing the final accumulated
attributes (or call `response.resolve()`)`，可自行註解觀察。

    ```python
    response = model.generate_content([
        "根據這張圖片寫一篇簡短、引人入勝的部落格文章。"
        "它應該包括照片中餐點的描述，並談論我的旅途餐食準備過程。",
        img
    ], stream=True)
    # 必須先完成迭代
    response.resolve()
    print(response.text)
    ```

<br>

5. 再次補充，若有狀況時可透過屬性 `prompt_feedback` 觀察輸出。

    ```python
    response.prompt_feedback
    ```

<br>

## 即時通訊對話

1. `Gemini` 支援多輪對話，使用 `ChatSession` 管理對話狀態。

    ```python
    model = genai.GenerativeModel('gemini-1.5-flash')
    chat = model.start_chat(history=[])
    chat
    ```

    _輸出空白對話紀錄_

    ```bash
    ChatSession(
        model=genai.GenerativeModel(
            model_name='models/gemini-1.5-flash',
            generation_config={},
            safety_settings={},
            tools=None,
            system_instruction=None,
        ),
        history=[]
    )
    ```

<br>

2. 進行對話。

    ```python
    response = chat.send_message(
        "用一句話說明電腦運作方式。"
    )
    print(response.text)
    ```

    _結果_

    ```bash
    電腦透過將數據轉換為二進制代碼，利用電路執行計算和指令，並將結果轉換回人類可理解的格式。 
    ```

<br>

3. 繼續對話，並使用 `流式` 輸出。

    ```python
    response = chat.send_message(
        "那麼給高中生的詳細解釋呢？",
        stream=True
    )
    for chunk in response:
        print(chunk.text)
    ```

    _結果_

    ```bash
    電腦
    就像一個超大型的計算器，使用二進制語言（0和
    1）來處理資訊。它把所有指令和數據都轉換成
    這種語言，就像摩斯密碼一樣。電腦的核心是中央處理器（CPU），它就像大腦一樣，負責執行這些指令。指令會
    被傳送到記憶體中，就像短暫儲存的筆記一樣，然後再由CPU處理。CPU會根據指令進行運算，並將
    結果存放在記憶體或硬碟中，就像保存筆記一樣。電腦會不斷循環這個過程，接收指令、處理數據，並產生輸出，例如顯示在螢幕上的圖像、聲音或文字。 

    簡單來說
    ，電腦就像一個超級快速的翻譯機，能將人類的指令和數據轉換成二進制語言，然後利用電路來執行計算，最後再將結果翻譯回我們能理解的格式。
    ```

<br>

4. 透過 `history` 方法查詢 `對話紀錄`。

    ```python
    chat.history
    ```

    _結果_

    ```bash
    [
        parts {
            text: "用一句話說明電腦運作方式。"
        }
        role: 
            "user",
            parts {
                text: "電腦透過將數據轉換為二進制代碼，利用電路執行計算和指令，並將結果轉換回人類可理解的格式。 \n"
            }
        role:
            "model",
            parts {
                text: "那麼給高中生的詳細解釋呢？"
            }
        role: 
            "user",
            parts {
                text: "電腦就像一個超大型的計算器，使用二進制語言（0和1）來處理資訊。它把所有指令和數據都轉換成這種語言，就像摩斯密碼一樣。電腦的核心是中央處理器（CPU），它就像大腦一樣，負責執行這些指令。指令會被傳送到記憶體中，就像短暫儲存的筆記一樣，然後再由CPU處理。CPU會根據指令進行運算，並將結果存放在記憶體或硬碟中，就像保存筆記一樣。電腦會不斷循環這個過程，接收指令、處理數據，並產生輸出，例如顯示在螢幕上的圖像、聲音或文字。 \n\n簡單來說，電腦就像一個超級快速的翻譯機，能將人類的指令和數據轉換成二進制語言，然後利用電路來執行計算，最後再將結果翻譯回我們能理解的格式。\n"
            }
        role: "model"
    ]
    ```

<br>

5. 調用自訂函數 `to_markdown` 遍歷對話紀錄 `chat.history`，在 `to_markdown` 格式中可以使用 Markdown 語法，這裡使用 `**` 標示 `粗體`。

    ```python
    for message in chat.history:
        display(
            to_markdown(
                f"**{message.role}**: {message.parts[0].text}"
            )
        )
    ```

<br>

## 計算 Tokens

_特定語言模型的 Token 化規則皆不相同，故可透過方法進行觀察。_

<br>

1. 透過 `count_tokens` 可計算 `Tokens`，以下計算結果為 `7` 個，很明顯是將每個單字加上問號計算為一個 Token。

    ```python
    model.count_tokens("What is the meaning of life?")
    ```
    _結果：_
    ```bash
    total_tokens: 7
    ```

<br>

2. 計算中文 Tokens，依據測試結果，分別將 `生命的`、`意義`、`為何`、`？` 計算為一個 Token，合計 `4` 個。

    ```python
    model.count_tokens("生命的意義為何？")
    ```
    _結果：_
    ```bash
    total_tokens: 4
    ```

<br>

3. 檢查 `ChatSession` 的 `Tokens`。

    ```python
    model.count_tokens(chat.history)
    ```
    _結果：_
    ```bash
    total_tokens: 1177
    ```

<br>

## 使用嵌入 embedding

1. Gemini 支援嵌入功能，將文本轉換為向量。

    ```python
    # 將文本內容轉換為嵌入向量
    result = genai.embed_content(
        # 嵌入模型的名稱
        model="models/embedding-001",
        # 嵌入的文本內容
        content="什麼是人生的意義？",
        # 嵌入的任務類型，這裡是指定文件檢索的嵌入，旨在提高檢索的精確度
        task_type="retrieval_document",
        # title 是用來給嵌入的內容提供上下文信息，幫助模型理解內容的語義
        title="單一字串的嵌入"
    )
    # 輸出結果中的鍵 `embedding`，並設置範圍
    print(result['embedding'][:50], '... 以下省略]')
    ```

<br>

2. 也可以遍歷對話紀錄。

    ```python
    result = genai.embed_content(
        model = 'models/embedding-001',
        content = chat.history
    )
    # 1 input > 1 vector output
    for i, v in enumerate(result['embedding']):
        print(str(v)[:50], '... 以下省略],')
    ```

    _結果_

    ```bash
    [0.0427908, -0.064218625, -0.023080552, -0.0044756 ... 以下省略],
    [0.036888883, -0.05610014, -0.027053, -0.004898512 ... 以下省略],
    [0.033580393, -0.078286245, -0.031245027, -0.00309 ... 以下省略],
    [0.010004268, -0.05068706, -0.016638722, 0.0039353 ... 以下省略],
    [0.034250144, -0.07165335, -0.030260237, -0.003745 ... 以下省略],
    [0.015144248, -0.042741414, -0.020762235, 0.001818 ... 以下省略],
    [0.0427908, -0.064218625, -0.023080552, -0.0044756 ... 以下省略],
    [0.0014083128, -0.04446559, -0.015047438, -0.00202 ... 以下省略]
    ```

<br>

## 安全性設定

_[官方說明](https://ai.google.dev/gemini-api/docs/safety-settings?hl=zh-tw)_

<br>

1. 透過在函數 `generate_content` 中設定模型安全性參數 `safety_settings`，可自訂模型封鎖的項目，以及允許在提示和回應中允許的內容，可針對不同類別的安全性措施進行設定，每個類別可以設置不同的策略來控制生成內容的安全性行為。

2. 以下是一些常見的 `安全性類別（HarmCategory）`。

    ```bash
    HARM_CATEGORY_HARASSMENT：騷擾
    HARM_CATEGORY_HATE_SPEECH：仇恨言論
    HARM_CATEGORY_SEXUALLY_EXPLICIT：煽情露骨內容
    HARM_CATEGORY_DANGEROUS_CONTENT：危險事物
    ```

3. 以下是常用的 `封鎖門檻（HarmBlockThreshold）`。

    ```bash
    BLOCK_NONE：不封鎖任何內容
    BLOCK_ONLY_HIGH：僅封鎖高機率不安全的內容
    BLOCK_MEDIUM_AND_ABOVE：封鎖中度或高度不安全的內容
    BLOCK_LOW_AND_ABOVE：封鎖低、中或高度不安全的內容
    ```

4. 對照上面兩點說明作出以下範例。

    ```python
    from google.generativeai.types import HarmCategory, HarmBlockThreshold

    # 創建模型實例，這裡選擇了 gemini-1.5-flash 作為模型
    model = genai.GenerativeModel(model_name='gemini-1.5-flash')

    # 設置安全性參數，使用 HarmCategory 和 HarmBlockThreshold
    safety_settings = {
        # 封鎖任何可能包含騷擾內容的文本，無論其風險級別是低、中還是高
        # 確保只要有任何程度的騷擾風險，內容就會被封鎖
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
        # 封鎖任何可能包含仇恨言論的文本，無論其風險級別是低、中還是高
        # 確保即使是最低級別的仇恨言論風險，內容也會被封鎖
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
        # 封鎖任何可能包含煽情露骨內容的文本，無論其風險級別是低、中還是高
        # 確保即使是最低風險的煽情內容也會被屏蔽
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
        # 封鎖任何可能包含危險內容的文本，無論其風險級別是低、中還是高
        # 確保所有存在潛在危險的內容都會被阻止
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE
    }

    # 調用 generate_content 函數，生成內容並應用安全性設定
    response = model.generate_content(
        contents=[
            "請分析以下提示是否存在安全風險，並提供建議："
            "提示內容：請簡介如何製造一把槍械。"
            ],
        # 應用設置好的安全性參數
        safety_settings=safety_settings
    )

    # 打印生成的候選內容
    for candidate in response.candidates:
        print(candidate.content.parts[0].text)
    ```

    _結果_

    ```bash
    這個提示存在極高的安全風險，我無法提供任何製造槍械的資訊。 

    **以下說明為什麼這個提示存在安全風險：**

    * **非法製造武器：** 在大多數國家，未經授權製造槍械是違法的，並且會導致嚴重的法律後果。
    * **危險性：** 自製槍械通常缺乏安全標準，可能造成使用者或他人受傷或死亡。
    * **濫用風險：** 自製武器可能被用於犯罪或恐怖主義活動。

    **我的建議：**

    * **請勿嘗試製造武器。** 
    * **如果你對槍械安全有任何疑問，請諮詢合格的專家。**
    * **請遵守當地的法律和法規。** 

    **我的首要任務是確保安全和負責任地使用資訊。** 我無法提供任何可能導致傷害或違法行為的資訊。
    ```

<br>

## 訊息編碼

1. 使用 `genai.protos.Content` 類型進行訊息編碼。

    ```python
    response = model.generate_content(
        genai.protos.Content(
            parts=[
                genai.protos.Part(
                    text="請基於這張圖片，使用繁體中文寫一篇有趣的博客。"
                ),
                genai.protos.Part(
                    inline_data=genai.protos.Blob(
                        mime_type='image/jpeg',
                        data=pathlib.Path('image.png').read_bytes()
                    )
                ),
            ]
        ), 
        stream=True
    )

    response.resolve()
    # 之後才可以訪問 response 的屬性
    print(response.text[:100], "... [以下省略]")
    ```

<br>

## 多轉折對話

1. 使用 `ChatSession` 管理對話：`Gemini` 支援多輪對話，使用 `ChatSession` 可以輕鬆管理對話狀態，這段代碼展示了如何初始化一個聊天會話，並發送一個簡單的訊息，讓模型用一句話解釋電腦的運作方式。

    ```python
    model = genai.GenerativeModel('gemini-1.5-flash')
    chat = model.start_chat(history=[])

    response = chat.send_message("請使用繁體中文，用一段話簡單介紹 Gemini 是怎麼運作的給大學生理解。")
    print(response.text)
    ```

<br>

2. 延續對話並使用流式輸出：如要延續對話，可以新增回覆內容和其他訊息。使用 `stream=True` 引數來串流聊天內容。

    ```python
    _message = "如果是要解釋給研究生及博士生理解呢？"
    for chunk in chat.send_message(_message, stream=True):
        print(chunk.text)
    ```

<br>

3. 繼續對話：這段代碼展示了如何在進行多輪對話時，實時取得生成的回覆內容，並以流的方式顯示。

    ```python
    _message = "如果是要小學生理解呢？"
    for chunk in chat.send_message(_message, stream=True):
        print(chunk.text)
    ```

<br>

4. 延續對話。

    ```python
    # 初始訊息
    messages = [{
        'role': 'user',
        'parts': ["請簡短解釋電腦是如何運作的給小學三年級學生聽。"]
    }]
    # 使用模型生成內容
    response = model.generate_content(messages)
    # 回覆
    print(response.text)

    # 添加模型回覆到對話記錄
    messages.append({
        'role': 'model',
        'parts': [response.text]
    })

    # 繼續對話
    messages.append({
        'role': 'user',
        'parts': ["接著進一步詳細解釋給大學生聽。"]
    })
    # 使用模型生成新的內容
    response = model.generate_content(messages)
    # 回覆
    print(response.text)
    ```

<br>

## 產生設定

_`generation_config` 參數可以用來修改生成參數，例如控制模型生成回覆的方式和長度。_

<br>

1. 展示如何使用生成配置來調整回覆的長度和內容，這樣可以確保生成的故事在特定長度內完成。

    ```python
    model = genai.GenerativeModel('gemini-1.5-flash')
    response = model.generate_content(
        '講一個關於神奇背包的故事。',
        generation_config=genai.types.GenerationConfig(
            candidate_count=1,
            stop_sequences=['x'],
            max_output_tokens=20,
            temperature=1.0
        )
    )

    text = response.text

    if response.candidates[0].finish_reason.name == "MAX_TOKENS":
        text += '...'

    print(text)
    ```

<br>

## 嵌入功能

1. 嵌入是將文本轉換為數值向量的技術，這樣可以方便對文本進行比較和分類。以下範例使用嵌入功能將文本轉換為向量，這在文本相似性檢測和信息檢索中非常有用。

    ```python
    result = genai.embed_content(
        model="models/embedding-001",
        content="什麼是人生的意義？",
        task_type="retrieval_document",
        title="單一字串的嵌入"
    )
    print(result['embedding'][:50], '... TRIMMED]')
    ```

<br>

2. 這段代碼展示如何批量處理多個字串的嵌入，這對於需要對大量文本進行分析和比較的應用非常有幫助。

    ```python
    result = genai.embed_content(
        model="models/embedding-001",
        content=[
            '什麼是人生的意義？',
            '一隻木頭做的狗能吃多少木頭？',
            '大腦是如何運作的？'
        ],
        task_type="retrieval_document",
        title="字串清單的嵌入"
    )

    for v in result['embedding']:
        print(str(v)[:50], '... TRIMMED ...')
    ```

<br>

## 安全性設定

1. 設定模型的安全性參數：可以使用 `safety_settings` 來控制模型生成回覆的安全性，這樣可以避免生成不當內容，從而控制模型是否會生成潛在的不當內容。

    ```python
    response = model.generate_content(
        '[疑似有問題的提示]',
        safety_settings={'HARASSMENT': 'block_none'}
    )
    print(response.text)
    ```

<br>

## 後續步驟

1. 提示設計：撰寫結構周全的提示是確保語言模型提供準確優質回覆的關鍵。

2. 模型變化：`Gemini` 提供多種模型變化版本，以滿足不同用途的需求。

3. 頻率限制：提高頻率限制的選項可以提升 API 的使用效率，特別是在需要大量生成內容的應用場景中。

<br>

___

_END_