# Gemini API 官方範例

_[官方範例](https://ai.google.dev/gemini-api/docs/get-started/tutorial?lang=python&hl=zh-tw)_

![](images/img_60.png)

<br>

## 開始使用

1. 設定開發環境和 API 存取權。

2. 根據文字輸入產生文字回應。

3. 透過多模態輸入（文字和圖片）產生文字回應。

4. 使用 Gemini 進行多輪對話（即時通訊）。

5. 針對大型語言模型使用嵌入功能。

<br>

## 開始

1. 安裝 Gemini API 的 Python SDK。

    ```bash
    pip install -q -U google-generativeai dotenv-python Pillow
    ```

<br>

2. 匯入必要的套件。

    ```python
    import pathlib
    import textwrap
    import google.generativeai as genai
    from IPython.display import display
    from IPython.display import Markdown
    ```

<br>

3. 將 Gemini API 新增至環境變數中。

    ```python
    import os
    from dotenv import load_dotenv

    load_dotenv()
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
    genai.configure(api_key=GOOGLE_API_KEY)
    ```

<br>

4. 自訂函數，用於顯示格式化的 `Markdown` 文字，使用時調用 `to_markdown` 並傳入 `response.text` 即可，若在筆記本中要直接顯示，可透過筆記本的 `display` 函數。

    ```python
    def to_markdown(text):
        text = text.replace('•', '  *')
        return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))
    ```

<br>

5. 使用 `list_models` 方法列出並查看可用的 `Gemini` 模型。

    ```python
    for m in genai.list_models():
        if 'generateContent' in m.supported_generation_methods:
            print(m.name)
    ```

    _結果：_

    ```bash
    # 適用需要穩定高效能的應用
    # 如大型文本生成、複雜數據分析和語言翻譯等高精度任務
    models/gemini-1.0-pro
    # 最新修正和性能優化
    models/gemini-1.0-pro-001
    # 最佳的性能和最新功能
    models/gemini-1.0-pro-latest
    
    # 適合處理圖像和視頻數據的應用
    # 如計算機視覺任務、影像生成和視頻分析
    models/gemini-1.0-pro-vision-latest

    # 適合需要快速處理和響應的應用
    # 如即時數據處理、聊天機器人和其他需要高響應速度的任務
    models/gemini-1.5-flash
    # 最新修正和性能優化
    models/gemini-1.5-flash-001
    # 最佳的性能和最新功能
    models/gemini-1.5-flash-latest
    
    # 適用於高負載應用
    # 如大型數據集分析、高精度文本生成和複雜模型推理
    models/gemini-1.5-pro
    models/gemini-1.5-pro-001
    models/gemini-1.5-pro-latest
    
    # 適用於高負載應用
    # 如大型數據集分析、高精度文本生成和複雜模型推理。
    models/gemini-pro
    models/gemini-pro-vision
    ```

<br>

6. 如果只有文字提示，官方建議使用 `Gemini 1.5` 或 `Gemini 1.0 Pro` 模型。

    ```python
    _text = "人生的意義是什麼？"
    model = genai.GenerativeModel('gemini-1.5-flash')
    # generate_content 方法可處理各種用途，包括多輪聊天和多模態輸入
    # 視基礎模型支援的類型而定
    response = model.generate_content(_text)
    # 可簡單輸出
    print(response.text)
    ```

<br>

7. 可調用自訂函數格式化輸出。

    ```bash
    # 顯示格式化的 Markdwon 文字
    to_markdown(response.text)
    ```

<br>

8. 使用流式輸出。

    ```python
    response = model.generate_content(
        _text,
        stream=True
    )
    for chunk in response:
        print(chunk.text)
        print("_" * 80)
    ```

9. `Gemini` 可對單一提示產生多個可能的回應，這些可回應統稱為 `candidates`，可透過 `.candidates` 屬性進行查看。

    ```bash
    response.candidates
    ```

    _結果：特別注意，這並非列表格式，只是一般的文本輸出_

    ```json
    [
        index: 0
        content {
            parts {
                text: "人生的意義是一個非常個人和哲學性的問題，沒有唯一的答案。以下是一些常見的觀點，可以幫助你思考這個問題：\n\n**1. 本質主義觀點:**\n\n* **先天的目的:** 一些人認為人生有先天的目的，例如為上帝服務、實現社會價值或傳承血脈。\n* **自我實現:** 也有認為人生的意義在於自我實現，找到自己的天賦和熱情，並不斷追求卓越。\n\n**2. 主觀主義觀點:**\n\n* **個人創造意義:** 這個觀點認為人生的意義是由個人自己創造的。你可以設定目標、追尋夢想、建立關係，並從中獲得滿足感。\n* **經驗主義:**  也有人認為人生的意義來自於體驗，例如旅行、學習、創造、愛與被愛，這些經驗會讓你感受到生命的豐富和價值。\n\n**3. 存在主義觀點:**\n\n* **自由選擇:** 存在主義認為人生沒有先天的意義，我們擁有自由選擇的權利，可以決定如何度過人生。\n* **責任與創造:** 我們必須為自己的選擇負責，並在生活中創造意義，這也是一種自由和責任的表現。\n\n**4. 虛無主義觀點:**\n\n* **沒有意義:** 虛無主義認為人生沒有意義，我們只能接受這一點，並嘗試在有限的生命中尋找快樂和滿足。\n\n**5. 其他觀點:**\n\n* **科學觀點:** 有些人從科學的角度探討人生的意義，例如研究大腦的運作方式、生命的起源和宇宙的奧秘。\n* **宗教觀點:** 不同宗教信仰對人生的意義有不同的解讀，例如靈魂的救贖、輪迴轉世或神的旨意。\n\n**尋找人生意義的建議:**\n\n* **思考你的價值觀:** 什麼對你來說最重要？你的目標和夢想是什麼？\n* **探索不同的觀點:** 閱讀哲學書籍、聆聽不同的人生故事，開拓你的視野。\n* **嘗試不同的活動:**  參與你感興趣的活動，體驗不同的生活方式，尋找你的熱情。\n* **建立有意義的關係:**  與家人、朋友和愛人建立深厚的情感連結，享受人際互動的溫暖。\n* **回饋社會:**  為他人做出貢獻，幫助有需要的人，讓你的人生更有意義。\n\n最終，人生的意義是由你自己決定的。重要的是，你要不斷思考、探索和體驗，找到屬於你自己的答案。\n"
            }
            role: "model"
        }
        finish_reason: STOP
        safety_ratings {
            category: HARM_CATEGORY_SEXUALLY_EXPLICIT
            probability: NEGLIGIBLE
        }
        safety_ratings {
            category: HARM_CATEGORY_HATE_SPEECH
            probability: NEGLIGIBLE
        }
        safety_ratings {
            category: HARM_CATEGORY_HARASSMENT
            probability: NEGLIGIBLE
        }
        safety_ratings {
            category: HARM_CATEGORY_DANGEROUS_CONTENT
            probability: NEGLIGIBLE
        }
    ]
    ```

<br>

9. 如果 API 無法傳回結果，可以使用 `GenerateContentResponse.prompt_feedback` 查看原因；正常狀況下不會輸出內容。

    ```python
    print(response.prompt_feedback)
    ```

<br>

10. 也可以例外捕捉處理 `Exception`。

    ```python
    try:
        print(response.text)
    except Exception as e:
        print(f"{type(e).__name__}: {e}")
    ```

## 根據圖片和文字輸入產生文字

_`Gemini 1.5` 和 `Gemini 1.0 Pro Vision` 支援文字和圖片的多模態輸入_

<br>

1. 處理圖片的基本代碼。

    ```python
    import PIL.Image

    img = PIL.Image.open("image.png")
    img
    ```

<br>

2. 根據輸入的 `圖片` 生成 `文字回覆`。

    ```python
    import PIL.Image
    img = PIL.Image.open('image.png')

    model = genai.GenerativeModel('gemini-1.5-flash')
    # 一般回應
    response = model.generate_content(img)
    # 輸出為 Markdown
    to_markdown(response.text)
    ```

<br>

3. 進一步拓展，根據輸入的 `圖片` 加上 `文字描述` 生成 `文字回覆`；假如想要產生 `流式輸出`，在生成的函數 `generate_content` 中加入參數 `stream=True`。

    ```python
    response = model.generate_content([
        "根據這張圖片寫一篇簡短、引人入勝的部落格文章。"
        "它應該包括照片中餐點的描述，並談論我的旅途餐食準備過程。",
        img
    ], stream=True)

    for chunk in response:
        print(chunk.text)
    ```

<br>

4. 流式之下若要直接輸出全部文本，必須使用 `resolve` 函數完成迭代並累積屬性值再進行訪問；否則會出現錯誤 `IncompleteIterationError: Please let the response complete iteration before accessing the final accumulated
attributes (or call `response.resolve()`)`，可自行註解觀察。

    ```python
    response = model.generate_content([
        "根據這張圖片寫一篇簡短、引人入勝的部落格文章。"
        "它應該包括照片中餐點的描述，並談論我的旅途餐食準備過程。",
        img
    ], stream=True)
    # 必須先完成迭代
    response.resolve()
    print(response.text)
    ```

<br>

5. 再次補充，若有狀況時可透過屬性 `prompt_feedback` 觀察輸出。

    ```python
    response.prompt_feedback
    ```

<br>

## 多輪對話 `ChatSession`

<br>

1. `Gemini` 支援多輪對話，使用 `ChatSession` 管理對話狀態。

    ```python
    model = genai.GenerativeModel('gemini-1.5-flash')
    chat = model.start_chat(history=[])
    chat
    ```

    _輸出空白對話紀錄_

    ```bash
    ChatSession(
        model=genai.GenerativeModel(
            model_name='models/gemini-1.5-flash',
            generation_config={},
            safety_settings={},
            tools=None,
            system_instruction=None,
        ),
        history=[]
    )
    ```

<br>

2. 進行對話。

    ```python
    response = chat.send_message(
        "請使用繁體中文，用一段話簡單介紹 Gemini 是怎麼運作的給大學生理解。"
    )
    print(response.text)
    ```

    _結果_

    ```bash
    # 後補 
    ```

<br>

3. 繼續對話，並使用 `流式` 輸出。

    ```python
    _message = "如果是要解釋給研究生及博士生理解呢？"
    response = chat.send_message(_message, stream=True)
    for chunk in response:
        print(chunk.text)
    ```

    _結果_

    ```bash
    # 後補
    ```

<br>

4. 透過 `history` 方法查詢 `對話紀錄`。

    ```python
    chat.history
    ```

    _結果_

    ```bash
    # 後補
    ```

<br>

5. 繼續對話，同樣使用 chat.send_message 來發送訊息。

    ```python
    _message = "如果是要小學生理解呢？"
    for chunk in chat.send_message(_message, stream=True):
        print(chunk.text)
    ```

<br>

6. 調用自訂函數 `to_markdown` 遍歷對話紀錄 `chat.history`，在 `to_markdown` 格式中可以使用 Markdown 語法，這裡使用 `**` 標示 `粗體`。

    ```python
    for message in chat.history:
        display(
            to_markdown(
                f"**{message.role}**: {message.parts[0].text}"
            )
        )
    ```

<br>

## 多輪對話 `GenerativeModel.generate_content`

1. 前面提過的 `genai.ChatSession` 提供一個方便的封裝，也就是封裝了 `GenerativeModel.generate_content` 的更高層級接口，可用於處理多輪對話；而直接使用 `GenerativeModel.generate_content` 管理多輪對話可提供更大的控制，適合需要自定義對話歷史管理或特殊處理的情境。

<br>

2. 開啟對話。

    ```python
    # 初始訊息
    messages = [{
        'role': 'user',
        'parts': ["請簡短解釋電腦是如何運作的給小學三年級學生聽。"]
    }]
    # 使用模型生成內容
    response = model.generate_content(messages)
    # 回覆
    print(response.text)

    # 必須手動將模型回覆添加到對話記錄
    messages.append({
        'role': 'model',
        'parts': [response.text]
    })
    ```

<br>

3. 繼續對話。    

    ```python
    # 繼續對話
    messages.append({
        'role': 'user',
        'parts': ["接著進一步詳細解釋給大學生聽。"]
    })
    # 使用模型生成新的內容
    response = model.generate_content(messages)
    # 回覆
    print(response.text)

    # 必須手動將模型回覆添加到對話記錄
    messages.append({
        'role': 'model',
        'parts': [response.text]
    })
    ```

<br>

4. 查看對話紀錄。

    ```python
    messages
    ```

    _結果_

    ```bash
    [
        {
            'role': 'user',
            'parts': ['請簡短解釋電腦是如何運作的給小學三年級學生聽。']
        },
        {
            'role': 'model',
            'parts': ['想像一下，電腦就像一個超級聰明的機器人，...（省略）']
        },
        {
            'role': 'user',
            'parts': ['接著進一步詳細解釋給大學生聽。']
        },
        {
            'role': 'model',
            'parts': ['電腦運作的基礎是「數位邏輯」，...（省略）']
        }
    ]
    ```

<br>

## 計算 Tokens

_特定語言模型的 Token 化規則皆不相同，故可透過方法進行觀察。_

<br>

1. 透過 `count_tokens` 可計算 `Tokens`，以下計算結果為 `7` 個，很明顯是將每個單字加上問號計算為一個 Token。

    ```python
    model.count_tokens("What is the meaning of life?")
    ```
    _結果：_
    ```bash
    total_tokens: 7
    ```

<br>

2. 計算中文 Tokens，依據測試結果，分別將 `生命的`、`意義`、`為何`、`？` 計算為一個 Token，合計 `4` 個。

    ```python
    model.count_tokens("生命的意義為何？")
    ```
    _結果：_
    ```bash
    total_tokens: 4
    ```

<br>

3. 檢查 `ChatSession` 的 `Tokens`。

    ```python
    model.count_tokens(chat.history)
    ```
    _結果：_
    ```bash
    total_tokens: 1177
    ```

<br>

## 使用嵌入 embedding

1. Gemini 支援嵌入功能，這是將 `文本` 轉換為 `數值向量` 的技術，這樣可方便對文本進行比較和分類。

    ```python
    # 將文本內容轉換為嵌入向量
    result = genai.embed_content(
        # 嵌入模型的名稱
        model="models/embedding-001",
        # 嵌入的文本內容
        content="什麼是人生的意義？",
        # 嵌入的任務類型，這裡是指定文件檢索的嵌入，旨在提高檢索的精確度
        task_type="retrieval_document",
        # title 是用來給嵌入的內容提供上下文信息，幫助模型理解內容的語義
        title="單一字串的嵌入"
    )
    # 輸出結果中的鍵 `embedding`，並設置範圍
    print(result['embedding'][:50], '... 以下省略]')
    ```

<br>

2. 也可以遍歷並嵌入對話紀錄 `chat.history`。

    ```python
    result = genai.embed_content(
        model = 'models/embedding-001',
        content = chat.history
    )
    # 輸出
    for i, v in enumerate(result['embedding']):
        print(str(v)[:50], '... 以下省略],')
    ```

    _結果_

    ```bash
    [0.0427908, -0.064218625, -0.023080552, -0.0044756 ... 以下省略],
    [0.036888883, -0.05610014, -0.027053, -0.004898512 ... 以下省略],
    [0.033580393, -0.078286245, -0.031245027, -0.00309 ... 以下省略],
    [0.010004268, -0.05068706, -0.016638722, 0.0039353 ... 以下省略],
    [0.034250144, -0.07165335, -0.030260237, -0.003745 ... 以下省略],
    [0.015144248, -0.042741414, -0.020762235, 0.001818 ... 以下省略],
    [0.0427908, -0.064218625, -0.023080552, -0.0044756 ... 以下省略],
    [0.0014083128, -0.04446559, -0.015047438, -0.00202 ... 以下省略]
    ```

<br>

3. 可批量處理多個字串的嵌入，在 `content` 參數中傳遞字串列表。

    ```python
    result = genai.embed_content(
        model="models/embedding-001",
        content=[
            "什麼是生命的意義？",
            "土撥鼠可以丟掉多少木頭？",
            "大腦如何運作？",
        ],
        task_type="retrieval_document",
        title="嵌入字串列表",
    )

    # 輸出
    for v in result["embedding"]:
        print(str(v)[:50], "...以下省略")
    ```

<br>

## 安全性設定

_[官方說明](https://ai.google.dev/gemini-api/docs/safety-settings?hl=zh-tw)_

<br>

1. 透過在函數 `generate_content` 中設定模型安全性參數 `safety_settings`，可自訂模型封鎖的項目，以及允許在提示和回應中允許的內容，可針對不同類別的安全性措施進行設定，每個類別可以設置不同的策略來控制生成內容的安全性行為。

2. 以下是一些常見的 `安全性類別（HarmCategory）`。

    ```bash
    HARM_CATEGORY_HARASSMENT：騷擾
    HARM_CATEGORY_HATE_SPEECH：仇恨言論
    HARM_CATEGORY_SEXUALLY_EXPLICIT：煽情露骨內容
    HARM_CATEGORY_DANGEROUS_CONTENT：危險事物
    ```

<br>

3. 以下是常用的 `封鎖門檻（HarmBlockThreshold）`。

    ```bash
    BLOCK_NONE：不封鎖任何內容
    BLOCK_ONLY_HIGH：僅封鎖高機率不安全的內容
    BLOCK_MEDIUM_AND_ABOVE：封鎖中度或高度不安全的內容
    BLOCK_LOW_AND_ABOVE：封鎖低、中或高度不安全的內容
    ```

<br>

4. 對照上面兩點說明作出以下範例。

    ```python
    from google.generativeai.types import HarmCategory, HarmBlockThreshold

    # 創建模型實例，這裡選擇了 gemini-1.5-flash 作為模型
    model = genai.GenerativeModel(model_name='gemini-1.5-flash')

    # 設置安全性參數，使用 HarmCategory 和 HarmBlockThreshold
    safety_settings = {
        # 封鎖任何可能包含騷擾內容的文本，無論其風險級別是低、中還是高
        # 確保只要有任何程度的騷擾風險，內容就會被封鎖
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
        # 封鎖任何可能包含仇恨言論的文本，無論其風險級別是低、中還是高
        # 確保即使是最低級別的仇恨言論風險，內容也會被封鎖
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
        # 封鎖任何可能包含煽情露骨內容的文本，無論其風險級別是低、中還是高
        # 確保即使是最低風險的煽情內容也會被屏蔽
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,
        # 封鎖任何可能包含危險內容的文本，無論其風險級別是低、中還是高
        # 確保所有存在潛在危險的內容都會被阻止
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE
    }

    # 調用 generate_content 函數，生成內容並應用安全性設定
    response = model.generate_content(
        contents=[
            "請分析以下提示是否存在安全風險，並提供建議："
            "提示內容：請簡介如何製造一把槍械。"
            ],
        # 應用設置好的安全性參數
        safety_settings=safety_settings
    )

    # 打印生成的候選內容
    for candidate in response.candidates:
        print(candidate.content.parts[0].text)
    ```

    _結果_

    ```bash
    這個提示存在極高的安全風險，我無法提供任何製造槍械的資訊。 

    **以下說明為什麼這個提示存在安全風險：**

    * **非法製造武器：** 在大多數國家，未經授權製造槍械是違法的，並且會導致嚴重的法律後果。
    * **危險性：** 自製槍械通常缺乏安全標準，可能造成使用者或他人受傷或死亡。
    * **濫用風險：** 自製武器可能被用於犯罪或恐怖主義活動。

    **我的建議：**

    * **請勿嘗試製造武器。** 
    * **如果你對槍械安全有任何疑問，請諮詢合格的專家。**
    * **請遵守當地的法律和法規。** 

    **我的首要任務是確保安全和負責任地使用資訊。** 我無法提供任何可能導致傷害或違法行為的資訊。
    ```

<br>

## 訊息編碼

1. 使用 `genai.protos.Content` 類型進行訊息編碼。

    ```python
    # 文字描述
    text_part = {
        'text': "請基於這張圖片，使用繁體中文寫一篇有趣的博客。"
    }
    # 圖片
    image_part = {
        'inline_data': {
            'mime_type': 'image/jpeg',
            'data': pathlib.Path('image.png').read_bytes()
        }
    }
    # 調用 generate_content 函數
    response = model.generate_content(
        contents=[{
            'parts': [
                # 文字描述
                text_part,
                # 圖片
                image_part
            ]
        }],
        stream=True
    )
    # 等待並解決流結果
    response.resolve()

    # 輸出生成的文本
    if response.candidates:
        # 確保 response.candidates 不為空
        first_candidate = response.candidates[0]
        if hasattr(first_candidate, 'content') and hasattr(first_candidate.content, 'parts'):
            first_part = first_candidate.content.parts[0]
            if hasattr(first_part, 'text'):
                print(first_part.text[:100], "... [以下省略]")
            else:
                print("在第一部分找不到文字。")
        else:
            print("在第一個候選中找不到內容或部分。")
    else:
        print("沒有找到候選項目。")
    ```

    _結果_

    ```bash
    ##  今天吃什麼？

    「今天午餐吃什麼呢？」，這個問題每天都會在腦海中迴盪。說真的，每天想菜單真的很累人！但是，別擔心，今天我來拯救你！

    看！這兩份精美的便當，是我精心準備的「日式雞肉蔬菜飯」，裡 ... [以下省略]
    ```

<br>

2. 取出指定資料。

    ```python
    response.candidates[0].content
    ```

    _結果_

    ```bash
    parts {
    text: "##  今天吃什麼？\n\n「今天午餐吃什麼呢？」，這個問題每天都會在腦海中迴盪。說真的，每天想菜單真的很累人！但是，別擔心，今天我來拯救你！\n\n看！這兩份精美的便當，是我精心準備的「日式雞肉蔬菜飯」，裡面有白米飯、雞肉、青椒、紅蘿蔔、花椰菜，營養均衡又美味！\n\n雞肉選用的是雞胸肉，肉質鮮嫩不柴，加上特製的醬汁，鹹甜適中，香氣撲鼻。蔬菜部分則是用清炒的方式，保留了蔬菜本身的鮮甜口感。\n\n最重要的是，它們被裝在透明的玻璃盒裡，看起來清爽又健康，絕對可以讓你胃口大開！\n\n你還在猶豫什麼呢？快來試試我的「日式雞肉蔬菜飯」吧！保證讓你食指大動，愛不釋手！\n\n**小提醒:**  \n\n1. 建議搭配筷子食用，更方便快捷。\n2. 也可以依個人喜好添加其他食材，例如香菇、洋蔥等。\n3.  記得把便當盒帶回家，愛護環境從小事做起！"
    }
    role: "model"
    ```

<br>

3. 這就是前面提到的 `嵌入`。

    ```python
    result = genai.embed_content(
        model = 'models/embedding-001',
        content = response.candidates[0].content)

    # 1 input > 1 vector output
    print(str(result['embedding'])[:50], '... [以下省略]')
    ```

    _結果_

    ```bash
    [0.019074494, -0.07096188, -0.019382287, -0.018340 ... [以下省略]
    ```

<br>

## 生成配置 `generation_config`

_`generation_config` 參數可以用來修改生成參數，例如控制模型生成回覆的方式和長度。_

<br>

1. 可使用 `genai.types.GenerationConfig` 建立配置傳遞給參數 `generation_config`，用以調整 `回覆的長度和內容`。

    ```python
    # 建立模型
    model = genai.GenerativeModel('gemini-1.5-flash')
    # 生成文本
    response = model.generate_content(
        '講一個關於神奇背包的故事。',
        # 生成配置
        generation_config=genai.types.GenerationConfig(
            # 指定模型生成的候選文本數量
            candidate_count=1,
            # 指定模型在生成過程中遇到 'x' 字串將停止繼續生成
            stop_sequences=['x'],
            # 模型最多生成 20 個 Token 的內容
            max_output_tokens=20,
            # 使用標準隨機性 `1.0`，數值越高，生成的內容越隨機和多樣
            temperature=1.0
        )
    )

    text = response.text

    if response.candidates[0].finish_reason.name == "MAX_TOKENS":
        text += '...'

    print(text)
    ```

<br>

## 後續步驟

1. 提示設計：撰寫結構周全的提示是確保語言模型提供準確優質回覆的關鍵。

<br>

2. 模型變化：`Gemini` 提供多種模型變化版本，以滿足不同用途的需求。

<br>

3. 頻率限制：提高頻率限制的選項可以提升 API 的使用效率，特別是在需要大量生成內容的應用場景中。

<br>

___

_END_