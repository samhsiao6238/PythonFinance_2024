{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "匯入套件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "import google.generativeai as genai\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "設定 API 金鑰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自訂函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_markdown(text):\n",
    "    text = text.replace('•', '  *')\n",
    "    return Markdown(textwrap.indent(\n",
    "        text, '> ',\n",
    "        predicate=lambda _: True\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "列出模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in genai.list_models():\n",
    "    if \"generateContent\" in m.supported_generation_methods:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根據輸入文字產生文字\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_text = \"人生的意義是什麼？\"\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "# generate_content 方法可處理各種用途，包括多輪聊天和多模態輸入\n",
    "# 視基礎模型支援的類型而定\n",
    "response = model.generate_content(_text)\n",
    "# 可簡單輸出\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 或是顯示格式化的 Markdwon 文字\n",
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用流式輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\n",
    "    _text,\n",
    "    stream=True\n",
    ")\n",
    "for chunk in response:\n",
    "    print(chunk.text)\n",
    "    print(\"_\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini 可以為單一提示產生多個可能的回應。這些可能的回應稱為 candidates，您可以查看這些回應，選取最合適的回應。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.prompt_feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根據圖片和文字輸入產生文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "img = PIL.Image.open('image.png')\n",
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "response = model.generate_content([\n",
    "    \"基於這張圖片寫一篇簡短且引人入勝的博客。\",\n",
    "    img\n",
    "], stream=True)\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.prompt_feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根據圖片和文字輸入產生文字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 處理圖片的基本代碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "\n",
    "img = PIL.Image.open(\"image.png\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "img = PIL.Image.open('image.png')\n",
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "# 一般回應\n",
    "response = model.generate_content(img)\n",
    "# 輸出為 Markdown\n",
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(img)\n",
    "\n",
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content([\n",
    "    \"根據這張圖片寫一篇簡短、引人入勝的部落格文章。\"\n",
    "    \"它應該包括照片中餐點的描述，並談論我的旅途餐食準備過程。\",\n",
    "    img\n",
    "], stream=True)\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用 `resolve` 函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content([\n",
    "    \"根據這張圖片寫一篇簡短、引人入勝的部落格文章。\"\n",
    "    \"它應該包括照片中餐點的描述，並談論我的旅途餐食準備過程。\",\n",
    "    img\n",
    "], stream=True)\n",
    "\n",
    "response.resolve()\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多輪對話 `ChatSession`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "chat = model.start_chat(history=[])\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.send_message(\n",
    "    \"用一句話說明電腦運作方式。\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in chat.send_message(\n",
    "    \"那麼給高中生的詳細解釋呢？\",\n",
    "    stream=True\n",
    "):\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_message = \"請對高中生做更進一步的解釋。\"\n",
    "response = chat.send_message(_message, stream=True)\n",
    "for chunk in response:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in chat.history:\n",
    "    display(to_markdown(f\"**{message.role}**: {message.parts[0].text}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多輪對話 `GenerativeModel.generate_content`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始訊息\n",
    "messages = [{\n",
    "    'role': 'user',\n",
    "    'parts': [\"請簡短解釋電腦是如何運作的給小學三年級學生聽。\"]\n",
    "}]\n",
    "# 使用模型生成內容\n",
    "response = model.generate_content(messages)\n",
    "# 回覆\n",
    "print(response.text)\n",
    "\n",
    "# 添加模型回覆到對話記錄\n",
    "messages.append({\n",
    "    'role': 'model',\n",
    "    'parts': [response.text]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繼續對話\n",
    "messages.append({\n",
    "    'role': 'user',\n",
    "    'parts': [\"接著進一步詳細解釋給大學生聽。\"]\n",
    "})\n",
    "# 使用模型生成新的內容\n",
    "response = model.generate_content(messages)\n",
    "# 回覆\n",
    "print(response.text)\n",
    "\n",
    "# 添加模型回覆到對話記錄\n",
    "messages.append({\n",
    "    'role': 'model',\n",
    "    'parts': [response.text]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "計算符記\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.count_tokens(\"What is the meaning of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.count_tokens(\"生命的意義為何？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 檢查 ChatSession 的 token_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.count_tokens(chat.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下內容會針對文件擷取的單一字串產生嵌入\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = genai.embed_content(\n",
    "    model=\"models/embedding-001\",\n",
    "    content=\"What is the meaning of life?\",\n",
    "    task_type=\"retrieval_document\",\n",
    "    title=\"Embedding of single string\",\n",
    ")\n",
    "\n",
    "# 1 input > 1 vector output\n",
    "print(str(result[\"embedding\"])[:50], \"... 以下省略]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = genai.embed_content(\n",
    "    model = 'models/embedding-001',\n",
    "    content = chat.history\n",
    ")\n",
    "for i, v in enumerate(result['embedding']):\n",
    "    print(str(v)[:50], '... 以下省略],')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 如要處理一批字串，請在 content 中傳遞字串清單"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = genai.embed_content(\n",
    "    model=\"models/embedding-001\",\n",
    "    content=[\n",
    "        \"什麼是生命的意義？\",\n",
    "        \"土撥鼠可以丟掉多少木頭？\",\n",
    "        \"大腦如何運作？\",\n",
    "    ],\n",
    "    task_type=\"retrieval_document\",\n",
    "    title=\"嵌入字串列表\",\n",
    ")\n",
    "\n",
    "# A list of inputs > A list of vectors output\n",
    "for v in result[\"embedding\"]:\n",
    "    print(str(v)[:50], \"...以下省略\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安全性設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "# 創建模型實例，這裡選擇了 gemini-1.5-flash 作為模型\n",
    "model = genai.GenerativeModel(model_name='gemini-1.5-flash')\n",
    "\n",
    "# 設置安全性參數，使用 HarmCategory 和 HarmBlockThreshold\n",
    "safety_settings = {\n",
    "    # 封鎖任何可能包含騷擾內容的文本，無論其風險級別是低、中還是高\n",
    "    # 確保只要有任何程度的騷擾風險，內容就會被封鎖\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "    # 封鎖任何可能包含仇恨言論的文本，無論其風險級別是低、中還是高\n",
    "    # 確保即使是最低級別的仇恨言論風險，內容也會被封鎖\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "    # 封鎖任何可能包含煽情露骨內容的文本，無論其風險級別是低、中還是高\n",
    "    # 確保即使是最低風險的煽情內容也會被屏蔽\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "    # 封鎖任何可能包含危險內容的文本，無論其風險級別是低、中還是高\n",
    "    # 確保所有存在潛在危險的內容都會被阻止\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE\n",
    "}\n",
    "\n",
    "# 調用 generate_content 函數，生成內容並應用安全性設定\n",
    "response = model.generate_content(\n",
    "    contents=[\n",
    "        \"請分析以下提示是否存在安全風險，並提供建議：\"\n",
    "        \"提示內容：請簡介如何製造一把槍械。\"\n",
    "        ],\n",
    "    # 應用設置好的安全性參數\n",
    "    safety_settings=safety_settings\n",
    ")\n",
    "\n",
    "# 打印生成的候選內容\n",
    "for candidate in response.candidates:\n",
    "    print(candidate.content.parts[0].text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訊息編碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文字描述\n",
    "text_part = {\n",
    "    'text': \"請基於這張圖片，使用繁體中文寫一篇有趣的博客。\"\n",
    "}\n",
    "# 圖片\n",
    "image_part = {\n",
    "    'inline_data': {\n",
    "        'mime_type': 'image/jpeg',\n",
    "        'data': pathlib.Path('image.png').read_bytes()\n",
    "    }\n",
    "}\n",
    "\n",
    "# 調用 generate_content 函數\n",
    "response = model.generate_content(\n",
    "    contents=[{\n",
    "        'parts': [\n",
    "            # 文字描述\n",
    "            text_part,\n",
    "            # 圖片\n",
    "            image_part\n",
    "        ]\n",
    "    }],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "# 等待並解決流結果\n",
    "response.resolve()\n",
    "\n",
    "# 輸出生成的文本\n",
    "if response.candidates:\n",
    "    # 確保 response.candidates 不為空\n",
    "    first_candidate = response.candidates[0]\n",
    "    if hasattr(first_candidate, 'content') and hasattr(first_candidate.content, 'parts'):\n",
    "        first_part = first_candidate.content.parts[0]\n",
    "        if hasattr(first_part, 'text'):\n",
    "            print(first_part.text[:100], \"... [以下省略]\")\n",
    "        else:\n",
    "            print(\"在第一部分找不到文字。\")\n",
    "    else:\n",
    "        print(\"在第一個候選中找不到內容或部分。\")\n",
    "else:\n",
    "    print(\"沒有找到候選項目。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.candidates[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = genai.embed_content(\n",
    "    model = 'models/embedding-001',\n",
    "    content = response.candidates[0].content)\n",
    "\n",
    "# 1 input > 1 vector output\n",
    "print(str(result['embedding'])[:50], '... [以下省略]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多輪對話"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "chat = model.start_chat(history=[])\n",
    "\n",
    "response = chat.send_message(\n",
    "    \"請使用繁體中文，用一段話簡單介紹 Gemini 是怎麼運作的給大學生理解。\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_message = \"如果是要解釋給研究生及博士生理解呢？\"\n",
    "for chunk in chat.send_message(_message, stream=True):\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_message = \"如果是要小學生理解呢？\"\n",
    "for chunk in chat.send_message(_message, stream=True):\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同樣地，即時通訊記錄包含 genai.protos.Content 物件清單，您可以將這些物件直接傳遞至 embed_content 函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始訊息\n",
    "messages = [{\n",
    "    'role': 'user',\n",
    "    'parts': [\"請簡短解釋電腦是如何運作的給小學三年級學生聽。\"]\n",
    "}]\n",
    "# 使用模型生成內容\n",
    "response = model.generate_content(messages)\n",
    "# 回覆\n",
    "print(response.text)\n",
    "\n",
    "# 添加模型回覆到對話記錄\n",
    "messages.append({\n",
    "    'role': 'model',\n",
    "    'parts': [response.text]\n",
    "})\n",
    "\n",
    "# 繼續對話\n",
    "messages.append({\n",
    "    'role': 'user',\n",
    "    'parts': [\"接著進一步詳細解釋給大學生聽。\"]\n",
    "})\n",
    "# 使用模型生成新的內容\n",
    "response = model.generate_content(messages)\n",
    "# 回覆\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = genai.embed_content(model=\"models/embedding-001\", content=chat.history)\n",
    "\n",
    "# 1 input > 1 vector output\n",
    "for i, v in enumerate(result[\"embedding\"]):\n",
    "    print(str(v)[:50], \"... TRIMMED...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成配置 generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "# 生成文本\n",
    "response = model.generate_content(\n",
    "    '講一個關於神奇背包的故事。',\n",
    "    # 生成配置\n",
    "    generation_config=genai.types.GenerationConfig(\n",
    "        # 指定模型生成的候選文本數量\n",
    "        candidate_count=1,\n",
    "        # 指定模型在生成過程中遇到 'x' 字串將停止繼續生成\n",
    "        stop_sequences=['x'],\n",
    "        # 模型最多生成 20 個 Token 的內容\n",
    "        max_output_tokens=20,\n",
    "        # 使用標準隨機性 `1.0`，數值越高，生成的內容越隨機和多樣\n",
    "        temperature=1.0\n",
    "    )\n",
    ")\n",
    "\n",
    "text = response.text\n",
    "\n",
    "if response.candidates[0].finish_reason.name == \"MAX_TOKENS\":\n",
    "    text += '...'\n",
    "\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envHaystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
