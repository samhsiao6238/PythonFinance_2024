# 結合 LangChain

<br>

## 說明

1. 以下使用 `Streamlit`、`LangChain` 和 `Google Gemini API` 製作一個文本生成應用的完整範例。

<br>

2. 本範例使用模型為 `gemini-pro`，透過腳本，用戶可輸入文本並獲得來自 `Google Gemini` 的生成回應。

<br>

## 準備工作

1. 使用全新虛擬環境 `envLCG`。

    ```bash
    python -m venv envLCG
    ```

<br>

2. 使用以下命令安裝必要的庫，特別注意，套件 `tenacity` 的當前版本與 `langchain-core` 存在衝突，所以指定較低的版本。

    ```bash
    pip install streamlit langchain-google-genai langchain-core tenacity==8.3.0
    ```

<br>

3. 在桌面建立並進入專案資料夾；說明一下，這裡建立在桌面是因為這僅是用來練習的資料夾，建立在桌面便於隨後刪除。

    ```bash
    cd ~/Desktop && mkdir _exLCG_ && cd _exLCG_
    ```

<br>

## 配置環境變數

_這個範例因為使用了 Streamlit，所以使用相同套件來管理敏感資訊_

<br>

1. 建立資料夾，新增並編輯密鑰文件 `secrets.toml`。

    ```bash
    mkdir -p .streamlit && nano .streamlit/secrets.toml
    ```

<br>

2. 將 [Google Gemini API](https://aistudio.google.com/app/apikey) 金鑰寫入文件中。

    ```bash
    GEMINI_API_KEY = "<填入自己的 API Key>"
    ```

<br>

## Streamlit 應用

1. 建立並編輯 `app.py` 腳本。

    ```bash
    nano app.py
    ```

<br>

2. 在 `app.py` 腳本中貼上以下代碼。

    ```python
    # app.py
    import streamlit as st
    # # 導入 Google Generative AI 聊天模型
    from langchain_google_genai import ChatGoogleGenerativeAI
    # HumanMessage 類，用於建立人類語言的訊息
    # 將輸入轉換為人類語言，提供給模型生成回覆
    from langchain_core.messages import HumanMessage


    # Google Gemini API 金鑰
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    # 檢查是否存在 API 金鑰
    if GEMINI_API_KEY is None:
        # 如果金鑰未設置，顯示錯誤信息
        st.error("環境變數 GEMINI_API_KEY 未設置，請檢查 .env 文件。")
        st.stop()

    # 使用模型
    model_name = "gemini-pro"
    # 建立模型，這個模型將用於生成回覆
    model = ChatGoogleGenerativeAI(
        model=model_name,
        google_api_key=GEMINI_API_KEY
    )

    # 設置 Streamlit 標題
    st.title("Gemini API 文本生成器")

    # 建立文本輸入框讓用戶輸入問題
    user_input = st.text_input("請輸入你的問題：")

    # 當用戶點擊 `生成` 按鈕時執行的操作
    if st.button("生成"):
        if not user_input:
            st.warning("請輸入一些文本。")
        else:
            try:
                # 依據用戶輸入，建立 HumanMessage 實體
                message = HumanMessage(content=user_input)
                # 傳入 `HumanMessage 實體`，並使用模型生成回應文本
                response = model.stream([message])
                # 建立一個空的 Streamlit 元件，以便後續更新輸出
                output_placeholder = st.empty()
                generated_text = ""

                # 使用流式方式逐步顯示生成的文本
                for chunk in response:
                    generated_text += chunk.content
                    output_placeholder.text(generated_text)

                # 顯示成功信息，指示文本生成完成
                st.success("文本生成已完成。")

            except Exception as e:
                st.error(f"發生錯誤： {str(e)}")
    ```

<br>

3. 運行。

    ```bash
    streamlit run app.py
    ```

<br>

4. 透過瀏覽器訪問 `http://localhost:8501`，並輸入查詢文字。

    ![](images/img_03.png)

<br>

5. 流式輸出完成後會顯示。

    ![](images/img_04.png)

<br>

## 關於 `HumanMessage`

1. 目的是將用戶的輸入統一封裝為一個標準化的消息對象，以便模型可以一致地處理所有輸入。

<br>

___

_END_