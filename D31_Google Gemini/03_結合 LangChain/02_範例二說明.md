# 範例

## 說明

1. [參考來源](https://github.com/google/generative-ai-docs/blob/main/examples/gemini/python/langchain/Gemini_LangChain_QA_Chroma_WebLoad.ipynb)。

2. 使用 `Gemini`、`LangChain` 和 `Chroma` 建立一個取得 `網站數據` 生成 `嵌入向量`，並使用這些嵌入向量來 `回答用戶提問` 的應用。

## 主要套件

1. LangChain：一個數據框架，可簡化 `LLM` 的集成。

2. LangChain-Google-GenAI：這是 `LangChain` 的擴展包，用於與 `Google 的生成式 AI 模型（如 Gemini）`進行集成。

3. Chroma：Chroma 客戶端 SDK，這是一個開源的 `嵌入向量資料庫`，允許儲存嵌入向量及其元數據。

4. Streamlit：用於快速建立和部署數據應用的 Python 庫。

## 準備工作

1. 安裝所需套件。

    ```bash
    pip install --quiet langchain langchain-google-genai chromadb
    ```

## 開始撰寫

1. 設置環境變量。

    ```python
    # 導入所需庫
    import os

    # 設置 Google API 金鑰為環境變量
    os.environ["GOOGLE_API_KEY"] = st.secrets["GEMINI_API_KEY"]
    ```

2. 導入必要的庫。

    ```python
    import streamlit as st
    from langchain_google_genai import ChatGoogleGenerativeAI
    from langchain.messages import HumanMessage
    ```

3. 設置 Google Gemini API 金鑰。

    ```python
    # 從 Streamlit 的 secrets 中取得 API 金鑰
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    # 檢查是否設置 API 金鑰
    if GEMINI_API_KEY is None:
        st.error("環境變數 GEMINI_API_KEY 未設置，請檢查 .env 文件。")
        st.stop()
    ```

4. 初始化 Gemini 模型。

    ```python
    # 模型指定為 gemini-pro
    model_name = "gemini-pro"
    
    # 初始化 ChatGoogleGenerativeAI 模型
    model = ChatGoogleGenerativeAI(
        model=model_name,
        google_api_key=GEMINI_API_KEY
    )
    ```

5. 設置 Streamlit 標題。

    ```python
    # 設置應用程序標題
    st.title("Gemini API 文本生成器")
    ```

6. 建立用戶輸入框。

    ```python
    # 建立文本輸入框供用戶輸入問題
    user_input = st.text_input("請輸入你的問題：")
    ```

7. 生成回答。

    ```python
    # 當用戶點擊生成按鈕時執行的操作
    if st.button("生成"):
        if not user_input:
            # 如果用戶未輸入文本，提示輸入
            st.warning("請輸入一些文本。")
        else:
            try:
                # 建立 HumanMessage 實例
                message = HumanMessage(content=user_input)
                
                # 使用模型生成文本
                response = model.stream([message])
                
                # 建立一個空的 Streamlit 元素，以便後續更新輸出
                output_placeholder = st.empty()
                generated_text = ""
                
                # 使用流式方式逐步顯示生成的文本
                for chunk in response:
                    generated_text += chunk.content
                    output_placeholder.text(generated_text)
                
                # 顯示成功信息，指示文本生成完成
                st.success("文本生成已完成。")
            
            except Exception as e:
                # 捕獲錯誤並顯示
                st.error(f"發生錯誤： {str(e)}")
    ```

8. 讀取並解析網站數據。

    ```python
    # 從 langchain 中導入 WebBaseLoader
    from langchain.document_loaders import WebBaseLoader
    
    # 建立網站數據加載器
    loader = WebBaseLoader(
        "https://blog.google/technology/ai/google-gemini-ai/"
    )
    
    # 加載網站數據
    docs = loader.load()
    ```

9. 提取和處理文本內容。

    ```python
    # 提取網站數據中的文本內容
    text_content = docs[0].page_content
    
    # 使用 Python 的 split 方法提取所需文本內容
    text_content_1 = text_content.split(
        "code, audio, image and video.",
        1
    )[1]
    final_text = text_content_1.split("Cloud TPU v5p",1)[0]
    
    # 將提取的文本轉換為 LangChain 的 Document 格式
    docs = [
        Document(
            page_content=final_text,
            metadata={"source": "local"}
        )
    ]
    ```

10. 初始化嵌入模型並生成嵌入向量。

    ```python
    from langchain_google_genai import GoogleGenerativeAIEmbeddings
    
    # 初始化嵌入模型
    gemini_embeddings = GoogleGenerativeAIEmbeddings(
        model="models/embedding-001"
    )
    ```

11. 使用 Chroma 儲存數據。

    ```python
    # 使用 Chroma 建立向量資料庫
    vectorstore = Chroma.from_documents(
        # 數據
        documents=docs,
        # 嵌入模型
        embedding=gemini_embeddings,
        # 保存數據的目錄
        persist_directory="./chroma_db"
    )
    ```

12. 建立檢索器。

    ```python
    # 從磁盤加載向量資料庫
    vectorstore_disk = Chroma(
        # 資料庫目錄
        persist_directory="./chroma_db",
        # 嵌入模型
        embedding_function=gemini_embeddings
    )
    # 建立檢索器
    retriever = vectorstore_disk.as_retriever(
        search_kwargs={"k": 1}
    )
    # 測試檢索器是否正常工作
    print(len(retriever.get_relevant_documents("MMLU")))
    ```

13. 初始化 Gemini 模型並設置參數。

    ```python
    from langchain_google_genai import ChatGoogleGenerativeAI
    
    # 初始化 Gemini 模型，並設置參數如溫度和 top_p
    llm = ChatGoogleGenerativeAI(
        model="gemini-pro",
        temperature=0.7,
        top_p=0.85
    )
    ```

14. 建立提示模板。

    ```python
    # 建立問答提示模板
    llm_prompt_template = """
    你是一位專業的咨詢師。
    請使用以下的上下文來回答問題。
    你的回答請使用繁體中文以及繁體中文用語。
    如果你不知道答案，就說你不知道。
    你的回覆最多不要超過五個句子，並保持答案簡潔。
    \n問題：{question}
    \n上下文：{context}
    \n答案：
    """
    
    # 使用 LangChain 建立 PromptTemplate
    llm_prompt = PromptTemplate.from_template(llm_prompt_template)
    ```

15. 建立文件鏈。

    ```python
    # 定義格式化文件的函數
    def format_docs(docs):
        return "\n\n".join(doc.page_content for doc in docs)
    
    # 建立文件鏈
    rag_chain = (
        {
            "context": retriever | format_docs,
            "question": RunnablePassthrough()
        }
        | llm_prompt
        | llm
        | StrOutputParser()
    )
    ```

16. 使用模型生成答案。

    ```python
    # 對模型進行提問並取得答案
    answer = rag_chain.invoke("請說明什麼是 Google 的 Gemini？")
    
    # 顯示答案
    print(answer)
    ```

<br>

___

_END_