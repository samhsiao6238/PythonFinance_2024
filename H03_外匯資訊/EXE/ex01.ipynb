{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç›´æ¥å–å›å…¨éƒ¨éŠ€è¡ŒæŒ‡å®šåŒ¯ç‡è³‡è¨Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.findrate.tw/USD/\"\n",
    "response = requests.get(url)\n",
    "data = response.text\n",
    "\n",
    "soup = BeautifulSoup(data, 'html.parser')\n",
    "table = soup.find_all('table')[1]\n",
    "\n",
    "# æå–è¨Šæ¯\n",
    "exchange_rates = []\n",
    "# è·³éæ¨™é¡Œè¡Œ\n",
    "for row in table.find_all('tr')[1:]:\n",
    "    cols = row.find_all('td')\n",
    "    # æª¢æŸ¥è¡Œæ˜¯å¦æœ‰é æœŸçš„åˆ—æ•¸\n",
    "    if len(cols) == 7:\n",
    "        exchange_rates.append([col.text.strip() for col in cols])\n",
    "\n",
    "# å»ºç«‹ DataFrame\n",
    "if exchange_rates:\n",
    "    df = pd.DataFrame(\n",
    "        exchange_rates, \n",
    "        columns=[\n",
    "            \"éŠ€è¡Œåç¨±\", \"ç¾éˆ”è²·å…¥\", \"ç¾éˆ”è³£å‡º\", \"å³æœŸè²·å…¥\", \n",
    "            \"å³æœŸè³£å‡º\", \"æ›´æ–°æ™‚é–“\", \"ç¾éˆ”æ‰‹çºŒè²»\"\n",
    "        ]\n",
    "    )\n",
    "    # å„²å­˜åˆ° Excel\n",
    "    df.to_excel(\"ç¾é‡‘åŒ¯ç‡.xlsx\", index=False)\n",
    "else:\n",
    "    print(\"æœªæ‰¾åˆ°è³‡æ–™æˆ–è¡¨æ ¼æ ¼å¼ä¸åŒã€‚\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å„ªåŒ–ä»¥ä¸Šä»£ç¢¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… åŒ¯ç‡è³‡æ–™å·²å„²å­˜è‡³ ç¾é‡‘åŒ¯ç‡_20250220.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ç›®æ¨™ç¶²å€\n",
    "url = \"https://www.findrate.tw/USD/\"\n",
    "\n",
    "# æ·»åŠ  User-Agent é¿å…è¢«é˜»æ“‹\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# ç™¼é€è«‹æ±‚\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# ç¢ºä¿è«‹æ±‚æˆåŠŸ\n",
    "if response.status_code == 200:\n",
    "    data = response.text\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "\n",
    "    # æ‰¾åˆ°æ‰€æœ‰è¡¨æ ¼ï¼Œé¿å…ç´¢å¼•éŒ¯èª¤\n",
    "    tables = soup.find_all('table')\n",
    "    \n",
    "    if len(tables) > 1:\n",
    "        # ç›®æ¨™è¡¨æ ¼\n",
    "        table = tables[1]\n",
    "\n",
    "        # æå–è¨Šæ¯\n",
    "        exchange_rates = []\n",
    "        # è·³éæ¨™é¡Œè¡Œ\n",
    "        for row in table.find_all('tr')[1:]:\n",
    "            cols = row.find_all('td')\n",
    "            # ç¢ºä¿ç¬¦åˆé æœŸæ ¼å¼\n",
    "            if len(cols) == 7:\n",
    "                exchange_rates.append([col.text.strip() for col in cols])\n",
    "\n",
    "        # å»ºç«‹ DataFrame\n",
    "        if exchange_rates:\n",
    "            df = pd.DataFrame(\n",
    "                exchange_rates, \n",
    "                columns=[\n",
    "                    \"éŠ€è¡Œåç¨±\", \"ç¾éˆ”è²·å…¥\", \"ç¾éˆ”è³£å‡º\", \"å³æœŸè²·å…¥\", \n",
    "                    \"å³æœŸè³£å‡º\", \"æ›´æ–°æ™‚é–“\", \"ç¾éˆ”æ‰‹çºŒè²»\"\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # ç”Ÿæˆ Excel æª”æ¡ˆåç¨±\n",
    "            today_str = datetime.now().strftime('%Y%m%d')\n",
    "            excel_filename = f\"ç¾é‡‘åŒ¯ç‡_{today_str}.xlsx\"\n",
    "\n",
    "            # å„²å­˜åˆ° Excel\n",
    "            df.to_excel(excel_filename, index=False)\n",
    "\n",
    "            print(f\"âœ… åŒ¯ç‡è³‡æ–™å·²å„²å­˜è‡³ {excel_filename}\")\n",
    "        else:\n",
    "            print(\"âš ï¸ æœªæ‰¾åˆ°å¯ç”¨çš„åŒ¯ç‡æ•¸æ“šã€‚\")\n",
    "    else:\n",
    "        print(\"âš ï¸ æœªæ‰¾åˆ°ç›®æ¨™è¡¨æ ¼ï¼Œè«‹ç¢ºèªç¶²é çµæ§‹æ˜¯å¦è®Šæ›´ã€‚\")\n",
    "else:\n",
    "    print(f\"âŒ ç„¡æ³•ç²å–æ•¸æ“šï¼ŒHTTP ç‹€æ…‹ç¢¼: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åŠ å…¥æ—¥æœŸ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… åŒ¯ç‡è³‡æ–™å·²å„²å­˜è‡³ ç¾é‡‘åŒ¯ç‡_V2_20250220.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_data():\n",
    "    \"\"\"å¾æŒ‡å®šç¶²ç«™æŠ“å–ç¾é‡‘åŒ¯ç‡æ•¸æ“š\"\"\"\n",
    "    url = \"https://www.findrate.tw/USD/\"\n",
    "\n",
    "    # æ·»åŠ  `User-Agent` ä»¥æ¨¡æ“¬ç€è¦½å™¨ï¼Œé¿å…è«‹æ±‚è¢«é˜»æ“‹\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    # ç™¼é€è«‹æ±‚\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # æª¢æŸ¥è«‹æ±‚æ˜¯å¦æˆåŠŸ\n",
    "    if response.status_code != 200:\n",
    "        print(f\"âŒ ç„¡æ³•å–å¾—æ•¸æ“šï¼ŒHTTP ç‹€æ…‹ç¢¼: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "    # è§£æ HTML å…§å®¹\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # å˜—è©¦æå–æ—¥æœŸè³‡è¨Š\n",
    "    date_info = soup.find('span', style=\"float:right\")\n",
    "    if not date_info:\n",
    "        print(\"âš ï¸ ç„¡æ³•æ‰¾åˆ°æ›´æ–°æ—¥æœŸï¼Œè«‹ç¢ºèªç¶²é çµæ§‹æ˜¯å¦è®Šæ›´ã€‚\")\n",
    "        return []\n",
    "\n",
    "    # è§£ææ—¥æœŸ\n",
    "    date_text = date_info.text.strip().split('æ™‚é–“ï¼š')[-1]\n",
    "    # ç§»é™¤ `-` è½‰ç‚º YYYYMMDD æ ¼å¼\n",
    "    date_str = date_text.replace('-', '')\n",
    "\n",
    "    # æ‰¾åˆ°æ‰€æœ‰è¡¨æ ¼ï¼Œé¿å…ç´¢å¼•éŒ¯èª¤\n",
    "    tables = soup.find_all('table')\n",
    "    if len(tables) < 2:\n",
    "        print(\"âš ï¸ æœªæ‰¾åˆ°ç›®æ¨™è¡¨æ ¼ï¼Œè«‹ç¢ºèªç¶²é çµæ§‹æ˜¯å¦è®Šæ›´ã€‚\")\n",
    "        return []\n",
    "\n",
    "    # ç›®æ¨™è¡¨æ ¼\n",
    "    table = tables[1]\n",
    "\n",
    "    # æå–åŒ¯ç‡æ•¸æ“š\n",
    "    exchange_rates = []\n",
    "    # è·³éæ¨™é¡Œè¡Œ\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        cols = row.find_all('td')\n",
    "        # ç¢ºä¿è¡Œæ•¸ç¬¦åˆé æœŸ\n",
    "        if len(cols) == 7:\n",
    "            row_data = [col.text.strip() for col in cols]\n",
    "\n",
    "            # è™•ç†æ›´æ–°æ™‚é–“ï¼Œç§»é™¤ HTML è¨»è§£ä¸¦åˆä½µæ—¥æœŸ\n",
    "            update_time = BeautifulSoup(row_data[5], \"html.parser\").text\n",
    "            # å®Œæ•´æ™‚é–“è³‡è¨Š\n",
    "            row_data[5] = f\"{date_text} {update_time}\"\n",
    "            exchange_rates.append(row_data)\n",
    "    # å›å‚³æ•¸æ“šèˆ‡æ—¥æœŸå­—ä¸²\n",
    "    return exchange_rates, date_str\n",
    "\n",
    "# æŠ“å–æ•¸æ“š\n",
    "exchange_rates, date_str = fetch_data()\n",
    "\n",
    "if exchange_rates:\n",
    "    # å»ºç«‹ DataFrame\n",
    "    df = pd.DataFrame(\n",
    "        exchange_rates, \n",
    "        columns=[\n",
    "            \"éŠ€è¡Œåç¨±\", \"ç¾éˆ”è²·å…¥\", \"ç¾éˆ”è³£å‡º\", \"å³æœŸè²·å…¥\",\n",
    "            \"å³æœŸè³£å‡º\", \"æ›´æ–°æ™‚é–“\", \"ç¾éˆ”æ‰‹çºŒè²»\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # ç”Ÿæˆ Excel æª”æ¡ˆåç¨±\n",
    "    excel_filename = f\"ç¾é‡‘åŒ¯ç‡_V2_{date_str}.xlsx\"\n",
    "\n",
    "    # å„²å­˜ç‚º Excel æª”æ¡ˆ\n",
    "    df.to_excel(excel_filename, index=False)\n",
    "\n",
    "    print(f\"âœ… åŒ¯ç‡è³‡æ–™å·²å„²å­˜è‡³ {excel_filename}\")\n",
    "else:\n",
    "    print(\"âš ï¸ æ²’æœ‰æ‰¾åˆ°å¯ç”¨çš„æ•¸æ“šã€‚\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»¥ä¸‹æ˜¯å¾æŒ‡å®šéŠ€è¡Œå–å›æŒ‡å®šè³‡è¨Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸç²å–ç¾é‡‘åŒ¯ç‡è³‡è¨Šï¼š\n",
      "['ç¾é‡‘ USD', '32.365', '33.063', '32.68', '32.84']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# æŒ‡å®šæŸ¥è©¢çš„éŠ€è¡Œç¶²å€ï¼ˆç¯„ä¾‹ï¼šå°ç£éŠ€è¡Œï¼‰\n",
    "url = \"https://www.findrate.tw/bank/10/\"\n",
    "\n",
    "# æ·»åŠ  `User-Agent` ä»¥æ¨¡æ“¬ç€è¦½å™¨ï¼Œé¿å…è«‹æ±‚è¢«é˜»æ“‹\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# ç™¼é€è«‹æ±‚\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# æª¢æŸ¥è«‹æ±‚æ˜¯å¦æˆåŠŸ\n",
    "if response.status_code != 200:\n",
    "    print(f\"âŒ ç„¡æ³•å–å¾—æ•¸æ“šï¼ŒHTTP ç‹€æ…‹ç¢¼: {response.status_code}\")\n",
    "else:\n",
    "    # è§£æ HTML å…§å®¹\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # æ‰¾åˆ°åŒ…å«åŒ¯ç‡çš„è¡¨æ ¼\n",
    "    table = soup.find('table', {'width': '725px'})\n",
    "    \n",
    "    # ç¢ºä¿è¡¨æ ¼å­˜åœ¨\n",
    "    if table:\n",
    "        # å­˜æ”¾ USD åŒ¯ç‡è³‡è¨Š\n",
    "        usd_info = None\n",
    "        \n",
    "        # éæ­·è¡¨æ ¼ä¸­çš„æ¯ä¸€è¡Œï¼ŒæŸ¥æ‰¾ USD\n",
    "        for row in table.find_all('tr'):\n",
    "            cols = row.find_all('td')\n",
    "            if cols and 'USD' in cols[0].text:\n",
    "                usd_info = [col.text.strip() for col in cols]\n",
    "                break  # æ‰¾åˆ°å¾Œå³åœæ­¢æœå°‹\n",
    "        \n",
    "        # é¡¯ç¤ºçµæœ\n",
    "        if usd_info:\n",
    "            print(\"âœ… æˆåŠŸç²å–ç¾é‡‘åŒ¯ç‡è³‡è¨Šï¼š\")\n",
    "            print(usd_info)\n",
    "        else:\n",
    "            print(\"âš ï¸ æœªæ‰¾åˆ° USD åŒ¯ç‡æ•¸æ“šï¼Œè«‹ç¢ºèªç¶²é çµæ§‹æ˜¯å¦è®Šæ›´ã€‚\")\n",
    "    else:\n",
    "        print(\"âš ï¸ æœªæ‰¾åˆ°ç›®æ¨™è¡¨æ ¼ï¼Œè«‹ç¢ºèªç¶²é çµæ§‹æ˜¯å¦è®Šæ›´ã€‚\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨ä»¥ä¸Šçš„æŸ¥è©¢è¼¸å‡ºä¸­åŠ å…¥éŠ€è¡Œè³‡è¨Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦ éŠ€è¡Œåç¨±: åˆä½œé‡‘åº«ç‰Œå‘ŠåŒ¯ç‡è¡¨\n",
      "ğŸ§ è·¨è¡Œè½‰å¸³ç¨‹å¼ç¢¼: 006\n",
      "ğŸ’³ SWIFT ç¨‹å¼ç¢¼: TACBTWTP\n",
      "âœ… ç¾é‡‘åŒ¯ç‡è³‡è¨Š: ['ç¾é‡‘ USD', '32.365', '33.063', '32.68', '32.84']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# æŒ‡å®šéŠ€è¡ŒæŸ¥è©¢ç¶²å€ï¼ˆç¯„ä¾‹ï¼šå°ç£éŠ€è¡Œï¼‰\n",
    "url = \"https://www.findrate.tw/bank/10/\"\n",
    "\n",
    "# æ·»åŠ  `User-Agent` ä»¥æ¨¡æ“¬ç€è¦½å™¨ï¼Œé¿å…è«‹æ±‚è¢«é˜»æ“‹\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# ç™¼é€è«‹æ±‚\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# æª¢æŸ¥è«‹æ±‚æ˜¯å¦æˆåŠŸ\n",
    "if response.status_code != 200:\n",
    "    print(f\"âŒ ç„¡æ³•å–å¾—æ•¸æ“šï¼ŒHTTP ç‹€æ…‹ç¢¼: {response.status_code}\")\n",
    "else:\n",
    "    # è§£æ HTML å…§å®¹\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # å–å¾—éŠ€è¡Œåç¨±\n",
    "    bank_title = soup.find('div', {'id': 'Title'})\n",
    "    bank_name = bank_title.h1.text if bank_title else \"æœªæ‰¾åˆ°éŠ€è¡Œåç¨±\"\n",
    "\n",
    "    # å–å¾—è·¨è¡Œè½‰å¸³ç¨‹å¼ç¢¼å’Œ SWIFT éŠ€è¡Œåœ‹éš›ç¨‹å¼ç¢¼\n",
    "    bank_info_paragraph = bank_title.find_next_sibling('p') if bank_title else None\n",
    "    if bank_info_paragraph:\n",
    "        bank_transfer_code = bank_info_paragraph.find_all('b')[0].text if len(bank_info_paragraph.find_all('b')) > 0 else \"æœªæ‰¾åˆ°è½‰å¸³ç¨‹å¼ç¢¼\"\n",
    "        swift_code = bank_info_paragraph.find_all('b')[1].text if len(bank_info_paragraph.find_all('b')) > 1 else \"æœªæ‰¾åˆ° SWIFT ç¨‹å¼ç¢¼\"\n",
    "    else:\n",
    "        bank_transfer_code = \"æœªæ‰¾åˆ°è½‰å¸³ç¨‹å¼ç¢¼\"\n",
    "        swift_code = \"æœªæ‰¾åˆ° SWIFT ç¨‹å¼ç¢¼\"\n",
    "\n",
    "    # æ‰¾åˆ°åŒ…å«åŒ¯ç‡çš„è¡¨æ ¼\n",
    "    table = soup.find('table', {'width': '725px'})\n",
    "\n",
    "    # ç¢ºä¿è¡¨æ ¼å­˜åœ¨\n",
    "    usd_info = None\n",
    "    if table:\n",
    "        # éæ­·è¡¨æ ¼ä¸­çš„æ¯ä¸€è¡Œï¼ŒæŸ¥æ‰¾ USD\n",
    "        for row in table.find_all('tr'):\n",
    "            cols = row.find_all('td')\n",
    "            if cols and 'USD' in cols[0].text:\n",
    "                usd_info = [col.text.strip() for col in cols]\n",
    "                break  # æ‰¾åˆ°å¾Œå³åœæ­¢æœå°‹\n",
    "\n",
    "    # é¡¯ç¤ºçµæœ\n",
    "    print(f\"ğŸ¦ éŠ€è¡Œåç¨±: {bank_name}\")\n",
    "    print(f\"ğŸ§ è·¨è¡Œè½‰å¸³ç¨‹å¼ç¢¼: {bank_transfer_code}\")\n",
    "    print(f\"ğŸ’³ SWIFT ç¨‹å¼ç¢¼: {swift_code}\")\n",
    "    \n",
    "    if usd_info:\n",
    "        print(\"âœ… ç¾é‡‘åŒ¯ç‡è³‡è¨Š:\", usd_info)\n",
    "    else:\n",
    "        print(\"âš ï¸ æœªæ‰¾åˆ° USD åŒ¯ç‡æ•¸æ“šï¼Œè«‹ç¢ºèªç¶²é çµæ§‹æ˜¯å¦è®Šæ›´ã€‚\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ”¹æŸ¥è©¢ `9`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦ éŠ€è¡Œåç¨±: ä¸­åœ‹ä¿¡è¨—ç‰Œå‘ŠåŒ¯ç‡è¡¨\n",
      "ğŸ§ è·¨è¡Œè½‰å¸³ç¨‹å¼ç¢¼: 822\n",
      "ğŸ’³ SWIFT ç¨‹å¼ç¢¼: CTCBTWTP\n",
      "âš ï¸ æœªæ‰¾åˆ° USD åŒ¯ç‡æ•¸æ“šï¼Œè«‹ç¢ºèªç¶²é çµæ§‹æ˜¯å¦è®Šæ›´ã€‚\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# æŒ‡å®šéŠ€è¡ŒæŸ¥è©¢ç¶²å€\n",
    "url = \"https://www.findrate.tw/bank/2/\"\n",
    "\n",
    "# æ·»åŠ  `User-Agent` ä»¥æ¨¡æ“¬ç€è¦½å™¨ï¼Œé¿å…è«‹æ±‚è¢«é˜»æ“‹\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# ç™¼é€è«‹æ±‚\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# æª¢æŸ¥è«‹æ±‚æ˜¯å¦æˆåŠŸ\n",
    "if response.status_code != 200:\n",
    "    print(f\"âŒ ç„¡æ³•å–å¾—æ•¸æ“šï¼ŒHTTP ç‹€æ…‹ç¢¼: {response.status_code}\")\n",
    "else:\n",
    "    # è§£æ HTML å…§å®¹\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # å–å¾—éŠ€è¡Œåç¨±\n",
    "    bank_title = soup.find('div', {'id': 'Title'})\n",
    "    bank_name = bank_title.h1.text if bank_title else \"æœªæ‰¾åˆ°éŠ€è¡Œåç¨±\"\n",
    "\n",
    "    # å–å¾—è·¨è¡Œè½‰å¸³ç¨‹å¼ç¢¼å’Œ SWIFT éŠ€è¡Œåœ‹éš›ç¨‹å¼ç¢¼\n",
    "    bank_info_paragraph = bank_title.find_next_sibling('p') if bank_title else None\n",
    "    if bank_info_paragraph:\n",
    "        bank_transfer_code = bank_info_paragraph.find_all('b')[0].text if len(bank_info_paragraph.find_all('b')) > 0 else \"æœªæ‰¾åˆ°è½‰å¸³ç¨‹å¼ç¢¼\"\n",
    "        swift_code = bank_info_paragraph.find_all('b')[1].text if len(bank_info_paragraph.find_all('b')) > 1 else \"æœªæ‰¾åˆ° SWIFT ç¨‹å¼ç¢¼\"\n",
    "    else:\n",
    "        bank_transfer_code = \"æœªæ‰¾åˆ°è½‰å¸³ç¨‹å¼ç¢¼\"\n",
    "        swift_code = \"æœªæ‰¾åˆ° SWIFT ç¨‹å¼ç¢¼\"\n",
    "\n",
    "    # æ‰¾åˆ°åŒ…å«åŒ¯ç‡çš„è¡¨æ ¼\n",
    "    table = soup.find('table', {'width': '725px'})\n",
    "\n",
    "    # ç¢ºä¿è¡¨æ ¼å­˜åœ¨\n",
    "    usd_info = None\n",
    "    if table:\n",
    "        # éæ­·è¡¨æ ¼ä¸­çš„æ¯ä¸€è¡Œï¼ŒæŸ¥æ‰¾ USD\n",
    "        for row in table.find_all('tr'):\n",
    "            cols = row.find_all('td')\n",
    "            if cols and 'USD' in cols[0].text:\n",
    "                usd_info = [col.text.strip() for col in cols]\n",
    "                break  # æ‰¾åˆ°å¾Œå³åœæ­¢æœå°‹\n",
    "\n",
    "    # é¡¯ç¤ºçµæœ\n",
    "    print(f\"ğŸ¦ éŠ€è¡Œåç¨±: {bank_name}\")\n",
    "    print(f\"ğŸ§ è·¨è¡Œè½‰å¸³ç¨‹å¼ç¢¼: {bank_transfer_code}\")\n",
    "    print(f\"ğŸ’³ SWIFT ç¨‹å¼ç¢¼: {swift_code}\")\n",
    "    \n",
    "    if usd_info:\n",
    "        print(\"âœ… ç¾é‡‘åŒ¯ç‡è³‡è¨Š:\", usd_info)\n",
    "    else:\n",
    "        print(\"âš ï¸ æœªæ‰¾åˆ° USD åŒ¯ç‡æ•¸æ“šï¼Œè«‹ç¢ºèªç¶²é çµæ§‹æ˜¯å¦è®Šæ›´ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ‰¹æ¬¡æŸ¥è©¢å¤šå®¶éŠ€è¡Œè³‡è¨Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ğŸ¦ éŠ€è¡Œåç¨±: ä¸Šæµ·å•†éŠ€ç‰Œå‘ŠåŒ¯ç‡è¡¨\n",
      "ğŸ§ è·¨è¡Œè½‰å¸³ç¨‹å¼ç¢¼: 011\n",
      "ğŸ’³ SWIFT ç¨‹å¼ç¢¼: SCSBTWTP\n",
      "âœ… ç¾é‡‘åŒ¯ç‡è³‡è¨Š: ['ç¾é‡‘ USD', '32.51', '33.01', '32.7', '32.81']\n",
      "==================================================\n",
      "==================================================\n",
      "ğŸ¦ éŠ€è¡Œåç¨±: ä¸­åœ‹ä¿¡è¨—ç‰Œå‘ŠåŒ¯ç‡è¡¨\n",
      "ğŸ§ è·¨è¡Œè½‰å¸³ç¨‹å¼ç¢¼: 822\n",
      "ğŸ’³ SWIFT ç¨‹å¼ç¢¼: CTCBTWTP\n",
      "âš ï¸ æœªæ‰¾åˆ° USD åŒ¯ç‡æ•¸æ“šï¼Œè«‹ç¢ºèªç¶²é çµæ§‹æ˜¯å¦è®Šæ›´ã€‚\n",
      "==================================================\n",
      "==================================================\n",
      "ğŸ¦ éŠ€è¡Œåç¨±: äº¬åŸéŠ€è¡Œç‰Œå‘ŠåŒ¯ç‡è¡¨\n",
      "ğŸ§ è·¨è¡Œè½‰å¸³ç¨‹å¼ç¢¼: 054\n",
      "ğŸ’³ SWIFT ç¨‹å¼ç¢¼: TNBBTWTN\n",
      "âœ… ç¾é‡‘åŒ¯ç‡è³‡è¨Š: ['ç¾é‡‘ USD', '32.337', '33.027', '32.707', '32.807']\n",
      "==================================================\n",
      "==================================================\n",
      "ğŸ¦ éŠ€è¡Œåç¨±: å…ƒå¤§éŠ€è¡Œç‰Œå‘ŠåŒ¯ç‡è¡¨\n",
      "ğŸ§ è·¨è¡Œè½‰å¸³ç¨‹å¼ç¢¼: 806\n",
      "ğŸ’³ SWIFT ç¨‹å¼ç¢¼: APBKTWTH\n",
      "âœ… ç¾é‡‘åŒ¯ç‡è³‡è¨Š: ['ç¾é‡‘ USD', '32.43', '33.044', '32.68', '32.816']\n",
      "==================================================\n",
      "==================================================\n",
      "ğŸ¦ éŠ€è¡Œåç¨±: å…†è±éŠ€è¡Œç‰Œå‘ŠåŒ¯ç‡è¡¨\n",
      "ğŸ§ è·¨è¡Œè½‰å¸³ç¨‹å¼ç¢¼: 017\n",
      "ğŸ’³ SWIFT ç¨‹å¼ç¢¼: ICBCTWTP\n",
      "âœ… ç¾é‡‘åŒ¯ç‡è³‡è¨Š: ['ç¾é‡‘ USD', '32.35', '33.02', '32.69', '32.79']\n",
      "==================================================\n",
      "==================================================\n",
      "ğŸ¦ éŠ€è¡Œåç¨±: åŒ¯è±éŠ€è¡Œç‰Œå‘ŠåŒ¯ç‡è¡¨\n",
      "ğŸ§ è·¨è¡Œè½‰å¸³ç¨‹å¼ç¢¼: 081\n",
      "ğŸ’³ SWIFT ç¨‹å¼ç¢¼: HSBCTWTP\n",
      "âœ… ç¾é‡‘åŒ¯ç‡è³‡è¨Š: ['ç¾é‡‘ USD', '32.46', '33.06', '32.71', '32.81']\n",
      "==================================================\n",
      "==================================================\n",
      "ğŸ¦ éŠ€è¡Œåç¨±: å°ä¸­éŠ€è¡Œç‰Œå‘ŠåŒ¯ç‡è¡¨\n",
      "ğŸ§ è·¨è¡Œè½‰å¸³ç¨‹å¼ç¢¼: 053\n",
      "ğŸ’³ SWIFT ç¨‹å¼ç¢¼: TCBBTWTH\n",
      "âœ… ç¾é‡‘åŒ¯ç‡è³‡è¨Š: ['ç¾é‡‘ USD', '32.459', '33.009', '32.709', '32.809']\n",
      "==================================================\n",
      "==================================================\n",
      "ğŸ¦ éŠ€è¡Œåç¨±: å¯Œé‚¦éŠ€è¡Œç‰Œå‘ŠåŒ¯ç‡è¡¨\n",
      "ğŸ§ è·¨è¡Œè½‰å¸³ç¨‹å¼ç¢¼: 012\n",
      "ğŸ’³ SWIFT ç¨‹å¼ç¢¼: TPBKTWTP\n",
      "âœ… ç¾é‡‘åŒ¯ç‡è³‡è¨Š: ['ç¾é‡‘ USD', '32.425', '33.067', '32.687', '32.847']\n",
      "==================================================\n",
      "==================================================\n",
      "ğŸ¦ éŠ€è¡Œåç¨±: å°æ–°éŠ€è¡Œç‰Œå‘ŠåŒ¯ç‡è¡¨\n",
      "ğŸ§ è·¨è¡Œè½‰å¸³ç¨‹å¼ç¢¼: 812\n",
      "ğŸ’³ SWIFT ç¨‹å¼ç¢¼: TSIBTWTP\n",
      "âœ… ç¾é‡‘åŒ¯ç‡è³‡è¨Š: ['ç¾é‡‘ USD', '32.517', '32.994', '32.719', '32.819']\n",
      "==================================================\n",
      "==================================================\n",
      "ğŸ¦ éŠ€è¡Œåç¨±: åˆä½œé‡‘åº«ç‰Œå‘ŠåŒ¯ç‡è¡¨\n",
      "ğŸ§ è·¨è¡Œè½‰å¸³ç¨‹å¼ç¢¼: 006\n",
      "ğŸ’³ SWIFT ç¨‹å¼ç¢¼: TACBTWTP\n",
      "âœ… ç¾é‡‘åŒ¯ç‡è³‡è¨Š: ['ç¾é‡‘ USD', '32.365', '33.063', '32.68', '32.84']\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fetch_data(bank_index):\n",
    "    \"\"\"\n",
    "    å¾æŒ‡å®šçš„éŠ€è¡Œç´¢å¼•é é¢æŠ“å–éŠ€è¡Œè³‡è¨Šèˆ‡ USD åŒ¯ç‡æ•¸æ“š\n",
    "    \"\"\"\n",
    "    # æŒ‡å®šéŠ€è¡ŒæŸ¥è©¢ç¶²å€\n",
    "    url = f\"https://www.findrate.tw/bank/{bank_index}/\"\n",
    "\n",
    "    # æ·»åŠ  `User-Agent` ä»¥æ¨¡æ“¬ç€è¦½å™¨ï¼Œé¿å…è«‹æ±‚è¢«é˜»æ“‹\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    # ç™¼é€è«‹æ±‚\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # æª¢æŸ¥è«‹æ±‚æ˜¯å¦æˆåŠŸ\n",
    "    if response.status_code != 200:\n",
    "        print(f\"âŒ ç„¡æ³•å–å¾—æ•¸æ“š (HTTP ç‹€æ…‹ç¢¼: {response.status_code})ï¼Œè·³ééŠ€è¡Œç´¢å¼• {bank_index}\")\n",
    "        return\n",
    "\n",
    "    # è§£æ HTML å…§å®¹\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # å–å¾—éŠ€è¡Œåç¨±\n",
    "    bank_title = soup.find('div', {'id': 'Title'})\n",
    "    bank_name = bank_title.h1.text.strip() if bank_title else f\"æœªæ‰¾åˆ°éŠ€è¡Œåç¨± (ç´¢å¼•: {bank_index})\"\n",
    "\n",
    "    # å–å¾—è·¨è¡Œè½‰å¸³ç¨‹å¼ç¢¼å’Œ SWIFT éŠ€è¡Œåœ‹éš›ç¨‹å¼ç¢¼\n",
    "    bank_info_paragraph = bank_title.find_next_sibling('p') if bank_title else None\n",
    "    if bank_info_paragraph:\n",
    "        bank_transfer_code = bank_info_paragraph.find_all('b')[0].text if len(bank_info_paragraph.find_all('b')) > 0 else \"æœªæ‰¾åˆ°è½‰å¸³ç¨‹å¼ç¢¼\"\n",
    "        swift_code = bank_info_paragraph.find_all('b')[1].text if len(bank_info_paragraph.find_all('b')) > 1 else \"æœªæ‰¾åˆ° SWIFT ç¨‹å¼ç¢¼\"\n",
    "    else:\n",
    "        bank_transfer_code = \"æœªæ‰¾åˆ°è½‰å¸³ç¨‹å¼ç¢¼\"\n",
    "        swift_code = \"æœªæ‰¾åˆ° SWIFT ç¨‹å¼ç¢¼\"\n",
    "\n",
    "    # æ‰¾åˆ°åŒ…å«åŒ¯ç‡çš„è¡¨æ ¼\n",
    "    table = soup.find('table', {'width': '725px'})\n",
    "\n",
    "    # ç¢ºä¿è¡¨æ ¼å­˜åœ¨ä¸¦æå– USD åŒ¯ç‡æ•¸æ“š\n",
    "    usd_info = None\n",
    "    if table:\n",
    "        for row in table.find_all('tr'):\n",
    "            cols = row.find_all('td')\n",
    "            if cols and 'USD' in cols[0].text:\n",
    "                usd_info = [col.text.strip() for col in cols]\n",
    "                break  # æ‰¾åˆ°å¾Œå³åœæ­¢æœå°‹\n",
    "\n",
    "    # é¡¯ç¤ºçµæœ\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"ğŸ¦ éŠ€è¡Œåç¨±: {bank_name}\")\n",
    "    print(f\"ğŸ§ è·¨è¡Œè½‰å¸³ç¨‹å¼ç¢¼: {bank_transfer_code}\")\n",
    "    print(f\"ğŸ’³ SWIFT ç¨‹å¼ç¢¼: {swift_code}\")\n",
    "    \n",
    "    if usd_info:\n",
    "        print(\"âœ… ç¾é‡‘åŒ¯ç‡è³‡è¨Š:\", usd_info)\n",
    "    else:\n",
    "        print(\"âš ï¸ æœªæ‰¾åˆ° USD åŒ¯ç‡æ•¸æ“šï¼Œè«‹ç¢ºèªç¶²é çµæ§‹æ˜¯å¦è®Šæ›´ã€‚\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "# ä¸»ç¨‹å¼: éæ­·éŠ€è¡Œç´¢å¼• 1~10\n",
    "if __name__ == '__main__':\n",
    "    for i in range(1, 11):  # 10 å®¶éŠ€è¡Œ\n",
    "        fetch_data(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å­˜æª”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… åŒ¯ç‡æ•¸æ“šå·²å„²å­˜è‡³ ç¾é‡‘åŒ¯ç‡_å½™æ•´_20250220.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_data(bank_index):\n",
    "    \"\"\"\n",
    "    å¾æŒ‡å®šçš„éŠ€è¡Œç´¢å¼•é é¢æŠ“å–éŠ€è¡Œè³‡è¨Šèˆ‡ USD åŒ¯ç‡æ•¸æ“š\n",
    "    \"\"\"\n",
    "    # æŒ‡å®šéŠ€è¡ŒæŸ¥è©¢ç¶²å€\n",
    "    url = f\"https://www.findrate.tw/bank/{bank_index}/\"\n",
    "\n",
    "    # æ·»åŠ  `User-Agent` ä»¥æ¨¡æ“¬ç€è¦½å™¨ï¼Œé¿å…è«‹æ±‚è¢«é˜»æ“‹\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    # ç™¼é€è«‹æ±‚\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # æª¢æŸ¥è«‹æ±‚æ˜¯å¦æˆåŠŸ\n",
    "    if response.status_code != 200:\n",
    "        print(f\"âŒ ç„¡æ³•å–å¾—æ•¸æ“š (HTTP ç‹€æ…‹ç¢¼: {response.status_code})ï¼Œè·³ééŠ€è¡Œç´¢å¼• {bank_index}\")\n",
    "        return None\n",
    "\n",
    "    # è§£æ HTML å…§å®¹\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # å–å¾—å®Œæ•´éŠ€è¡Œåç¨±\n",
    "    bank_title = soup.find('div', {'id': 'Title'})\n",
    "    full_bank_name = bank_title.h1.text.strip() if bank_title else f\"æœªæ‰¾åˆ°éŠ€è¡Œåç¨± (ç´¢å¼•: {bank_index})\"\n",
    "    bank_name = full_bank_name.split('ç‰Œå‘ŠåŒ¯ç‡')[0].strip()  # å»é™¤å¤šé¤˜å­—ä¸²\n",
    "\n",
    "    # å–å¾—è·¨è¡Œè½‰å¸³ç¨‹å¼ç¢¼å’Œ SWIFT éŠ€è¡Œåœ‹éš›ç¨‹å¼ç¢¼\n",
    "    bank_info_paragraph = bank_title.find_next_sibling('p') if bank_title else None\n",
    "    if bank_info_paragraph:\n",
    "        bank_transfer_code = bank_info_paragraph.find_all('b')[0].text if len(bank_info_paragraph.find_all('b')) > 0 else \"æœªæ‰¾åˆ°è½‰å¸³ç¨‹å¼ç¢¼\"\n",
    "        swift_code = bank_info_paragraph.find_all('b')[1].text if len(bank_info_paragraph.find_all('b')) > 1 else \"æœªæ‰¾åˆ° SWIFT ç¨‹å¼ç¢¼\"\n",
    "    else:\n",
    "        bank_transfer_code = \"æœªæ‰¾åˆ°è½‰å¸³ç¨‹å¼ç¢¼\"\n",
    "        swift_code = \"æœªæ‰¾åˆ° SWIFT ç¨‹å¼ç¢¼\"\n",
    "\n",
    "    # æ‰¾åˆ°åŒ…å«åŒ¯ç‡çš„è¡¨æ ¼\n",
    "    table = soup.find('table', {'width': '725px'})\n",
    "\n",
    "    # ç¢ºä¿è¡¨æ ¼å­˜åœ¨ä¸¦æå– USD åŒ¯ç‡æ•¸æ“š\n",
    "    usd_info = None\n",
    "    if table:\n",
    "        for row in table.find_all('tr'):\n",
    "            cols = row.find_all('td')\n",
    "            if cols and 'USD' in cols[0].text:\n",
    "                usd_info = [col.text.strip() for col in cols[1:]]  # åªæå–åŒ¯ç‡æ•¸æ“š\n",
    "                break  # æ‰¾åˆ°å¾Œå³åœæ­¢æœå°‹\n",
    "\n",
    "    # æª¢æŸ¥æ˜¯å¦æœ‰ç²å–åˆ° USD åŒ¯ç‡æ•¸æ“š\n",
    "    if usd_info is not None:\n",
    "        return [bank_name, bank_transfer_code, swift_code] + usd_info\n",
    "    else:\n",
    "        return [bank_name, bank_transfer_code, swift_code] + [None, None, None, None]  # ç„¡æ•¸æ“šå‰‡å¡«å…¥ None\n",
    "\n",
    "# åˆå§‹åŒ–å„²å­˜æ‰€æœ‰éŠ€è¡Œæ•¸æ“šçš„åˆ—è¡¨\n",
    "all_bank_data = []\n",
    "\n",
    "# éæ­· 1~10 çš„éŠ€è¡Œç´¢å¼•\n",
    "for i in range(1, 11):\n",
    "    result = fetch_data(i)\n",
    "    if result:\n",
    "        all_bank_data.append(result)\n",
    "\n",
    "# å»ºç«‹ DataFrame\n",
    "df = pd.DataFrame(all_bank_data, columns=[\n",
    "    \"éŠ€è¡Œåç¨±\", \"éŠ€è¡Œç¨‹å¼ç¢¼\", \"SWIFT Code\", \"ç¾é‡‘è²·å…¥\", \"ç¾é‡‘è³£å‡º\", \"å³æœŸè²·å…¥\", \"å³æœŸè³£å‡º\"\n",
    "])\n",
    "\n",
    "# å–å¾—ç•¶å‰æ—¥æœŸï¼Œæ ¼å¼ç‚º YYYYMMDD\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# ç”Ÿæˆ Excel æª”æ¡ˆåç¨±\n",
    "file_name = f\"ç¾é‡‘åŒ¯ç‡_å½™æ•´_{current_date}.xlsx\"\n",
    "\n",
    "# å„²å­˜ç‚º Excel æª”æ¡ˆ\n",
    "df.to_excel(file_name, index=False)\n",
    "\n",
    "print(f\"âœ… åŒ¯ç‡æ•¸æ“šå·²å„²å­˜è‡³ {file_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é€²è¡Œæ¯”è¼ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š å³æœŸè²·å…¥èˆ‡å³æœŸè³£å‡ºæœ€é«˜èˆ‡æœ€ä½éŠ€è¡Œ\n",
      "ğŸ† å³æœŸè²·å…¥æœ€é«˜: å°æ–°éŠ€è¡Œ - 32.719\n",
      "ğŸ”» å³æœŸè²·å…¥æœ€ä½: å…ƒå¤§éŠ€è¡Œ - 32.68\n",
      "ğŸ† å³æœŸè³£å‡ºæœ€é«˜: å¯Œé‚¦éŠ€è¡Œ - 32.847\n",
      "ğŸ”» å³æœŸè³£å‡ºæœ€ä½: å…†è±éŠ€è¡Œ - 32.79\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fetch_data(bank_index):\n",
    "    \"\"\"\n",
    "    å¾æŒ‡å®šçš„éŠ€è¡Œç´¢å¼•é é¢æŠ“å–éŠ€è¡Œè³‡è¨Šèˆ‡ USD åŒ¯ç‡æ•¸æ“š\n",
    "    \"\"\"\n",
    "    url = f\"https://www.findrate.tw/bank/{bank_index}/\"\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"âŒ ç„¡æ³•å–å¾—æ•¸æ“š (HTTP ç‹€æ…‹ç¢¼: {response.status_code})ï¼Œè·³ééŠ€è¡Œç´¢å¼• {bank_index}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    bank_title = soup.find('div', {'id': 'Title'})\n",
    "    full_bank_name = bank_title.h1.text.strip() if bank_title else f\"æœªæ‰¾åˆ°éŠ€è¡Œåç¨± (ç´¢å¼•: {bank_index})\"\n",
    "    bank_name = full_bank_name.split('ç‰Œå‘ŠåŒ¯ç‡')[0].strip()\n",
    "\n",
    "    table = soup.find('table', {'width': '725px'})\n",
    "\n",
    "    usd_info = None\n",
    "    if table:\n",
    "        for row in table.find_all('tr'):\n",
    "            cols = row.find_all('td')\n",
    "            if cols and 'USD' in cols[0].text:\n",
    "                usd_info = [col.text.strip() for col in cols[1:]]  # åªæå–åŒ¯ç‡æ•¸æ“š\n",
    "                break  \n",
    "\n",
    "    if usd_info:\n",
    "        try:\n",
    "            return [bank_name, float(usd_info[2]), float(usd_info[3])]  # å³æœŸè²·å…¥ã€å³æœŸè³£å‡º\n",
    "        except ValueError:\n",
    "            print(f\"âš ï¸ {bank_name} è³‡æ–™æ ¼å¼éŒ¯èª¤ï¼Œè·³é\")\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# æŠ“å–æ‰€æœ‰éŠ€è¡Œæ•¸æ“š\n",
    "all_bank_data = []\n",
    "for i in range(1, 11):\n",
    "    result = fetch_data(i)\n",
    "    if result:\n",
    "        all_bank_data.append(result)\n",
    "\n",
    "# å»ºç«‹ DataFrame\n",
    "df = pd.DataFrame(all_bank_data, columns=[\"éŠ€è¡Œåç¨±\", \"å³æœŸè²·å…¥\", \"å³æœŸè³£å‡º\"])\n",
    "\n",
    "# æ‰¾å‡ºå³æœŸè²·å…¥æœ€é«˜èˆ‡æœ€ä½\n",
    "if not df.empty:\n",
    "    max_buy = df.loc[df[\"å³æœŸè²·å…¥\"].idxmax()]\n",
    "    min_buy = df.loc[df[\"å³æœŸè²·å…¥\"].idxmin()]\n",
    "    max_sell = df.loc[df[\"å³æœŸè³£å‡º\"].idxmax()]\n",
    "    min_sell = df.loc[df[\"å³æœŸè³£å‡º\"].idxmin()]\n",
    "\n",
    "    print(\"\\nğŸ“Š å³æœŸè²·å…¥èˆ‡å³æœŸè³£å‡ºæœ€é«˜èˆ‡æœ€ä½éŠ€è¡Œ\")\n",
    "    print(f\"ğŸ† å³æœŸè²·å…¥æœ€é«˜: {max_buy['éŠ€è¡Œåç¨±']} - {max_buy['å³æœŸè²·å…¥']}\")\n",
    "    print(f\"ğŸ”» å³æœŸè²·å…¥æœ€ä½: {min_buy['éŠ€è¡Œåç¨±']} - {min_buy['å³æœŸè²·å…¥']}\")\n",
    "    print(f\"ğŸ† å³æœŸè³£å‡ºæœ€é«˜: {max_sell['éŠ€è¡Œåç¨±']} - {max_sell['å³æœŸè³£å‡º']}\")\n",
    "    print(f\"ğŸ”» å³æœŸè³£å‡ºæœ€ä½: {min_sell['éŠ€è¡Œåç¨±']} - {min_sell['å³æœŸè³£å‡º']}\")\n",
    "else:\n",
    "    print(\"âŒ ç„¡æ³•ç²å–æœ‰æ•ˆçš„åŒ¯ç‡æ•¸æ“š\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envStock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
