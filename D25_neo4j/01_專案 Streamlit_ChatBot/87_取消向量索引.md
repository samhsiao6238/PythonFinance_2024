# 取消向量索引

_由於向量索引使用上有問題，以下將不再使用它並更新多個腳本。_

<br>

1. app.py。

    ```python
    import streamlit as st
    from utils import write_message
    from solutions.agent import generate_response

    st.set_page_config("電影資訊聊天機器人", page_icon=":movie_camera:")

    # 設置 Session State
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {
                "role": "assistant",
                "content": "哈囉～我是柱機器人，有啥可幫你的？",
            },
        ]

    # 提交處理函數
    def handle_submit(message):
        with st.spinner("我想一下..."):
            print(f'===bot.py -> message(用戶)：類型 {type(message)}:{message}===')
            response = generate_response(message)
            write_message("assistant", response)

    # 顯示 Session State 中的消息
    for message in st.session_state.messages:
        write_message(message["role"], message["content"], save=False)

    # 處理用戶輸入
    if prompt := st.chat_input("怎麼了？"):
        write_message("user", prompt)
        handle_submit(prompt)
    ```

<br>

2. `utils.py`。

    ```python
    import streamlit as st

    def write_message(role, content, save=True):
        print('=utility.py -> 調用 `write_message` 處理訊息=')
        if save:
            print('=utility.py -> 添加訊息到 session_state=')
            st.session_state.messages.append({
                "role": role,
                "content": content
            })
        else:
            print('=utility.py -> 不添加訊息到 session_state=')

        with st.chat_message(role):
            st.markdown(content)
    ```

<br>

3.  `agent.py`。

    ```python
    from langchain.tools import Tool
    from langchain.agents import AgentExecutor, create_react_agent
    from langchain import hub
    from langchain.chains.conversation.memory import ConversationBufferWindowMemory
    from solutions.llm import llm
    from solutions.tools.finetuned import cypher_qa

    # 設置 tools 的列表
    tools = [
        Tool.from_function(
            name="General Chat",
            description="For general chat not covered by other tools",
            func=llm.invoke,
            return_direct=True,
        ),
        Tool.from_function(
            name="Cypher QA",
            description="Provide info about movies questions using Cypher",
            func=cypher_qa,
            return_direct=True,
        ),
    ]

    # 設置記憶體
    memory = ConversationBufferWindowMemory(
        memory_key="chat_history",
        k=5,
        return_messages=True,
    )

    # 調用 langchain 函數 hub.pull() 生成 agent_prompt
    agent_prompt = hub.pull("hwchase17/react-chat")
    # 調用 create_react_agent 生成 agent
    agent = create_react_agent(llm, tools, agent_prompt)
    agent_executor = AgentExecutor(
        agent=agent, tools=tools, memory=memory, verbose=True
    )

    # 生成回應的函數
    def generate_response(prompt):
        response = agent_executor.invoke({"input": prompt})
        return response["output"]
    ```

<br>

4. `graph.py`。

    ```python
    # graph.py
    import streamlit as st
    from langchain_community.graphs import Neo4jGraph

    # 取得環境變數
    NEO4J_URI = st.secrets["NEO4J_URI"]
    NEO4J_USERNAME = st.secrets["NEO4J_USERNAME"]
    NEO4J_PASSWORD = st.secrets["NEO4J_PASSWORD"]

    # 建立 Neo4jGraph 實體
    graph = Neo4jGraph(
        url=NEO4J_URI,
        username=NEO4J_USERNAME,
        password=NEO4J_PASSWORD,
    )

    ```

<br>

5. `llm.py`。

    ```python
    # llm.py
    import streamlit as st
    from langchain_openai import ChatOpenAI
    from langchain_openai import OpenAIEmbeddings

    # 取得環境變數
    OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
    OPENAI_MODEL = st.secrets["OPENAI_MODEL"]

    # 建立 ChatOpenAI 實體
    llm = ChatOpenAI(
        openai_api_key=OPENAI_API_KEY,
        model=OPENAI_MODEL,
    )

    # 建立 OpenAIEmbeddings 實體
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)

    ```

<br>

6. 需要移除的 `vector.py`。

    ```python
    # 移除 vector.py 文件，因為不再使用向量索引
    ```

<br>

7. 修改後的工具模組 `solutions/tools/finetuned.py`。

    ```python
    from langchain.chains import LLMChain
    from solutions.llm import llm
    from solutions.graph import graph

    # 不同語言的模板
    prompt_templates = {
        "en": "Translate the following natural language query into a Cypher query: {query}",
        "zh": "將以下自然語言查詢轉換為 Cypher 查詢: {query}",
    }

    # 根據語言獲取對應的模板
    def get_prompt_template(language):
        return prompt_templates.get(language, prompt_templates["en"])

    # 定義 Cypher QA 的處理函數
    def cypher_qa(input_text):
        language = detect(input_text)
        prompt_template = get_prompt_template(language)
        cypher_query = prompt_template.format(query=input_text)
        
        # 查詢 Neo4j
        result = graph.run(cypher_query).data()
        return format_neo4j_result(result, language)

    # 格式化 Neo4j 查詢結果
    def format_neo4j_result(result, language):
        if language == "zh":
            formatted_result = "查詢結果：\n"
        else:
            formatted_result = "Query results:\n"

        for record in result:
            formatted_result += f"{record}\n"

        return formatted_result
    ```

<br>

___

_END_