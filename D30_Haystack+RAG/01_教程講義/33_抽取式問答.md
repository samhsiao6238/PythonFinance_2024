# æŠ½å–å¼å•ç­” Extractive QA

![](images/img_52.png)

<br>

## ç°¡ä»‹

1. æœ¬ç¯„ä¾‹ä½¿ç”¨ `è‡ªç„¶èªè¨€è™•ç†æŠ€è¡“` ä¾†ç†è§£å•é¡Œçš„èªç¾©ï¼Œç„¶å¾Œçµåˆ `å‘é‡æª¢ç´¢æŠ€è¡“` å¾å¤§é‡æ–‡æœ¬ä¸­æœå°‹ä¸¦æå–å•é¡Œçš„ `æœ€ç›¸é—œçš„æ–‡å­—ç‰‡æ®µ`ï¼Œç”±æ–¼ä¸æ˜¯ç”Ÿæˆæ–°çš„æ–‡æœ¬ä¾†å›ç­”ï¼Œå¯ç¢ºä¿ç­”æ¡ˆçš„æº–ç¢ºæ€§å’Œå¯é©—è­‰æ€§ã€‚åŒæ™‚é‚„å¯æ¨™ç¤ºå‡ºç­”æ¡ˆåœ¨åŸæ–‡æœ¬ä¸­çš„ä½ç½®ï¼Œä½¿å¾—ç”¨æˆ¶å¯ä»¥æŸ¥é–±æˆ–æ ¸å¯¦ç­”æ¡ˆçš„ä¾†æºã€‚

<br>

2. é€™æ˜¯å®˜æ–¹åœ¨ `2024/04/25` ç™¼ä½ˆçš„ [å®˜æ–¹æ•™ç¨‹](https://haystack.deepset.ai/tutorials/34_extractive_qa_pipeline)ï¼Œä½¿ç”¨äº† `Wikipedia` çš„ `å¤ä»£ä¸–ç•Œä¸ƒå¤§å¥‡è¹Ÿæ•¸æ“šé›†`ï¼Œè€Œæœ€çµ‚ç›®æ¨™æ˜¯å»ºç«‹ä¸€å€‹ä½¿ç”¨ `æŠ½å–æ¨¡å‹` ä¾†é¡¯ç¤ºæŸ¥è©¢ç­”æ¡ˆæ‰€åœ¨ä½ç½®çš„ `Haystack` ç®¡é“ï¼Œæ ¹æ“šæä¾›çš„æ–‡ä»¶æå–å•é¡Œçš„ç­”æ¡ˆã€‚

<br>

3. ç¯„ä¾‹æ‰€ä½¿ç”¨çš„åµŒå…¥æ¨¡å‹æ˜¯ `sentence-transformers/multi-qa-mpnet-base-dot-v1`ï¼Œé€™æ˜¯å°ˆé–€è¨­è¨ˆç”¨æ–¼å¤šä»»å‹™å•ç­”ï¼ˆMulti-QAï¼‰å ´æ™¯çš„åµŒå…¥æ¨¡å‹ã€‚

## ä¸»è¦çµ„ä»¶

1. `ExtractiveReader`ï¼šå°ˆé–€ç”¨ä¾†é€²è¡ŒæŠ½å–å¼å•ç­”çš„çµ„ä»¶ï¼Œä¸»è¦åŠŸèƒ½æ˜¯å¾æ–‡æœ¬ä¸­æå–å‡ºå…·é«”çš„ç­”æ¡ˆã€‚

<br>

2. `InMemoryDocumentStore`ï¼šæ˜¯ä¸€å€‹è¨˜æ†¶é«”ä¸­çš„æ–‡ä»¶å„²å­˜ï¼Œå®ƒç”¨ä¾†å„²å­˜å’Œç®¡ç†æ–‡ä»¶æ•¸æ“šï¼Œæ–¹ä¾¿å¾ŒçºŒçš„æª¢ç´¢å’ŒæŸ¥è©¢æ“ä½œã€‚

<br>

3. `InMemoryEmbeddingRetriever`ï¼šä¸€å€‹ç”¨ä¾†æª¢ç´¢ç›¸é—œæ–‡ä»¶çš„çµ„ä»¶ï¼Œå®ƒæœƒæ ¹æ“šæŸ¥è©¢å’Œæ–‡ä»¶çš„åµŒå…¥å‘é‡ä¾†æœå°‹æœ€ç›¸é—œçš„æ–‡ä»¶ã€‚

<br>

4. `DocumentWriter`ï¼šæ˜¯ä¸€å€‹è² è²¬å°‡æ–‡ä»¶å¯«å…¥åˆ°æ–‡ä»¶å„²å­˜çš„çµ„ä»¶ï¼Œé€šå¸¸ç”¨æ–¼å°‡è™•ç†å¾Œçš„æ–‡ä»¶å„²å­˜åˆ°è¨˜æ†¶é«”æˆ–è³‡æ–™åº«ä¸­ã€‚

<br>

5. `SentenceTransformersDocumentEmbedder`ï¼šæ˜¯ç”¨ä¾†å°‡æ–‡ä»¶è½‰æ›ç‚ºåµŒå…¥å‘é‡çš„çµ„ä»¶ï¼Œé€™äº›å‘é‡å¯ä»¥ç”¨æ–¼å¾ŒçºŒçš„æª¢ç´¢å’ŒæŸ¥è©¢ã€‚

<br>

6. `SentenceTransformersTextEmbedder`ï¼šæ˜¯ç”¨ä¾†å°‡æŸ¥è©¢æ–‡æœ¬è½‰æ›ç‚ºåµŒå…¥å‘é‡çš„çµ„ä»¶ï¼Œå®ƒé€šå¸¸ç”¨æ–¼å°‡æŸ¥è©¢è½‰æ›ç‚ºèˆ‡æ–‡ä»¶åŒæ¨£çš„å‘é‡è¡¨ç¤ºã€‚

<br>

## æµç¨‹èªªæ˜

1. å–å¾—æ•¸æ“šï¼šåœ¨å»ºç«‹ç´¢å¼•ç®¡é“ä¹‹å‰ï¼Œéœ€è¦å…ˆå–å¾—æ•¸æ“šï¼Œä¸¦ä¸”å°æ•¸æ“šé€²è¡ŒåŸºæœ¬çš„é è™•ç†ã€‚é€™æ­¥é©Ÿç›´æ¥ä½¿ç”¨ `datasets` åº«ä¾†è¼‰å…¥æ•¸æ“šé›†ï¼Œæ‰€ä»¥ä¸éœ€è¦ç‰¹å®šçš„ `Haystack` çµ„ä»¶é€²è¡Œè™•ç†ã€‚

<br>

2. æ–‡æœ¬åµŒå…¥ï¼šå°‡æ¸…ç†å¥½çš„æ–‡æœ¬é€šéåµŒå…¥æ¨¡å‹è½‰æ›æˆåµŒå…¥å‘é‡ï¼Œé€™äº›åµŒå…¥å‘é‡å°‡ç”¨æ–¼è¨ˆç®—æ–‡æœ¬ä¹‹é–“çš„ç›¸ä¼¼åº¦ï¼Œä¸¦é€²è¡Œç›¸é—œçš„æª¢ç´¢æ“ä½œï¼›ç¯„ä¾‹ä¸­ä½¿ç”¨äº† `SentenceTransformersDocumentEmbedder` çµ„ä»¶å°‡æ–‡ä»¶è½‰æ›ç‚ºåµŒå…¥å‘é‡ã€‚

<br>

3. æª¢ç´¢ï¼šä½¿ç”¨ `InMemoryEmbeddingRetriever` çµ„ä»¶é€²è¡Œæª¢ç´¢ï¼Œé€™å€‹çµ„ä»¶æœƒæ ¹æ“šæŸ¥è©¢çš„åµŒå…¥å‘é‡å¾æ–‡ä»¶å„²å­˜ä¸­æª¢ç´¢å‡ºæœ€ç›¸é—œçš„æ–‡ä»¶ã€‚æª¢ç´¢å™¨è² è²¬æ‰¾æŸ¥ç›¸é—œçš„æ–‡ä»¶ï¼Œè®€å–å™¨å‰‡è² è²¬å¾æ–‡ä»¶ä¸­æŠ½å–å…·é«”çš„ç­”æ¡ˆï¼Œä¸¦è¿”å›ç­”æ¡ˆçš„ä½ç½®å’Œä¿¡å¿ƒåˆ†æ•¸ã€‚

<br>

4. å•ç­”ï¼šä½¿ç”¨ `ExtractiveReader` çµ„ä»¶é€²è¡Œå•ç­”ã€‚é€™å€‹çµ„ä»¶æœƒå¾æª¢ç´¢åˆ°çš„æ–‡ä»¶ä¸­æŠ½å–å‡ºå…·é«”çš„ç­”æ¡ˆï¼Œä¸¦æä¾›ç­”æ¡ˆçš„ç½®ä¿¡åº¦åˆ†æ•¸ã€‚

<br>

5. æ–‡ä»¶ç®¡ç†ï¼šä½¿ç”¨ `DocumentWriter` å°‡å‘é‡åŒ–çš„æ–‡ä»¶å¯«å…¥ `DocumentStore`ï¼Œä»¥ç¢ºä¿é€™äº›æ–‡ä»¶å¯ä»¥åœ¨éœ€è¦æ™‚å¿«é€Ÿæª¢ç´¢å’Œä½¿ç”¨ã€‚é€™è£¡ä½¿ç”¨çš„æ–‡ä»¶å„²å­˜äº‹è¨˜æ†¶é«”æ–‡ä»¶å„²å­˜ï¼ˆ`InMemoryDocumentStore`ï¼‰ã€‚

<br>

## é–‹å§‹å°ˆæ¡ˆç·¨è¼¯

1. å®‰è£åº«ã€‚

    ```bash
    # å®‰è£æ‰€éœ€çš„åº«
    pip install haystack-ai accelerate "sentence-transformers>=2.2.0" "datasets>=2.6.1"
    ```

<br>

2. è¼‰å…¥æ•¸æ“šé›†ä¸¦å°å…¥ç¯„ä¾‹æ‰€éœ€çš„ä¾è³´åº«ã€‚

    ```python
    # è¼‰å…¥æ•¸æ“šé›†
    from datasets import load_dataset
    # å°å…¥ç›¸é—œåº«
    from haystack import Document, Pipeline
    from haystack.document_stores.in_memory import InMemoryDocumentStore
    from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever
    from haystack.components.readers import ExtractiveReader
    from haystack.components.embedders import SentenceTransformersDocumentEmbedder
    from haystack.components.writers import DocumentWriter
    ```

<br>

3. è¼‰å…¥èˆ‡å„²å­˜è³‡æ–™ï¼Œæ•¸æ“šè¼‰å…¥å¾Œæœƒå„²å­˜åœ¨è¨˜æ†¶é«”ä¸­ï¼Œä¹Ÿå°±æ˜¯æœ¬åœ°çš„ `.cache` ç›®éŒ„ã€‚

    ```python
    # è¼‰å…¥ "å¤ä»£ä¸–ç•Œä¸ƒå¤§å¥‡è¹Ÿ" æ•¸æ“šé›†
    dataset = load_dataset(
        "bilgeyucel/seven-wonders",
        split="train"
    )
    ```

<br>

4. æŸ¥çœ‹æ•¸æ“šé›†çš„å‰å…©å€‹æ¨£æœ¬ã€‚

    ```python
    print(dataset[:2])
    ```

<br>

5. é¡¯ç¤ºçµæœï¼Œæœ‰å…©ç­†è³‡æ–™ã€‚

    ```python
    {
        "id": [
            "b3de1a673c1eb2876585405395a10c3d",
            "5dcd01886fcb24322578ceb49c96cc3e"
        ],
        "content": [
            "The Colossus of Rhodes ...(çœç•¥)",
            "[6]\nIn 653, an Arab force ...(çœç•¥)\n\n",
        ],
        "content_type": ["text", "text"],
        "meta": [
            {
                "url": "https://en.wikipedia.org/wiki/Colossus_of_Rhodes",
                "_split_id": 0
            },
            {
                "url": "https://en.wikipedia.org/wiki/Colossus_of_Rhodes",
                "_split_id": 1
            },
        ],
        "id_hash_keys": [["content"], ["content"]],
        "score": [None, None],
        "embedding": [None, None],
    }
    ```

<br>

6. ç·©å­˜ä½åœ¨æœ¬åœ°çš„ `.cache` ç›®éŒ„ï¼Œå¯é€éæŒ‡ä»¤æŸ¥çœ‹ã€‚

    ```bash
    ls ~/.cache/huggingface/datasets/
    ```

    ![](images/img_55.png)

<br>

7. ä¹Ÿé€éç¨‹å¼ç¢¼æŸ¥çœ‹ã€‚

    ```python
    # æŸ¥çœ‹ç·©å­˜ç›®éŒ„
    print(dataset.cache_files)
    ```

<br>

8. çµæœã€‚

    ```python
    [{
        'filename': '/Users/samhsiao/.cache/huggingface/datasets/bilgeyucel___seven-wonders/default/0.0.0/fb6a760df211962001d69fda7f3b42568ca938f8/seven-wonders-train.arrow'
    }]
    ```

<br>

## è½‰æ›æ•¸æ“šæ ¼å¼

1. å°‡æ•¸æ“šé›†è½‰æ›ç‚º Haystack æ–‡ä»¶æ ¼å¼ã€‚

    ```python
    # å°‡æ•¸æ“šé›†è½‰æ›ç‚º Haystack æ–‡ä»¶æ ¼å¼
    documents = [
        Document(content=doc["content"], meta=doc["meta"])
        for doc in dataset
    ]

    # å®šç¾©åµŒå…¥æ¨¡å‹
    model = "sentence-transformers/multi-qa-mpnet-base-dot-v1"

    # åˆå§‹åŒ–è¨˜æ†¶é«”æ–‡ä»¶å„²å­˜
    document_store = InMemoryDocumentStore()
    ```

<br>

4. å»ºç«‹ç®¡é“ã€‚

    ```python
    # å»ºç«‹ç´¢å¼•ç®¡é“
    indexing_pipeline = Pipeline()

    # æ·»åŠ åµŒå…¥çµ„ä»¶åˆ°ç®¡é“
    indexing_pipeline.add_component(instance=SentenceTransformersDocumentEmbedder(model=model), name="embedder")
    # æ·»åŠ æ–‡ä»¶å¯«å…¥çµ„ä»¶åˆ°ç®¡é“
    indexing_pipeline.add_component(instance=DocumentWriter(document_store=document_store), name="writer")

    # é€£æ¥åµŒå…¥çµ„ä»¶å’Œæ–‡ä»¶å¯«å…¥çµ„ä»¶
    indexing_pipeline.connect("embedder.documents", "writer.documents")

    # åŸ·è¡Œç´¢å¼•ç®¡é“
    indexing_pipeline.run({"documents": documents})
    ```

<br>

5. ä¸‹è¼‰æ¨¡å‹éœ€è¦ä¸€é»æ™‚é–“ã€‚

    ![](images/img_53.png)

<br>

## å»ºç«‹æŠ½å–å¼å•ç­”ç®¡é“

_`æŠ½å–å¼å•ç­”ç®¡é“` åŒ…å«ä¸‰å€‹çµ„ä»¶ï¼š`åµŒå…¥å™¨`ã€`æª¢ç´¢å™¨` å’Œ `è®€å–å™¨`ã€‚_

<br>

1. åµŒå…¥å™¨ `SentenceTransformersTextEmbedder` æœƒä½¿ç”¨å‰é¢æ‰€å®šç¾©çš„ `åµŒå…¥æ¨¡å‹` å°‡`æŸ¥è©¢` è½‰æ›ç‚º `å‘é‡`ã€‚

<br>

2. é€²è¡Œ `å‘é‡æœç´¢` æ™‚ï¼Œæª¢ç´¢å™¨æœƒå¾æ–‡ä»¶å„²å­˜ä¸­é«˜æ•ˆåœ°è¿”å›ç›¸é—œæ–‡ä»¶ï¼Œæ‰€ä»¥æª¢ç´¢å™¨èˆ‡æ–‡ä»¶å„²å­˜æ˜¯ç·Šå¯†è€¦åˆçš„ï¼Œé€™è£¡ä½¿ç”¨æª¢ç´¢å™¨ `InMemoryEmbeddingRetriever` ä¾†æ­é… `InMemoryDocumentStore`ã€‚

<br>

3. æœ€å¾Œé€éé–±è®€å™¨ `ExtractiveReader` æŸ¥è©¢ä¸¦è¿”å›çš„ç­”æ¡ˆï¼ŒåŒ…å«ç­”æ¡ˆåœ¨æºæ–‡ä»¶ä¸­çš„ä½ç½®å’Œç½®ä¿¡åº¦åˆ†æ•¸ã€‚

<br>

4. ç¨‹å¼ç¢¼ã€‚

    ```python
    # å¾ Haystack æ¨¡çµ„ä¸­å°å…¥éœ€è¦çš„çµ„ä»¶
    from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever
    from haystack.components.readers import ExtractiveReader
    from haystack.components.embedders import SentenceTransformersTextEmbedder

    # åˆå§‹åŒ–æª¢ç´¢å™¨
    retriever = InMemoryEmbeddingRetriever(document_store=document_store)

    # åˆå§‹åŒ–è®€å–å™¨
    reader = ExtractiveReader()
    # é ç†±è®€å–å™¨
    reader.warm_up()

    # å»ºç«‹æŠ½å–å¼å•ç­”ç®¡é“
    extractive_qa_pipeline = Pipeline()

    # æ·»åŠ åµŒå…¥çµ„ä»¶åˆ°ç®¡é“
    extractive_qa_pipeline.add_component(
        instance=SentenceTransformersTextEmbedder(model=model),
        name="embedder"
    )
    # æ·»åŠ æª¢ç´¢çµ„ä»¶åˆ°ç®¡é“
    extractive_qa_pipeline.add_component(
        instance=retriever,
        name="retriever"
    )
    # æ·»åŠ è®€å–çµ„ä»¶åˆ°ç®¡é“
    extractive_qa_pipeline.add_component(
        instance=reader,
        name="reader"
    )

    # é€£æ¥åµŒå…¥çµ„ä»¶å’Œæª¢ç´¢çµ„ä»¶
    extractive_qa_pipeline.connect(
        "embedder.embedding",
        "retriever.query_embedding"
    )
    # é€£æ¥æª¢ç´¢çµ„ä»¶å’Œè®€å–çµ„ä»¶
    extractive_qa_pipeline.connect(
        "retriever.documents",
        "reader.documents"
    )
    ```

<br>

5. é¡¯ç¤ºçµæœã€‚

    ```python
    <haystack.core.pipeline.pipeline.Pipeline object at 0x16a6bbbe0>

    ğŸš… Components
        - embedder: SentenceTransformersTextEmbedder
        - retriever: InMemoryEmbeddingRetriever
        - reader: ExtractiveReader

    ğŸ›¤ï¸ Connections
        - embedder.embedding -> retriever.query_embedding (List[float])
        - retriever.documents -> reader.documents (List[Document])
    ```

<br>

## å®šç¾©æŸ¥è©¢

1. æå•ã€‚

    ```python
    query = "Who was Pliny the Elder?"

    # åŸ·è¡ŒæŠ½å–å¼å•ç­”ç®¡é“ï¼Œä¸¦è¿”å›ç­”æ¡ˆ
    result = extractive_qa_pipeline.run(
        data={
            "embedder": {"text": query},
            "retriever": {"top_k": 3},
            "reader": {
                "query": query,
                "top_k": 2
            }
        }
    )
    # è¼¸å‡ºæŸ¥çœ‹
    print(result)
    ```

<br>

2. ä¸‹è¼‰æ¨¡å‹éœ€è¦ä¸€é»æ™‚é–“ã€‚

    ![](images/img_54.png)

<br>

3. çµæœã€‚

    ```python
    {'reader': {
        'answers': [
            ExtractedAnswer(
                query='Who was Pliny the Elder?',
                score=0.8306005597114563,
                data='Roman writer',
                document=Document(
                    id='bb2c5f3d2e2...',
                    content: 'The Roman writer Pliny the Elder, writing in the first century AD, argued that the Great Pyramid had...',
                    meta: {
                        'url': 'https://en.wikipedia.org/wiki/Great_Pyramid_of_Giza',
                        '_split_id': 16
                    },
                    score: 21.66772941840059
                ),
                context=None,
                document_offset=ExtractedAnswer.Span(start=4, end=16),
                context_offset=None,
                meta={}
            ),
            ExtractedAnswer(
                query='Who was Pliny the Elder?',
                score=0.7280887365341187,
                data='a Roman author',
                document=Document(
                    id='8910f21f7...',
                    content: '[21]Pliny the Elder (AD 23/24 â€“ 79) was a Roman author, a naturalist and natural philosopher, a nav...',
                    meta: {
                        'url': 'https://en.wikipedia.org/wiki/Colossus_of_Rhodes',
                        '_split_id': 8
                    },
                    score: 26.857539924645973
                ),
                context=None,
                document_offset=ExtractedAnswer.Span(start=41, end=55),
                context_offset=None,
                meta={}
            ),
            # ä»¥ä¸‹çœç•¥ ...
        ]
    }}
    ```

<br>

## å„ªåŒ–å›ç­”æ ¼å¼

1. æå•åŠå›ç­”ã€‚

    ```python
    # å„ªåŒ–è¼¸å‡ºç­”æ¡ˆæ ¼å¼
    def format_extracted_answers(answers):
        formatted_answers = []
        for answer in answers:
            data = answer.data if answer.data else "No answer provided."
            document_content = answer.document.content if answer.document else "No document found."
            document_url = answer.document.meta['url'] if answer.document and 'url' in answer.document.meta else "No URL available."
            score = answer.score
            
            try:
                start = int(answer.document_offset.start) if answer.document_offset else None
                end = int(answer.document_offset.end) if answer.document_offset else None
                excerpt = document_content[start:end] if start is not None and end is not None else "No excerpt available."
            except (ValueError, TypeError):
                excerpt = "Invalid indices for excerpt."
            
            formatted_answer = f"""
            Query: {answer.query}
            Answer: {data}
            Score: {score:.4f}
            Document Excerpt: {excerpt}
            Document URL: {document_url}
            Context (Start-End): {start}-{end}
            """
            formatted_answers.append(formatted_answer)
        return "\n".join(formatted_answers)

    # æª¢è¦–çµæœ
    answers = result["reader"]["answers"]
    print("æå–çš„ç­”æ¡ˆï¼š\n", format_extracted_answers(answers))
    ```

<br>

2. ç­”æ¡ˆã€‚

    ```bash
    æå–çš„ç­”æ¡ˆï¼š
    
            Query: Who was Pliny the Elder?
            Answer: Roman writer
            Score: 0.8306
            Document Excerpt: Roman writer
            Document URL: https://en.wikipedia.org/wiki/Great_Pyramid_of_Giza
            Context (Start-End): 4-16
            

            Query: Who was Pliny the Elder?
            Answer: a Roman author
            Score: 0.7281
            Document Excerpt: a Roman author
            Document URL: https://en.wikipedia.org/wiki/Colossus_of_Rhodes
            Context (Start-End): 41-55
            

            Query: Who was Pliny the Elder?
            Answer: No answer provided.
            Score: 0.0461
            Document Excerpt: No excerpt available.
            Document URL: No URL available.
            Context (Start-End): None-None
    ```

<br>

___

_END_