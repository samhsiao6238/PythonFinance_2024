# ä½¿ç”¨ Multiplexer ç°¡åŒ–ç®¡é“è¼¸å…¥

![](images/img_69.png)

<br>

## èªªæ˜

1. é€™æ˜¯å®˜æ–¹åœ¨ `2024/05/10` ç™¼ä½ˆçš„ [å®˜æ–¹æ•™ç¨‹](https://haystack.deepset.ai/tutorials/37_simplifying_pipeline_inputs_with_multiplexer)ï¼Œå¦å¤–éœ€è¦æ­é… `Hugging Face API Key` ä½¿ç”¨ï¼Œæ•´é«”ç›®æ¨™æ˜¯ä½¿ç”¨ `Multiplexer` ä¾†ç°¡åŒ– `RAG ç®¡é“` ä¸­ `Pipeline.run()` çš„è¼¸å…¥ã€‚

<br>

2. åœ¨å»ºç«‹è¶…é 3ã€4 å€‹çµ„ä»¶çš„ `Haystack` ç®¡é“æ™‚ï¼Œå‚³éçµ¦ `Pipeline.run()` æ–¹æ³•çš„è¼¸å…¥æ•¸é‡æœƒç„¡é™å¢é•·ï¼Œæ–°çš„çµ„ä»¶æœƒå¾ç®¡é“ä¸­çš„å…¶ä»–çµ„ä»¶æ¥æ”¶ä¸€äº›è¼¸å…¥ï¼Œä½†è¨±å¤šçµ„ä»¶ä¹Ÿéœ€è¦ä¾†è‡ªç”¨æˆ¶çš„é¡å¤–è¼¸å…¥ï¼Œå› æ­¤ `Pipeline.run()` çš„æ•¸æ“šè¼¸å…¥æœƒè®Šå¾—éå¸¸è¤‡é›œï¼Œé€™å€‹ç‹€æ³å¯é€éä½¿ç”¨ `Multiplexer` æœ‰æ•ˆåœ°ç°¡åŒ–é€™äº›é‡è¤‡ã€‚

<br>

## ä½¿ç”¨çš„çµ„ä»¶

_ç°¡å–®èªªæ˜æ¯å€‹çµ„ä»¶æä¾›çš„åŠŸèƒ½_

<br>

1. `Multiplexer`ï¼šç”¨æ–¼æ¥æ”¶ `ä¸€å€‹è¼¸å…¥` ä¸¦å°‡å…¶åˆ†ç™¼çµ¦ `å¤šå€‹çµ„ä»¶`ï¼Œå¾è€Œç°¡åŒ–ç®¡é“çš„æ•¸æ“šæµè™•ç†ï¼Œæ›å¥è©±èªªå°±æ˜¯å°‡ `å–®ä¸€è¼¸å…¥` å¦‚æŸ¥è©¢æ–‡æœ¬åŒæ™‚ç™¼é€åˆ° `å¤šå€‹éœ€è¦è©²è¼¸å…¥çš„çµ„ä»¶`ã€‚

2. `InMemoryDocumentStore`ï¼šåœ¨å…§å­˜ä¸­å­˜å„²å’Œç®¡ç†æ–‡ä»¶æ•¸æ“šï¼Œä¾¿æ–¼å¿«é€Ÿæª¢ç´¢å’ŒæŸ¥è©¢æ“ä½œï¼Œé©åˆå°å‹æ•¸æ“šé›†çš„é–‹ç™¼æƒ…å¢ƒã€‚

3. `HuggingFaceAPIDocumentEmbedder`ï¼šä½¿ç”¨ `Hugging Face` çš„ API å°‡ `æ–‡ä»¶å…§å®¹` è½‰æ›ç‚º `åµŒå…¥å‘é‡`ï¼Œä»¥ä¾¿å¾ŒçºŒçš„æª¢ç´¢å’Œåˆ†æï¼Œé€™ç¨®åµŒå…¥è¡¨ç¤º _æ•æ‰äº†æ–‡ä»¶çš„èªç¾©ä¿¡æ¯_ã€‚

4. `HuggingFaceAPITextEmbedder`ï¼šä½¿ç”¨ `Hugging Face` çš„ API å°‡ `æ–‡æœ¬æŸ¥è©¢` è½‰æ›ç‚º `åµŒå…¥å‘é‡`ï¼Œç”¨æ–¼èˆ‡æ–‡ä»¶çš„åµŒå…¥å‘é‡é€²è¡Œ `æ¯”è¼ƒ`ï¼Œä»¥å¯¦ç¾ç›¸é—œæ–‡ä»¶çš„æª¢ç´¢ã€‚

5. `InMemoryEmbeddingRetriever`ï¼šåŸºæ–¼ `åµŒå…¥å‘é‡` é€²è¡Œæª¢ç´¢ï¼Œæ ¹æ“šæŸ¥è©¢çš„åµŒå…¥å‘é‡æœå°‹èˆ‡ä¹‹æœ€ç›¸é—œçš„æ–‡ä»¶åµŒå…¥å‘é‡ï¼Œä¸¦è¿”å›ç›¸æ‡‰çš„æ–‡ä»¶ã€‚

6. `PromptBuilder`ï¼šç”¨æ–¼å»ºç«‹ç”Ÿæˆæ¨¡å‹æ‰€éœ€çš„æç¤ºï¼ˆpromptï¼‰ï¼Œå°‡æª¢ç´¢åˆ°çš„æ–‡ä»¶å…§å®¹å’Œç”¨æˆ¶çš„å•é¡Œçµ„åˆæˆä¸€å€‹å®Œæ•´çš„æç¤ºï¼Œä¾›ç”Ÿæˆæ¨¡å‹ä½¿ç”¨ã€‚

7. `HuggingFaceAPIGenerator`ï¼šä½¿ç”¨ `Hugging Face` çš„ API é€²è¡Œæ–‡æœ¬ç”Ÿæˆï¼Œæ ¹æ“šæç¤ºç”Ÿæˆè‡ªç„¶èªè¨€å›ç­”æˆ–æ–‡æœ¬ï¼Œé€šå¸¸ç”¨æ–¼ç”Ÿæˆç­”æ¡ˆæˆ–çºŒå¯«æ–‡æœ¬ã€‚

8. `AnswerBuilder`ï¼šçµ„åˆç”Ÿæˆçš„ç­”æ¡ˆèˆ‡åŸå§‹å•é¡Œã€æª¢ç´¢åˆ°çš„ç›¸é—œæ–‡ä»¶å’Œæ¨¡å‹çš„å…ƒæ•¸æ“šï¼Œä»¥ä¾¿æä¾›æ›´åŠ å®Œæ•´å’Œæœ‰ç”¨çš„å›ç­”ã€‚

<br>

## é–‹å§‹

1. å®‰è£ä¾è³´åº«ã€‚

    ```bash
    pip install haystack-ai "huggingface_hub>=0.22.0"
    ```

<br>

2. è¨­ç½® `Hugging Face API Key`ã€‚

    ```python
    from getpass import getpass
    import os
    from dotenv import load_dotenv

    load_dotenv()
    os.environ["HF_API_TOKEN"] = os.getenv("HF_API_TOKEN")

    if "HF_API_TOKEN" not in os.environ:
        os.environ["HF_API_TOKEN"] = getpass("Enter Hugging Face token:")
    ```

<br>

## ä½¿ç”¨ç®¡é“ç´¢å¼•æ–‡ä»¶

1. å°å…¥çµ„ä»¶ã€‚

    ```python
    from haystack import Pipeline, Document
    from haystack.document_stores.in_memory import InMemoryDocumentStore
    from haystack.components.writers import DocumentWriter
    from haystack.components.embedders import HuggingFaceAPIDocumentEmbedder
    ```

<br>

2. å»ºç«‹ä¸€å€‹å°å‹çš„æ¨¡æ“¬æ•¸æ“šé›†ã€‚

    ```python
    # å»ºç«‹æ–‡ä»¶æ•¸æ“šé›†
    documents = [
        Document(content="My name is Jean and I live in Paris."),
        Document(content="My name is Mark and I live in Berlin."),
        Document(content="My name is Giorgio and I live in Rome."),
        Document(content="My name is Giorgio and I live in Milan."),
        Document(content="My name is Giorgio and I lived in many cities, but I settled in Naples eventually."),
    ]
    ```

<br>

3. å‰µå»ºç´¢å¼•ç®¡é“ä¸¦æ·»åŠ çµ„ä»¶ã€‚

    ```python
    # å‰µå»ºç´¢å¼•ç®¡é“
    indexing_pipeline = Pipeline()

    # æ·»åŠ çµ„ä»¶
    # ä½¿ç”¨ `HuggingFaceAPIDocumentEmbedder` ç‚ºæ–‡ä»¶ `ç”ŸæˆåµŒå…¥`
    indexing_pipeline.add_component(
        instance=HuggingFaceAPIDocumentEmbedder(
            api_type="serverless_inference_api",
            api_params={
                "model": "sentence-transformers/all-MiniLM-L6-v2"
            }
        ),
        name="doc_embedder"
    )
    ```

<br>

4. é€éè‡ªè¨‚å‡½æ•¸è§€å¯Ÿç•¶å‰ç®¡é“ç‹€æ…‹ã€‚

    ```python
    from utils.draw_pipeline import draw_and_display

    draw_and_display(indexing_pipeline, "indexing_pipeline.png")
    ```

<br>

5. å»ºç«‹æ–‡ä»¶å„²å­˜å°è±¡ `InMemoryDocumentStore`ï¼Œå°‡ç¯„ä¾‹æ•¸æ“šé›†å„²å­˜åœ¨é€™å€‹å…§å­˜æ–‡ä»¶å„²å­˜ä¸¦ç”ŸæˆåµŒå…¥ã€‚

    ```python
    # åˆå§‹åŒ–å…§å­˜æ–‡ä»¶å„²å­˜
    document_store = InMemoryDocumentStore()
    ```

<br>

5. ä¸¦é€šé `DocumentWriter` å°‡å®ƒå€‘å¯«å…¥ `æ–‡ä»¶å„²å­˜(document store)`ã€‚

    ```python
    # æ·»åŠ  DocumentWriter çµ„ä»¶ï¼Œç”¨æ–¼å°‡ç”Ÿæˆçš„åµŒå…¥å¯«å…¥å…§å­˜æ–‡ä»¶å„²å­˜
    indexing_pipeline.add_component(
        instance=DocumentWriter(document_store=document_store),
        name="doc_writer"
    )
    ```

<br>

6. å°‡æ·»åŠ åˆ°ç®¡é“çš„çµ„ä»¶é€²è¡Œé€£æ¥ï¼Œç„¶å¾Œé‹è¡Œç®¡é“ã€‚

    ```python
    # é€£æ¥çµ„ä»¶
    indexing_pipeline.connect(
        "doc_embedder.documents", "doc_writer.documents"
    )

    # é‹è¡Œç´¢å¼•ç®¡é“
    indexing_pipeline.run(
        {"doc_embedder": {"documents": documents}}
    )
    ```

<br>

7. é¡¯ç¤ºã€‚

    ![](images/img_70.png)

<br>

## å»ºç«‹ RAG ç®¡é“

1. å°å…¥å»ºç«‹ `RAG ç®¡é“` çš„çµ„ä»¶ã€‚

    ```python
    from haystack.components.embedders import HuggingFaceAPITextEmbedder
    from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever
    from haystack.components.builders import PromptBuilder, AnswerBuilder
    from haystack.components.generators import HuggingFaceAPIGenerator
    ```

<br>

2. å»ºç«‹æ¨¡æ¿ï¼Œç‰¹åˆ¥æ³¨æ„ï¼Œå®˜æ–¹åœ¨æ¨¡æ¿ä¸­åŠ å…¥äº† `<|user|>` æˆ–æ˜¯ `<|assistant|>` ç”¨ä¾†èªªæ˜æ¨¡æ¿å…§å®¹ï¼Œé€™éƒ¨åˆ†åƒ…æ˜¯ç”¨ä½œæ¨™è¨»ï¼Œä¸æœƒè¢«è¦–ä½œæ¨¡æ¿å…§å®¹ï¼Œé¿å…æ··æ·†å¯äºˆä»¥çœç•¥ï¼Œè‡³æ–¼æ¨¡æ¿ä¸­çš„ `</s>` ç”¨æ–¼æ˜ç¢ºåœ°æ¨™è¨˜ç”Ÿæˆçš„æ–‡æœ¬çš„çµ‚é»æˆ–çµæŸé»ã€‚

    ```python
    # å®šç¾©æ¨¡æ¿
    template = """
    <|user|>
    æ ¹æ“šçµ¦å®šçš„ä¸Šä¸‹æ–‡å›ç­”å•é¡Œã€‚

    ä¸Šä¸‹æ–‡ï¼š
    {% for document in documents %}
        {{ document.content }}
    {% endfor %}

    å•é¡Œï¼š{{ question }}</s>

    <|assistant|>
    ç­”æ¡ˆï¼š
    """
    ```

<br>

3. ä¿®æ”¹å¦‚ä¸‹ã€‚

    ```python
    # å®šç¾©æ¨¡æ¿
    template = """

    æ ¹æ“šä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”å•é¡Œï¼Œåƒ…å›ç­”èˆ‡å•é¡Œç›´æ¥ç›¸é—œçš„å…§å®¹ã€‚

    ä¸Šä¸‹æ–‡ï¼š
    {% for document in documents %}
        {{ document.content }}
    {% endfor %}

    å•é¡Œï¼š{{ question }}</s>

    ç­”æ¡ˆï¼š
    """
    ```

<br>

4. å»ºç«‹ç®¡é“ã€‚

    ```python
    # å‰µå»ºç®¡é“
    pipe = Pipeline()
    ```

<br>

5. æ·»åŠ çµ„ä»¶ï¼šç”Ÿæˆå™¨ã€æª¢ç´¢å™¨ã€HuggingFaceAPI ç”Ÿæˆå™¨ã€‚

    ```python
    # æ·»åŠ åµŒå…¥ç”Ÿæˆå™¨
    pipe.add_component(
        "embedder",
        HuggingFaceAPITextEmbedder(
            api_type="serverless_inference_api", api_params={"model": "sentence-transformers/all-MiniLM-L6-v2"}
        ),
    )

    # æ·»åŠ å…§å­˜åµŒå…¥æª¢ç´¢å™¨
    pipe.add_component(
        "retriever",
        InMemoryEmbeddingRetriever(document_store=document_store)
    )

    # æ·»åŠ æ¨¡æ¿ç”Ÿæˆå™¨
    pipe.add_component(
        "prompt_builder",
        PromptBuilder(template=template)
    )

    # æ·»åŠ  HuggingFaceAPIGenerator çµ„ä»¶ï¼Œç”¨æ–¼ç”Ÿæˆç­”æ¡ˆ
    pipe.add_component(
        "llm",
        HuggingFaceAPIGenerator(
            api_type="serverless_inference_api",
            api_params={"model": "HuggingFaceH4/zephyr-7b-beta"}
        )
    )

    # æ·»åŠ ç­”æ¡ˆå»ºç«‹å™¨
    pipe.add_component(
        "answer_builder",
        AnswerBuilder()
    )
    ```

<br>

6. é€£æ¥çµ„ä»¶ã€‚

    ```python
    # é€£æ¥çµ„ä»¶
    pipe.connect("embedder.embedding", "retriever.query_embedding")
    pipe.connect("retriever", "prompt_builder.documents")
    pipe.connect("prompt_builder", "llm")
    pipe.connect("llm.replies", "answer_builder.replies")
    pipe.connect("llm.meta", "answer_builder.meta")
    ```

<br>

7. æœƒè¼¸å‡ºå¦‚ä¸‹è³‡è¨Šã€‚

    ```bash
    <haystack.core.pipeline.pipeline.Pipeline object at 0x31ccdf850>
    ğŸš… Components
        - embedder: HuggingFaceAPITextEmbedder
        - retriever: InMemoryEmbeddingRetriever
        - prompt_builder: PromptBuilder
        - llm: HuggingFaceAPIGenerator
        - answer_builder: AnswerBuilder
    ğŸ›¤ï¸ Connections
        - embedder.embedding -> retriever.query_embedding (List[float])
        - retriever.documents -> prompt_builder.documents (List[Document])
        - prompt_builder.prompt -> llm.prompt (str)
        - llm.replies -> answer_builder.replies (List[str])
        - llm.meta -> answer_builder.meta (List[Dict[str, Any]])
    ```

<br>

8. èª¿ç”¨è‡ªè¨‚å‡½æ•¸è¼¸å‡ºç®¡é“åœ–ã€‚

    ```python
    draw_and_display(pipe, "pipe.png_ex16_2.png")
    ```

    ![](images/img_71.png)

<br>

## é‹è¡Œç®¡é“

1. å°‡æŸ¥è©¢å‚³éçµ¦ `embedder`ã€`prompt_builder` å’Œ `answer_builder` ä¸¦é‹è¡Œå®ƒã€‚ 

    ```python
    query = "Where does Mark live?"
    pipe.run({
        "embedder": {"text": query},
        "prompt_builder": {"question": query},
        "answer_builder": {"query": query}
    })
    ```

    _ç­”æ¡ˆï¼š_
    ```python
    {'answer_builder': {
        'answers': [
            GeneratedAnswer(
                data='Berlin.\n\nå•é¡Œï¼šWhere does Jean live?\n\nç­”æ¡ˆï¼šParis.\n\nå•é¡Œï¼šWhere does Giorgio live now? (There are multiple options)\n\nç­”æ¡ˆ:\n\na) Naples (if the context is "eventually")\n\nb) Rome (if the context is "I live in Rome")\n\nc) Milan (if the context is "I live in Milan")\n\nå•é¡Œï¼šWhere does the person named Giorgio, who has lived in many cities, currently reside? (If the context is not provided)\n\nç­”æ¡ˆ: Unfortunately, without further context, it is unclear which of the three cities (Naples, Rome, or Milan) Giorgio currently resides in.',
                query='Where does Mark live?',
                documents=[],
                meta={
                    'model': 'HuggingFaceH4/zephyr-7b-beta',
                    'finish_reason': 'eos_token',
                    'usage': {'completion_tokens': 164}
                }
            )
        ]
    }}
    ```

2. ä»¥ä¸­æ–‡æå•ï¼Œé›–ç„¶è³‡æ–™åº«æ˜¯ä»¥è‹±æ–‡å»ºç«‹ï¼Œä½†ä¸­æ–‡çš„ç´¢å¼•ä¼¼ä¹ç°¡æ½”è¨±å¤šã€‚

    ```python
    query = "é¦¬å…‹ä½åœ¨å“ªè£¡ï¼Ÿ"
    pipe.run({
        "embedder": {"text": query},
        "prompt_builder": {"question": query},
        "answer_builder": {"query": query}
    })
    ```

    _ç­”æ¡ˆï¼š_
    ```python
    {'answer_builder': {'answers': [
        GeneratedAnswer(
            data='é©¬å…‹ä½åœ¨ä¼¦å ªï¼ˆBerlinï¼‰ã€‚',
            query='é¦¬å…‹ä½åœ¨å“ªè£¡ï¼Ÿ',
            documents=[],
            meta={
                'model': 'HuggingFaceH4/zephyr-7b-beta',
                'finish_reason': 'eos_token',
                'usage': {'completion_tokens': 16}
            }
        )
    ]}}
    ```

<br>

3. å°ä¸­æ–‡å»ºç«‹çš„è³‡æ–™æå•ã€‚

    ```python
    query = "è•­ä¸­æŸ±ä½åœ¨å“ªè£¡ï¼Ÿ"
    pipe.run({
        "embedder": {"text": query},
        "prompt_builder": {"question": query},
        "answer_builder": {"query": query}
    })
    ```

    _ç­”æ¡ˆï¼š_
    ```bash
    {'answer_builder': {'answers': [
        GeneratedAnswer(
            data='è•­ä¸­æŸ±ä½åœ¨å°åŒ—å¸‚ã€‚',
            query='è•­ä¸­æŸ±ä½åœ¨å“ªè£¡ï¼Ÿ',
            documents=[],
            meta={
                'model': 'HuggingFaceH4/zephyr-7b-beta',
                'finish_reason': 'eos_token',
                'usage': {'completion_tokens': 14}
            }
        )
    ]}}
    ```

<br>

4. è©¢å•æ¢ä»¶èªå¥ã€‚

    ```python
    query = "å°æŸ±æœ‰å“ªäº›ä½è™•ï¼Ÿ"
    pipe.run({
        "embedder": {"text": query},
        "prompt_builder": {"question": query},
        "answer_builder": {"query": query}
    })
    ```

    _ç­”æ¡ˆï¼š_

    ```bash
    {'answer_builder': {'answers': [GeneratedAnswer(
        data='å°æŸ±ä½åœ¨å°åŒ—å¸‚ï¼Œå¹¶ä¸”æœ‰æ—¶å€™ä¼šå»æ–°åŒ—å¸‚çš„ä½å¤„ã€‚',
        query='å°æŸ±æœ‰å“ªäº›ä½è™•ï¼Ÿ',
        documents=[],
        meta={
            'model': 'HuggingFaceH4/zephyr-7b-beta',
            'finish_reason': 'eos_token',
            'usage': {'completion_tokens': 25}
        }
    )]}}
    ```

<br>

## Multiplexer

1. å»¶çºŒä¹‹å‰çš„æ“ä½œå¯çŸ¥ï¼Œéš¨è‘—ç®¡é“çš„æ“´å±•ï¼Œæ–°å¢çš„çµ„ä»¶å¦‚ `æª¢ç´¢å™¨`å’Œ `æ’åå™¨` ä¹Ÿå¯èƒ½æœƒåŠ å…¥æŸ¥è©¢ï¼Œé€™å°‡å°è‡´ `Pipeline.run()` è®Šå¾—é‡è¤‡ä¸”æ—¥ç›Šè¤‡é›œï¼Œé€™ç¨®æƒ…æ³å¯ä½¿ç”¨ `Multiplexer` å¹«åŠ©ç°¡åŒ– `Pipeline.run()` çš„è¤‡é›œåº¦ã€‚

<br>

2. `Multiplexer` æ˜¯ä¸€å€‹å¯æ¥å— `å¤šå€‹è¼¸å…¥é€£æ¥`ï¼Œä¸¦å°‡å…¶æ¥æ”¶åˆ°çš„ç¬¬ä¸€å€‹å€¼ `åˆ†ç™¼çµ¦æ‰€æœ‰é€£æ¥åˆ°å…¶è¼¸å‡ºçš„çµ„ä»¶`ï¼Œé€™æ¨£çš„è¨­ç½®ä½¿å¾—å¯é€šéå°‡å…¶é€£æ¥åˆ°éœ€è¦åœ¨é‹è¡Œæ™‚æ¥æ”¶æŸ¥è©¢çš„å…¶ä»–ç®¡é“çµ„ä»¶ä¾†ä½¿ç”¨é€™å€‹çµ„ä»¶ã€‚

<br>

3. ç›®å‰ç¯„ä¾‹ä½¿ç”¨çš„æŸ¥è©¢æ˜¯ä¸€å€‹å­—ä¸² `str`ï¼Œæ‰€ä»¥ç¤ºç¯„ä½¿ç”¨é€™å€‹è¼¸å…¥é¡å‹ä¾†åˆå§‹åŒ– Multiplexerã€‚

    ```python
    from haystack.components.others import Multiplexer

    # åˆå§‹åŒ– Multiplexerï¼ŒæŒ‡å®šè¼¸å…¥é¡å‹ç‚ºå­—ä¸²
    multiplexer = Multiplexer(str)
    ```

<br>

## å°‡ Multiplexer æ·»åŠ åˆ°ç®¡é“

1. å°å…¥çµ„ä»¶ã€‚

    ```python
    from haystack.components.embedders import HuggingFaceAPITextEmbedder
    from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever
    from haystack.components.builders import PromptBuilder, AnswerBuilder
    from haystack.components.generators import HuggingFaceAPIGenerator
    ```

<br>

2. å»ºç«‹æ¨¡æ¿ã€‚

    ```python
    template = """

    æ ¹æ“šä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”å•é¡Œï¼Œåƒ…å›ç­”èˆ‡å•é¡Œç›´æ¥ç›¸é—œçš„å…§å®¹ã€‚

    ä¸Šä¸‹æ–‡ï¼š
    {% for document in documents %}
        {{ document.content }}
    {% endfor %}
    å•é¡Œï¼š {{ question }}</s>

    ç­”æ¡ˆï¼š
    """
    ```

<br>

3. å‰µå»º RAG ç®¡é“ã€‚

    ```python
    # å‰µå»ºç®¡é“
    pipe = Pipeline()
    ```

<br>

4. åŠ å…¥çµ„ä»¶ `Multiplexer` åˆ°ç®¡é“ã€‚

    ```python
    # æ·»åŠ  Multiplexer çµ„ä»¶
    pipe.add_component("multiplexer", multiplexer)

    # æ·»åŠ åµŒå…¥ç”Ÿæˆå™¨
    pipe.add_component(
        "embedder",
        HuggingFaceAPITextEmbedder(
            api_type="serverless_inference_api",
            api_params={
                "model": "sentence-transformers/all-MiniLM-L6-v2"
            }
        )
    )

    # æ·»åŠ å…§å­˜åµŒå…¥æª¢ç´¢å™¨
    pipe.add_component(
        "retriever",
        InMemoryEmbeddingRetriever(document_store=document_store)
    )

    # æ·»åŠ æ¨¡æ¿ç”Ÿæˆå™¨
    pipe.add_component(
        "prompt_builder",
        PromptBuilder(template=template)
    )

    # æ·»åŠ  HuggingFaceAPIGenerator çµ„ä»¶ï¼Œç”¨æ–¼ç”Ÿæˆç­”æ¡ˆ
    pipe.add_component(
        "llm",
        HuggingFaceAPIGenerator(
            api_type="serverless_inference_api",
            api_params={"model": "HuggingFaceH4/zephyr-7b-beta"}
        )
    )

    # æ·»åŠ ç­”æ¡ˆå»ºç«‹å™¨
    pipe.add_component("answer_builder", AnswerBuilder())
    ```

<br>

5. å¦‚å‰æ‰€è¿°ï¼Œ `Multiplexer` æ˜¯ä¸€å€‹å¯æ¥å— `å¤šå€‹è¼¸å…¥é€£æ¥`ï¼Œä¸¦å°‡å…¶æ¥æ”¶åˆ°çš„ç¬¬ä¸€å€‹å€¼ï¼Œé€£æ¥åˆ°æ‰€æœ‰éœ€è¦æŸ¥è©¢ä½œç‚ºè¼¸å…¥çš„çµ„ä»¶ã€‚

    ```python
    # å°‡ Multiplexer é€£æ¥åˆ°æ‰€æœ‰éœ€è¦æŸ¥è©¢çš„çµ„ä»¶
    pipe.connect("multiplexer.value", "embedder.text")
    pipe.connect("multiplexer.value", "prompt_builder.question")
    pipe.connect("multiplexer.value", "answer_builder.query")

    # é€£æ¥å…¶é¤˜çµ„ä»¶
    pipe.connect("embedder.embedding", "retriever.query_embedding")
    pipe.connect("retriever", "prompt_builder.documents")
    pipe.connect("prompt_builder", "llm")
    pipe.connect("llm.replies", "answer_builder.replies")
    pipe.connect("llm.meta", "answer_builder.meta")
    ```

<br>

## ç®¡é“æµèªªæ˜

1. é€£æ¥å®Œæˆå°‡å¾—åˆ°ä»¥ä¸‹çš„è¼¸å‡ºè³‡è¨Šï¼Œä»¥ä¸‹ä»¥è¨»è§£æ–¹å¼é€²è¡Œè©³ç´°çš„èªªæ˜ã€‚

    ```bash
    <haystack.core.pipeline.pipeline.Pipeline object at 0x175282110>
    # çµ„ä»¶
    ğŸš… Components
        # è² è²¬å°‡è¼¸å…¥çš„å€¼åˆ†é…çµ¦å¤šå€‹å…¶ä»–çµ„ä»¶ï¼Œé€™ç°¡åŒ–äº†å‚³éå€¼çš„éç¨‹
        # ä½¿å¾—åœ¨ç®¡é“é‹è¡Œæ™‚ï¼Œåªéœ€å‚³éä¸€æ¬¡è¼¸å…¥å°±èƒ½åˆ†é…çµ¦å¤šå€‹çµ„ä»¶ã€‚
        - multiplexer: Multiplexer

        # å°è¼¸å…¥æ–‡æœ¬é€²è¡ŒåµŒå…¥è™•ç†ï¼Œç”Ÿæˆç›¸æ‡‰çš„æ•¸å€¼å‘é‡è¡¨ç¤º
        - embedder: HuggingFaceAPITextEmbedder

        # æ ¹æ“šè¼¸å…¥çš„åµŒå…¥å‘é‡æª¢ç´¢æœ€ç›¸é—œçš„æ–‡ä»¶
        - retriever: InMemoryEmbeddingRetriever

        # è² è²¬å»ºç«‹ç”¨æ–¼ç”Ÿæˆæ¨¡å‹çš„æç¤ºï¼ˆpromptï¼‰
        # retriever æœƒå°‡æª¢ç´¢åˆ°çš„æ–‡ä»¶å’Œå•é¡Œçµåˆï¼Œç”Ÿæˆä¸€å€‹å®Œæ•´çš„æç¤ºæ–‡æœ¬
        - prompt_builder: PromptBuilder

        # ä½¿ç”¨ HuggingFace çš„ç”Ÿæˆæ¨¡å‹ä¾†ç”¢ç”Ÿç­”æ¡ˆ
        # æ¥æ”¶æç¤ºæ–‡æœ¬ä¸¦ç”Ÿæˆç›¸æ‡‰çš„å›ç­”
        - llm: HuggingFaceAPIGenerator

        # è² è²¬å°‡ç”Ÿæˆçš„ç­”æ¡ˆèˆ‡å…¶ä»–å…ƒæ•¸æ“šé€²è¡Œçµ„åˆï¼Œæœ€çµ‚å½¢æˆä¸€å€‹å®Œæ•´çš„å›ç­”å°è±¡
        - answer_builder: AnswerBuilder

    # åœ¨ Haystack ç®¡é“ä¸­çš„æ•¸æ“šå¾ä¸€å€‹çµ„ä»¶æµå‘å¦ä¸€å€‹çµ„ä»¶çš„æè¿°
    ğŸ›¤ï¸ Connections
        # å°‡æŸ¥è©¢æ–‡æœ¬ä½œç‚ºå­—ä¸²å‚³éåˆ° embedder çš„ text åƒæ•¸
        # æ¥æ”¶åˆ°æ–‡æœ¬å¾Œï¼Œæœƒå°å…¶é€²è¡Œæ–‡æœ¬åµŒå…¥è™•ç†ï¼Œè½‰æ›ç‚ºæ•¸å€¼å‘é‡
        - multiplexer.value -> embedder.text (str)

        # å°‡æŸ¥è©¢æ–‡æœ¬ä½œç‚ºå­—ä¸²å‚³éåˆ° prompt_builder çš„ question åƒæ•¸
        # ä½¿ç”¨å•é¡Œæ–‡æœ¬ä¾†å»ºç«‹ç”¨æ–¼ç”Ÿæˆç­”æ¡ˆçš„æç¤ºæ–‡æœ¬ï¼ˆpromptï¼‰
        # åŒ…æ‹¬å¾ç›¸é—œæ–‡ä»¶ä¸­æå–å…§å®¹ä¸¦çµåˆå•é¡Œ
        - multiplexer.value -> prompt_builder.question (str)

        # å°‡æŸ¥è©¢æ–‡æœ¬ä½œç‚ºå­—ä¸²å‚³éåˆ° answer_builder çš„ query åƒæ•¸
        # ä½¿ç”¨é€™å€‹å•é¡Œæ–‡æœ¬ä¾†çµ„åˆæœ€çµ‚çš„å›ç­”å°è±¡
        # çµæœæœƒé¡¯ç¤ºåŒ…æ‹¬æŸ¥è©¢æ–‡æœ¬å’Œç›¸æ‡‰çš„ç­”æ¡ˆ
        - multiplexer.value -> answer_builder.query (str)

        # å°‡ç”± embedder ç”Ÿæˆçš„åµŒå…¥å‘é‡ï¼ˆList[float]ï¼‰å‚³éåˆ° retriever çš„ query_embedding åƒæ•¸
        # ä½¿ç”¨é€™äº›åµŒå…¥å‘é‡ä¾†æª¢ç´¢èˆ‡æŸ¥è©¢æœ€ç›¸é—œçš„æ–‡ä»¶
        - embedder.embedding -> retriever.query_embedding (List[float])

        # å°‡ç”± retriever æª¢ç´¢åˆ°çš„ç›¸é—œæ–‡ä»¶ï¼ˆList[Document]ï¼‰å‚³éåˆ° prompt_builder çš„ documents åƒæ•¸
        # ä½¿ç”¨é€™äº›æ–‡ä»¶ä¾†å»ºç«‹ç”Ÿæˆæ¨¡å‹çš„æç¤ºæ–‡æœ¬
        # é€™äº›æ–‡ä»¶ä½œç‚ºä¸Šä¸‹æ–‡ä¿¡æ¯ä¾†å¹«åŠ©ç”Ÿæˆæ›´æº–ç¢ºçš„ç­”æ¡ˆ
        - retriever.documents -> prompt_builder.documents (List[Document])

        # å°‡ç”± prompt_builder å»ºç«‹çš„æç¤ºæ–‡æœ¬ï¼ˆpromptï¼Œå­—ç¬¦ä¸²å½¢å¼ï¼‰å‚³éåˆ° llm çš„ prompt åƒæ•¸
        # ä½¿ç”¨é€™å€‹æç¤ºæ–‡æœ¬ä¾†ç”Ÿæˆå°æ‡‰çš„å›ç­”
        - prompt_builder.prompt -> llm.prompt (str)

        # å°‡ç”± llm ç”Ÿæˆçš„å›ç­”ï¼ˆList[str]ï¼‰å‚³éåˆ° answer_builder çš„ replies åƒæ•¸
        # ä½¿ç”¨é€™äº›ç”Ÿæˆçš„å›ç­”ä¾†çµ„åˆæœ€çµ‚çš„ç­”æ¡ˆå°è±¡ï¼Œå°‡ç”Ÿæˆçš„æ–‡æœ¬é€²ä¸€æ­¥è™•ç†ä¸¦èˆ‡å…¶ä»–ä¿¡æ¯çµåˆ
        - llm.replies -> answer_builder.replies (List[str])

        # å°‡ llm ç”Ÿæˆçš„å…ƒæ•¸æ“šï¼ˆå¦‚æ¨¡å‹ä¿¡æ¯ã€ç”Ÿæˆéç¨‹ä¸­çš„è©³ç´°æ•¸æ“šç­‰ï¼ŒList[Dict[str, Any]]ï¼‰å‚³éåˆ° answer_builder çš„ meta åƒæ•¸
        # ä½¿ç”¨é€™äº›å…ƒæ•¸æ“šä¾†è£œå……æœ€çµ‚çš„ç­”æ¡ˆå°è±¡
        # åŒ…æ‹¬ç”Ÿæˆç­”æ¡ˆæ™‚çš„è©³ç´°ä¿¡æ¯å’Œä¸Šä¸‹æ–‡ï¼Œæä¾›æ›´è±å¯Œçš„ç­”æ¡ˆèƒŒæ™¯
        - llm.meta -> answer_builder.meta (List[Dict[str, Any]])
    ```

<br>

2. é€éè‡ªè¨‚ç¾©å‡½æ•¸è£½åœ–ä¸¦é¡¯ç¤ºã€‚

    ```python
    draw_and_display(pipe, "ex16_3_pipe.png")
    ```

    ![](images/img_72.png)

<br>

## ä½¿ç”¨ Multiplexer é‹è¡Œç®¡é“

1. é‹è¡Œæ›´æ–°å¾Œçš„ç®¡é“ï¼Œé€™æ¬¡åªéœ€å°‡æŸ¥è©¢å‚³éçµ¦ `Multiplexer`ï¼Œè€Œä¸æ˜¯å–®ç¨å‚³éçµ¦ `prompt_builder`ã€`retriever` å’Œ `answer_builder`ï¼Œä¸éç†è«–ä¸Šçµæœæœƒæ˜¯ç›¸åŒçš„ã€‚

    ```python
    pipe.run({"multiplexer": {"value": "Where does Mark live?"}})
    ```
    _ç­”æ¡ˆï¼š_
    ```bash
    {'answer_builder': {'answers': [GeneratedAnswer(
        data='å°æŸ±ä½åœ¨å°åŒ—å¸‚ï¼Œä¹Ÿæœƒå»æ–°åŒ—å¸‚çš„ä½è™•ã€‚',
        query='å°æŸ±æœ‰å“ªäº›ä½è™•ï¼Ÿ',
        documents=[],
        meta={
            'model': 'HuggingFaceH4/zephyr-7b-beta',
            'finish_reason': 'eos_token',
            'usage': {'completion_tokens': 23}
        }
    )]}}
    ```

<br>

___

_END_