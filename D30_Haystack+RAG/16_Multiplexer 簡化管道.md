# ä½¿ç”¨ Multiplexer ç°¡åŒ–ç®¡é“è¼¸å…¥

![](images/img_69.png)

## èªªæ˜

1. é€™æ˜¯å®˜æ–¹åœ¨ `2024/05/10` ç™¼ä½ˆçš„ [å®˜æ–¹æ•™ç¨‹](https://haystack.deepset.ai/tutorials/37_simplifying_pipeline_inputs_with_multiplexer)ï¼Œå¦å¤–éœ€è¦æ­é… `Hugging Face API Key` ä½¿ç”¨ï¼Œæ•´é«”ç›®æ¨™æ˜¯ä½¿ç”¨ Multiplexer ç°¡åŒ– `RAG ç®¡é“` ä¸­çš„ `Pipeline.run()` çš„è¼¸å…¥ã€‚

2. åœ¨æ§‹å»ºè¶…é 3 æˆ– 4 å€‹çµ„ä»¶çš„ Haystack ç®¡é“æ™‚ï¼Œå¯æ³¨æ„åˆ°å‚³éçµ¦ `Pipeline.run()` æ–¹æ³•çš„è¼¸å…¥æ•¸é‡æœƒç„¡é™å¢é•·ï¼Œæ–°çš„çµ„ä»¶æœƒå¾ç®¡é“ä¸­çš„å…¶ä»–çµ„ä»¶æ¥æ”¶ä¸€äº›è¼¸å…¥ï¼Œä½†è¨±å¤šçµ„ä»¶ä¹Ÿéœ€è¦ä¾†è‡ªç”¨æˆ¶çš„é¡å¤–è¼¸å…¥ï¼Œå› æ­¤ `Pipeline.run()` çš„æ•¸æ“šè¼¸å…¥æœƒè®Šå¾—éå¸¸é‡è¤‡ï¼Œé€™å€‹ç‹€æ³å¯é€é `Multiplexer` æœ‰æ•ˆåœ°ç®¡ç†é€™äº›é‡è¤‡ã€‚

## ä½¿ç”¨çš„çµ„ä»¶

1. `Multiplexer`ï¼š

2. `InMemoryDocumentStore`ï¼š

3. `HuggingFaceAPIDocumentEmbedder`ï¼š

4. `HuggingFaceAPITextEmbedder`ï¼š

5. `InMemoryEmbeddingRetriever`ï¼š

6. `PromptBuilder`ï¼š

7. `HuggingFaceAPIGenerator`ï¼š

8. `AnswerBuilder`ï¼š


## é–‹å§‹

1. å®‰è£ä¾è³´åº«ã€‚

```bash
pip install haystack-ai "huggingface_hub>=0.22.0"
```

2. è¨­ç½® `Hugging Face API Key`ã€‚

```python
from getpass import getpass
import os
from dotenv import load_dotenv

load_dotenv()
os.environ["HF_API_TOKEN"] = os.getenv("HF_API_TOKEN")

if "HF_API_TOKEN" not in os.environ:
    os.environ["HF_API_TOKEN"] = getpass("Enter Hugging Face token:")
```

## ä½¿ç”¨ç®¡é“ç´¢å¼•æ–‡ä»¶

1. å°å…¥çµ„ä»¶ã€‚
```python
from haystack import Pipeline, Document
from haystack.document_stores.in_memory import InMemoryDocumentStore
from haystack.components.writers import DocumentWriter
from haystack.components.embedders import HuggingFaceAPIDocumentEmbedder
```


2. æ¨¡çµ„å°å‹çš„æ•¸æ“šé›†ã€‚
```python
# å»ºç«‹æ–‡ä»¶æ•¸æ“šé›†
documents = [
    Document(content="My name is Jean and I live in Paris."),
    Document(content="My name is Mark and I live in Berlin."),
    Document(content="My name is Giorgio and I live in Rome."),
    Document(content="My name is Giorgio and I live in Milan."),
    Document(content="My name is Giorgio and I lived in many cities, but I settled in Naples eventually."),
]
```

3. å‰µå»ºç´¢å¼•ç®¡é“ä¸¦æ·»åŠ çµ„ä»¶ã€‚
```python
# å‰µå»ºç´¢å¼•ç®¡é“
indexing_pipeline = Pipeline()

# æ·»åŠ çµ„ä»¶
# ä½¿ç”¨ `HuggingFaceAPIDocumentEmbedder` ç‚ºæ–‡ä»¶ `ç”ŸæˆåµŒå…¥`
indexing_pipeline.add_component(
    instance=HuggingFaceAPIDocumentEmbedder(
        api_type="serverless_inference_api",
        api_params={
            "model": "sentence-transformers/all-MiniLM-L6-v2"
        }
    ),
    name="doc_embedder"
)
```

4. å»ºç«‹æ–‡ä»¶å„²å­˜å°è±¡ `InMemoryDocumentStore`ï¼Œå°‡ç¯„ä¾‹æ•¸æ“šé›†å„²å­˜åœ¨é€™å€‹å…§å­˜æ–‡ä»¶å„²å­˜ä¸¦ç”ŸæˆåµŒå…¥ã€‚

```python
# åˆå§‹åŒ–å…§å­˜æ–‡ä»¶å„²å­˜
document_store = InMemoryDocumentStore()
```

5. ä¸¦é€šé `DocumentWriter` å°‡å®ƒå€‘å¯«å…¥ `æ–‡ä»¶å„²å­˜(document store)`ã€‚
```python
# æ·»åŠ  DocumentWriter çµ„ä»¶ï¼Œç”¨æ–¼å°‡ç”Ÿæˆçš„åµŒå…¥å¯«å…¥å…§å­˜æ–‡ä»¶å„²å­˜
indexing_pipeline.add_component(
    instance=DocumentWriter(document_store=document_store),
    name="doc_writer"
)
```

6. å°‡æ·»åŠ åˆ°ç®¡é“çš„çµ„ä»¶é€²è¡Œé€£æ¥ï¼Œç„¶å¾Œé‹è¡Œç®¡é“ã€‚
```python
# é€£æ¥çµ„ä»¶
indexing_pipeline.connect(
    "doc_embedder.documents", "doc_writer.documents"
)

# é‹è¡Œç´¢å¼•ç®¡é“
indexing_pipeline.run(
    {"doc_embedder": {"documents": documents}}
)
```

## æ§‹å»º RAG ç®¡é“

1. å°å…¥æ§‹å»º `RAG ç®¡é“` çš„çµ„ä»¶ã€‚

```python
from haystack.components.embedders import HuggingFaceAPITextEmbedder
from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever
from haystack.components.builders import PromptBuilder, AnswerBuilder
from haystack.components.generators import HuggingFaceAPIGenerator
```


2. å»ºç«‹æ¨¡æ¿ã€‚

```python
# å®šç¾©æ¨¡æ¿
template = """
<|user|>
æ ¹æ“šçµ¦å®šçš„ä¸Šä¸‹æ–‡å›ç­”å•é¡Œã€‚

ä¸Šä¸‹æ–‡ï¼š
{% for document in documents %}
    {{ document.content }}
{% endfor %}

å•é¡Œï¼š{{ question }}</s>

<|assistant|>
ç­”æ¡ˆï¼š
"""
```

3. å»ºç«‹ç®¡é“ã€‚
```python
# å‰µå»ºç®¡é“
pipe = Pipeline()
```

4. æ·»åŠ çµ„ä»¶ï¼šç”Ÿæˆå™¨ã€æª¢ç´¢å™¨ã€HuggingFaceAPI ç”Ÿæˆå™¨ã€‚
```python
# æ·»åŠ åµŒå…¥ç”Ÿæˆå™¨
pipe.add_component(
    "embedder",
    HuggingFaceAPITextEmbedder(
        api_type="serverless_inference_api", api_params={"model": "sentence-transformers/all-MiniLM-L6-v2"}
    ),
)

# æ·»åŠ å…§å­˜åµŒå…¥æª¢ç´¢å™¨
pipe.add_component(
    "retriever",
    InMemoryEmbeddingRetriever(document_store=document_store)
)

# æ·»åŠ æ¨¡æ¿ç”Ÿæˆå™¨
pipe.add_component(
    "prompt_builder",
    PromptBuilder(template=template)
)

# æ·»åŠ  HuggingFaceAPIGenerator çµ„ä»¶ï¼Œç”¨æ–¼ç”Ÿæˆç­”æ¡ˆ
pipe.add_component(
    "llm",
    HuggingFaceAPIGenerator(
        api_type="serverless_inference_api",
        api_params={"model": "HuggingFaceH4/zephyr-7b-beta"}
    )
)

# æ·»åŠ ç­”æ¡ˆæ§‹å»ºå™¨
pipe.add_component(
    "answer_builder",
    AnswerBuilder()
)
```

5. é€£æ¥çµ„ä»¶ã€‚
```python
# é€£æ¥çµ„ä»¶
pipe.connect("embedder.embedding", "retriever.query_embedding")
pipe.connect("retriever", "prompt_builder.documents")
pipe.connect("prompt_builder", "llm")
pipe.connect("llm.replies", "answer_builder.replies")
pipe.connect("llm.meta", "answer_builder.meta")
```

---

## é‹è¡Œç®¡é“

å°‡æŸ¥è©¢å‚³éçµ¦ `embedder`ã€`prompt_builder` å’Œ `answer_builder` ä¸¦é‹è¡Œå®ƒï¼š

```python
query = "Where does Mark live?"
pipe.run({"embedder": {"text": query}, "prompt_builder": {"question": query}, "answer_builder": {"query": query}})
```

åœ¨é€™å€‹åŸºæœ¬çš„ RAG ç®¡é“ä¸­ï¼Œéœ€è¦æŸ¥è©¢ä¾†æ“ä½œçš„çµ„ä»¶æœ‰ `embedder`ã€`prompt_builder` å’Œ `answer_builder`ã€‚ä½†æ˜¯ï¼Œéš¨è‘—ç®¡é“çš„æ“´å±•ï¼Œæ–°å¢çš„çµ„ä»¶å¦‚æª¢ç´¢å™¨å’Œæ’åå™¨ä¹Ÿå¯èƒ½éœ€è¦æŸ¥è©¢ï¼Œé€™æœƒå°è‡´ `Pipeline.run()` èª¿ç”¨è®Šå¾—éå¸¸é‡è¤‡ä¸”æ—¥ç›Šè¤‡é›œã€‚åœ¨é€™ç¨®æƒ…æ³ä¸‹ï¼Œä½¿ç”¨ Multiplexer å¯ä»¥å¹«åŠ©ç°¡åŒ–å’Œæ¸›å°‘ `Pipeline.run()` çš„è¤‡é›œåº¦ã€‚

---

## ä»‹ç´¹ Multiplexer

Multiplexer æ˜¯ä¸€å€‹å¯ä»¥æ¥å—å¤šå€‹è¼¸å…¥é€£æ¥ï¼Œä¸¦å°‡å…¶æ¥æ”¶åˆ°çš„ç¬¬ä¸€å€‹å€¼åˆ†ç™¼çµ¦æ‰€æœ‰é€£æ¥åˆ°å…¶è¼¸å‡ºçš„çµ„ä»¶ã€‚åœ¨é€™ç¨®è¨­ç½®ä¸­ï¼Œæ‚¨å¯ä»¥é€šéå°‡å…¶é€£æ¥åˆ°éœ€è¦åœ¨é‹è¡Œæ™‚æ¥æ”¶æŸ¥è©¢çš„å…¶ä»–ç®¡é“çµ„ä»¶ä¾†ä½¿ç”¨é€™å€‹çµ„ä»¶ã€‚

ç¾åœ¨ï¼Œç”¨æœŸæœ›çš„è¼¸å…¥é¡å‹ï¼ˆåœ¨é€™ç¨®æƒ…æ³ä¸‹æ˜¯ `str`ï¼Œå› ç‚ºæŸ¥è©¢æ˜¯ä¸€å€‹å­—ç¬¦ä¸²ï¼‰åˆå§‹åŒ– Multiplexerï¼š

```python
from haystack.components.others import Multiplexer

# åˆå§‹åŒ– Multiplexerï¼ŒæŒ‡å®šè¼¸å…¥é¡å‹ç‚ºå­—ç¬¦ä¸²
multiplexer = Multiplexer(str)
```

---

## å°‡ Multiplexer æ·»åŠ åˆ°ç®¡é“

å‰µå»ºç›¸åŒçš„ RAG ç®¡é“ï¼Œä½†é€™æ¬¡åŠ å…¥ Multiplexerã€‚å°‡ Multiplexer æ·»åŠ åˆ°ç®¡é“ä¸¦é€£æ¥åˆ°æ‰€æœ‰éœ€è¦æŸ¥è©¢ä½œç‚ºè¼¸å…¥çš„çµ„ä»¶ï¼š

```python
from haystack.components.embedders import HuggingFaceAPITextEmbedder
from haystack.components.retrievers.in_memory import InMemoryEmbedding

Retriever
from haystack.components.builders import PromptBuilder, AnswerBuilder
from haystack.components.generators import HuggingFaceAPIGenerator

template = """
 
 Answer the question based on the given context.

Context:
{% for document in documents %}
    {{ document.content }}
{% endfor %}
Question: {{ question }}</s>

Answer:
"""

# å‰µå»ºç®¡é“
pipe = Pipeline()

# æ·»åŠ  Multiplexer çµ„ä»¶
pipe.add_component("multiplexer", multiplexer)

# æ·»åŠ åµŒå…¥ç”Ÿæˆå™¨
pipe.add_component(
    "embedder",
    HuggingFaceAPITextEmbedder(
        api_type="serverless_inference_api", api_params={"model": "sentence-transformers/all-MiniLM-L6-v2"}
    ),
)

# æ·»åŠ å…§å­˜åµŒå…¥æª¢ç´¢å™¨
pipe.add_component("retriever", InMemoryEmbeddingRetriever(document_store=document_store))

# æ·»åŠ æ¨¡æ¿ç”Ÿæˆå™¨
pipe.add_component("prompt_builder", PromptBuilder(template=template))

# æ·»åŠ  HuggingFaceAPIGenerator çµ„ä»¶ï¼Œç”¨æ–¼ç”Ÿæˆç­”æ¡ˆ
pipe.add_component(
    "llm",
    HuggingFaceAPIGenerator(api_type="serverless_inference_api", api_params={"model": "HuggingFaceH4/zephyr-7b-beta"}),
)

# æ·»åŠ ç­”æ¡ˆæ§‹å»ºå™¨
pipe.add_component("answer_builder", AnswerBuilder())

# å°‡ Multiplexer é€£æ¥åˆ°æ‰€æœ‰éœ€è¦æŸ¥è©¢çš„çµ„ä»¶
pipe.connect("multiplexer.value", "embedder.text")
pipe.connect("multiplexer.value", "prompt_builder.question")
pipe.connect("multiplexer.value", "answer_builder.query")

# é€£æ¥å…¶é¤˜çµ„ä»¶
pipe.connect("embedder.embedding", "retriever.query_embedding")
pipe.connect("retriever", "prompt_builder.documents")
pipe.connect("prompt_builder", "llm")
pipe.connect("llm.replies", "answer_builder.replies")
pipe.connect("llm.meta", "answer_builder.meta")
```

---

## ä½¿ç”¨ Multiplexer é‹è¡Œç®¡é“

é‹è¡Œæ›´æ–°å¾Œçš„ç®¡é“ï¼Œé€™æ¬¡æ‚¨åªéœ€å°‡æŸ¥è©¢å‚³éçµ¦ Multiplexerï¼Œè€Œä¸æ˜¯å–®ç¨å‚³éçµ¦ `prompt_builder`ã€`retriever` å’Œ `answer_builder`ï¼Œçµæœæœƒç›¸åŒã€‚

```python
pipe.run({"multiplexer": {"value": "Where does Mark live?"}})
```

---

## ä¸‹ä¸€æ­¥

ğŸ‰ æ­å–œï¼æ‚¨å·²ç¶“å­¸æœƒå¦‚ä½•ä½¿ç”¨ Multiplexer ç°¡åŒ–ç®¡é“é‹è¡Œï¼

å¦‚æœæ‚¨å–œæ­¡é€™å€‹æ•™ç¨‹ï¼Œé‚„æœ‰æ›´å¤šé—œæ–¼ Haystack 2.0 çš„çŸ¥è­˜ç­‰è‘—æ‚¨å­¸ç¿’ï¼š

- å‰µå»ºæ··åˆæª¢ç´¢ç®¡é“
- ä½¿ç”¨æ¢ä»¶è·¯ç”±æ§‹å»ºå¾Œå‚™æ–¹æ¡ˆé€²è¡Œ Web æª¢ç´¢
- åŸºæ–¼æ¨¡å‹çš„ RAG ç®¡é“è©•ä¼°

è‹¥æƒ³äº†è§£æœ€æ–°çš„ Haystack å‹•æ…‹ï¼Œæ‚¨å¯ä»¥è¨‚é–±æˆ‘å€‘çš„æ–°èç°¡å ±æˆ–åŠ å…¥ Haystack Discord ç¤¾å€ã€‚

æ„Ÿè¬é–±è®€ï¼