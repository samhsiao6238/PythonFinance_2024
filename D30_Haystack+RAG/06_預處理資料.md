# é è™•ç†ä¸åŒæ–‡ä»¶é¡å‹

_ä½¿ç”¨ `FileTypeRouter`_

## èªªæ˜

1. ä½¿ç”¨ [Haystack 2.0](https://haystack.deepset.ai/overview/quick-start)ï¼Œå¯æŸ¥è©¢å®˜æ–¹ [Haystack 2.0 æ–‡ä»¶](https://haystack.deepset.ai/docs/latest).

2. å»ºç«‹ç´¢å¼•ç®¡é“å¾Œï¼Œé‚„å¯æ­é… `Hugging Face API` ä¾†å½™æ•´æ–‡ä»¶å„²å­˜æ§‹å»º RAG ç®¡é“ã€‚

3. é€™å€‹ç¯„ä¾‹çš„ç›®æ¨™æ˜¯æ§‹å»ºä¸€å€‹ç´¢å¼•ç®¡é“ï¼Œè©²ç®¡é“å¯ä»¥é è™•ç†ä¸åŒé¡å‹çš„æ–‡ä»¶ï¼ŒåŒ…æ‹¬ Markdownã€TXT å’Œ PDF æ–‡ä»¶ã€‚æ¯ç¨®æ–‡ä»¶é¡å‹éƒ½éœ€è¦ä½¿ç”¨ç‰¹å®šçš„æ–‡ä»¶è½‰æ›å™¨ä¾†é€²è¡Œè™•ç†ã€‚é€™äº›è½‰æ›å™¨å°‡å„è‡ªçš„æ–‡ä»¶æ ¼å¼è½‰æ›ç‚ºæ¨™æº–çš„ Haystack æ–‡ä»¶æ ¼å¼ã€‚

## æ–‡ä»¶è½‰æ›å™¨

1. MarkdownToDocumentï¼šå°‡ Markdown æ–‡ä»¶è½‰æ›ç‚º Haystack æ–‡ä»¶ã€‚
2. TextFileToDocumentï¼šå°‡æ–‡æœ¬æ–‡ä»¶ï¼ˆå¦‚ TXTï¼‰è½‰æ›ç‚º Haystack æ–‡ä»¶ã€‚
3. PyPDFToDocumentï¼šå°‡ PDF æ–‡ä»¶è½‰æ›ç‚º Haystack æ–‡ä»¶ã€‚

## ç´¢å¼•ç®¡é“çš„å…¶ä»–æ­¥é©Ÿ

_ä¸€æ—¦æ‰€æœ‰æ–‡ä»¶éƒ½è¢«è½‰æ›ç‚º Haystack æ–‡ä»¶æ ¼å¼ï¼Œç´¢å¼•ç®¡é“çš„å…¶é¤˜éƒ¨åˆ†ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å¹¾å€‹æ¨™æº–æ­¥é©Ÿ_

1. æ–‡ä»¶æ¸…ç†ï¼ˆDocumentCleanerï¼‰ï¼šå»é™¤æ–‡ä»¶ä¸­çš„å¤šé¤˜ç©ºç™½å’Œå…¶ä»–ä¸éœ€è¦çš„å­—ç¬¦ï¼Œä½¿æ–‡ä»¶æ›´åŠ æ•´æ½”ã€‚

2. æ–‡ä»¶åˆ†å¡Šï¼ˆDocumentSplitterï¼‰ï¼šå°‡æ–‡ä»¶åˆ†æˆå°å¡Šï¼ˆä¾‹å¦‚æ¯å¡Š 150 å€‹å–®è©ï¼‰ï¼Œé€™æ¨£å¯ä»¥æ›´æ–¹ä¾¿åœ°é€²è¡Œæª¢ç´¢å’Œåˆ†æï¼Œä¸¦ä¸”å¯ä»¥é¿å…ä¸Ÿå¤±ä¸Šä¸‹æ–‡ã€‚

3. å‰µå»ºåµŒå…¥ï¼ˆSentenceTransformersDocumentEmbedderï¼‰ï¼šä½¿ç”¨åµŒå…¥æ¨¡å‹ï¼ˆä¾‹å¦‚ `sentence-transformers/all-MiniLM-L6-v2`ï¼‰ç‚ºæ–‡ä»¶å‰µå»ºåµŒå…¥å‘é‡ï¼Œé€™äº›å‘é‡ç”¨æ–¼å¾ŒçºŒçš„æ–‡æœ¬æª¢ç´¢å’ŒæŸ¥è©¢ã€‚

4. å¯«å…¥æ–‡ä»¶å„²å­˜ï¼ˆDocumentWriterï¼‰ï¼šæœ€å¾Œï¼Œå°‡è™•ç†å¥½çš„æ–‡ä»¶å¯«å…¥åˆ°æ–‡ä»¶å„²å­˜ï¼ˆä¾‹å¦‚ `InMemoryDocumentStore`ï¼‰ä¸­ï¼Œé€™æ¨£å¯ä»¥åœ¨å¾ŒçºŒçš„æŸ¥è©¢ä¸­é€²è¡Œé«˜æ•ˆæª¢ç´¢ã€‚

## å…¶ä»–é‡è¦æ¨¡çµ„

1. FileTypeRouterï¼šæ˜¯ä¸€å€‹è·¯ç”±å™¨ï¼Œç”¨æ–¼æ ¹æ“šæ–‡ä»¶çš„ MIME é¡å‹å°‡æ–‡ä»¶è·¯ç”±åˆ°ä¸åŒçš„æ¨¡çµ„æˆ–è½‰æ›å™¨ã€‚ç•¶æ–‡ä»¶ä¾†è‡ªä¸åŒçš„æ•¸æ“šæºï¼Œä¸”æ¯å€‹æ–‡ä»¶çš„é¡å‹ä¸åŒï¼ˆå¦‚ PDFã€Markdown æˆ– TXT æ–‡ä»¶ï¼‰æ™‚ï¼ŒFileTypeRouter å¯ä»¥æ ¹æ“šæ–‡ä»¶çš„ MIME é¡å‹å°‡å…¶è·¯ç”±åˆ°ç›¸æ‡‰çš„æ–‡ä»¶è½‰æ›å™¨é€²è¡Œè™•ç†ï¼Œé€™æ¨£å¯ä»¥ç¢ºä¿æ¯å€‹æ–‡ä»¶éƒ½èƒ½è¢«æ­£ç¢ºåœ°è½‰æ›æˆ Haystack æ–‡ä»¶æ ¼å¼ã€‚

2. DocumentJoinerï¼šç”¨æ–¼å°‡ä¾†è‡ªä¸åŒç®¡é“åˆ†æ”¯çš„æ–‡ä»¶åˆä½µæˆä¸€å€‹çµ±ä¸€çš„æ–‡ä»¶åˆ—è¡¨ï¼Œç•¶ä¸åŒçš„æ–‡ä»¶é¡å‹è¢«ä¸åŒçš„è½‰æ›å™¨è™•ç†ä¸¦ç”Ÿæˆ Haystack æ–‡ä»¶å¾Œï¼ŒDocumentJoiner å°‡é€™äº›åˆ†æ•£çš„æ–‡ä»¶åˆä½µæˆä¸€å€‹çµ±ä¸€çš„æ–‡ä»¶åˆ—è¡¨ï¼Œä»¥ä¾¿å¾ŒçºŒçš„æ¸…ç†ã€åˆ†å¡Šå’ŒåµŒå…¥è™•ç†ã€‚



## é–‹å§‹

1. å®‰è£ä¾è³´ã€‚

```bash
pip install haystack-ai
pip install "sentence-transformers>=2.2.0" "huggingface_hub>=0.22.0"
pip install markdown-it-py mdit_plain pypdf
# ä¸‹è¼‰æ–‡ä»¶
pip install gdown
```

2. ä¸‹è¼‰æ‰€æœ‰æ–‡ä»¶ã€‚

```python
import gdown

url = "https://drive.google.com/drive/folders/1n9yqq5Gl_HWfND5bTlrCwAOycMDt5EMj"
output_dir = "recipe_files"

gdown.download_folder(url, quiet=True, output=output_dir)
```

3. å‰µå»ºç´¢å¼•æ–‡ä»¶çš„ç®¡é“ï¼šä½¿ç”¨ `InMemoryDocumentStore`ï¼Œä½†æ­¤æ–¹æ³•ä¹Ÿé©ç”¨æ–¼ä»»ä½•å…¶ä»–é¡å‹çš„ `DocumentStore`ï¼Œéœ€è¦ç‚ºæ•¸æ“šæºä¸­çš„æ¯ç¨®é¡å‹çš„æ–‡ä»¶ä½¿ç”¨ä¸åŒçš„æ–‡ä»¶è½‰æ›å™¨é¡ï¼šPDFã€TXT å’Œ MD æ–‡ä»¶ï¼Œ `FileTypeRouter` å°‡æ¯ç¨®é¡å‹çš„æ–‡ä»¶é€£æ¥åˆ°é©ç•¶çš„è½‰æ›å™¨ã€‚å°‡æ‰€æœ‰æ–‡ä»¶è½‰æ›ç‚º Haystack æ–‡ä»¶å¾Œï¼Œä¾¿å¯ä½¿ç”¨ `DocumentJoiner` æ¨¡çµ„å°‡é€™äº›æ–‡ä»¶åˆä½µæˆä¸€å€‹æ–‡ä»¶åˆ—è¡¨ï¼Œç„¶å¾Œä¸€èµ·å‚³éçµ¦ç´¢å¼•ç®¡é“çš„å…¶é¤˜éƒ¨åˆ†ã€‚

```python
from haystack.components.writers import DocumentWriter
from haystack.components.converters import MarkdownToDocument, PyPDFToDocument, TextFileToDocument
from haystack.components.preprocessors import DocumentSplitter, DocumentCleaner
from haystack.components.routers import FileTypeRouter
from haystack.components.joiners import DocumentJoiner
from haystack.components.embedders import SentenceTransformersDocumentEmbedder
from haystack import Pipeline
from haystack.document_stores.in_memory import InMemoryDocumentStore

document_store = InMemoryDocumentStore()
file_type_router = FileTypeRouter(
    mime_types=[
        "text/plain",
        "application/pdf",
        "text/markdown"
    ]
)
text_file_converter = TextFileToDocument()
markdown_converter = MarkdownToDocument()
pdf_converter = PyPDFToDocument()
document_joiner = DocumentJoiner()
```


4. ä½¿ç”¨ `DocumentCleaner` åˆªé™¤ç©ºç™½ï¼Œç„¶å¾Œ `DocumentSplitter` å°‡å®ƒå€‘åˆ†æˆ `150` å­—çš„å¡Šï¼Œä¸¦é€²è¡Œä¸€äº›é‡ç–Šä»¥é¿å…ä¸Ÿå¤±ä¸Šä¸‹æ–‡ã€‚

```python
document_cleaner = DocumentCleaner()
document_splitter = DocumentSplitter(
    split_by="word",
    split_length=150,
    split_overlap=50
)
```

5. æ·»åŠ ä¸€å€‹ `SentenceTransformersDocumentEmbedder` ä¾†å‰µå»ºæ–‡ä»¶çš„åµŒå…¥ï¼Œç„¶å¾Œä½¿ç”¨ `DocumentWriter` å°‡é€™äº›æ–‡ä»¶å¯«å…¥å…§å­˜æ–‡ä»¶å„²å­˜ã€‚

```python
document_embedder = SentenceTransformersDocumentEmbedder(
    model="sentence-transformers/all-MiniLM-L6-v2"
)
document_writer = DocumentWriter(document_store)
```

6. å‰µå»ºæ‰€æœ‰æ¨¡çµ„å¾Œï¼Œå°‡å®ƒå€‘æ·»åŠ åˆ°ç´¢å¼•ç®¡é“ä¸­ã€‚

```python
preprocessing_pipeline = Pipeline()
preprocessing_pipeline.add_component(
    instance=file_type_router, name="file_type_router"
)
preprocessing_pipeline.add_component(
    instance=text_file_converter, name="text_file_converter"
)
preprocessing_pipeline.add_component(
    instance=markdown_converter, name="markdown_converter"
)
preprocessing_pipeline.add_component(
    instance=pdf_converter, name="pypdf_converter"
)
preprocessing_pipeline.add_component(
    instance=document_joiner, name="document_joiner"
)
preprocessing_pipeline.add_component(
    instance=document_cleaner, name="document_cleaner"
)
preprocessing_pipeline.add_component(
    instance=document_splitter, name="document_splitter"
)
preprocessing_pipeline.add_component(
    instance=document_embedder, name="document_embedder"
)
preprocessing_pipeline.add_component(
    instance=document_writer, name="document_writer"
)
```

7. æ¥ä¸‹ä¾†ï¼Œå°‡å®ƒå€‘é€£æ¥èµ·ä¾†ã€‚

```python
preprocessing_pipeline.connect(
    "file_type_router.text/plain", "text_file_converter.sources"
)
preprocessing_pipeline.connect(
    "file_type_router.application/pdf", "pypdf_converter.sources"
)
preprocessing_pipeline.connect(
    "file_type_router.text/markdown", "markdown_converter.sources"
)
preprocessing_pipeline.connect(
    "text_file_converter", "document_joiner"
)
preprocessing_pipeline.connect(
    "pypdf_converter", "document_joiner"
)
preprocessing_pipeline.connect(
    "markdown_converter", "document_joiner"
)
preprocessing_pipeline.connect(
    "document_joiner", "document_cleaner"
)
preprocessing_pipeline.connect(
    "document_cleaner", "document_splitter"
)
preprocessing_pipeline.connect(
    "document_splitter", "document_embedder"
)
preprocessing_pipeline.connect(
    "document_embedder", "document_writer"
)
```

_ä»¥ä¸Šå®Œæˆè³‡æ–™çš„é è™•ç†_

## åœ¨ RAG ç®¡é“ä¸­ä½¿ç”¨é€™äº›æ–‡ä»¶

1. å‹™å¿…ç¢ºä¿ Hugging Face å¸³è™Ÿå…·æœ‰ç›¸å°çš„æ¬Šé™ï¼Œåœ¨æ­¤éšæ®µå¯å°‡å…¨éƒ¨æ¬Šé™å‹¾é¸é–‹å•Ÿã€‚

2. ç”¨é£Ÿè­œæ–‡ä»¶ `recipe.txt` ä¾†æ¸¬è©¦é€™å€‹ç®¡é“ã€‚

```python
from pathlib import Path

# æ¸¬è©¦æ–‡ä»¶è·¯å¾‘æ˜¯å¦å­˜åœ¨
file_path = Path("recipe_files/recipe.txt")
if file_path.exists():
    print(f"æ­£åœ¨è™•ç†æ–‡ä»¶: {file_path}")

    try:
        # è¨­ç½®æ—¥èªŒç´šåˆ¥ä»¥æŸ¥çœ‹è™•ç†éç¨‹
        import logging
        logging.basicConfig(level=logging.INFO)
        
        preprocessing_pipeline.run(
            {"file_type_router": {"sources": [file_path]}}
        )
    except Exception as e:
        print(f"è™•ç†éç¨‹ä¸­å‡ºç¾éŒ¯èª¤: {e}")
else:
    print(f"æ–‡ä»¶ {file_path} ä¸å­˜åœ¨ã€‚")

```

3. æ§‹å»ºä¸€å€‹ RAG ç®¡é“ä¾†æ ¹æ“šå‰›å‰›å‰µå»ºçš„æ–‡ä»¶å›ç­”æŸ¥è©¢ã€‚åœ¨é€™ä¸€æ­¥å°‡ä½¿ç”¨ `HuggingFaceAPIGenerator`ï¼Œå› æ­¤éœ€è¦æ“æœ‰ä¸€å€‹ Hugging Face API Keyï¼ŒåŒæ™‚å°‡ä½¿ç”¨ `HuggingFaceH4/zephyr-7b-beta` æ¨¡å‹ã€‚

```python
import os
from getpass import getpass
from dotenv import load_dotenv()

os.environ["HF_API_TOKEN"] = os.getenv["HF_API_TOKEN"]

if "HF_API_TOKEN" not in os.environ:
    os.environ["HF_API_TOKEN"] = getpass("Enter Hugging Face token:")
```

## å›ç­”æœ‰é—œæ–‡ä»¶çš„å•é¡Œ

1. è©²ç®¡é“æ¥æ”¶æç¤ºï¼Œå¾æ–‡ä»¶å„²å­˜ä¸­æœç´¢ç›¸é—œæ–‡ä»¶ï¼Œä¸¦å°‡é€™äº›æ–‡ä»¶å‚³éçµ¦ LLM ä»¥å½¢æˆç­”æ¡ˆã€‚

```python
from haystack.components.embedders import SentenceTransformersTextEmbedder
from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever
from haystack.components.builders import PromptBuilder
from haystack.components.generators import HuggingFaceAPIGenerator

template = """
Answer the questions based on the given context.

Context:
{% for document in documents %}
    {{ document.content }}
{% endfor %}

Question: {{ question }}
Answer:
"""
pipe = Pipeline()
pipe.add_component("embedder", SentenceTransformersTextEmbedder(model="sentence-transformers/all-MiniLM-L6-v2"))
pipe.add_component("retriever", InMemoryEmbeddingRetriever(document_store=document_store))
pipe.add_component("prompt_builder", PromptBuilder(template=template))
pipe.add_component(
    "llm",
    HuggingFaceAPIGenerator(api_type="serverless_inference_api", api_params={"model": "HuggingFaceH4/zephyr-7b-beta"}),
)

pipe.connect("embedder.embedding", "retriever.query_embedding")
pipe.connect("retriever", "prompt_builder.documents")
pipe.connect("prompt_builder", "llm")
```

2. å¦‚æœä¸€åˆ‡æ­£ç¢ºï¼Œä»¥ä¸‹ä»£ç¢¼å°‡æœƒå¾—åˆ°ä¸€ä»½å®Œæ•´çš„è³¼ç‰©æ¸…å–®ï¼ŒåŒ…æ‹¬æ‰€æœ‰çš„é£Ÿè­œä¾†æºã€‚

```python
question = (
    "What ingredients would I need to make vegan keto eggplant lasagna, vegan persimmon flan, and vegan hemp cheese?"
)

pipe.run(
    {
        "embedder": {"text": question},
        "prompt_builder": {"question": question},
        "llm": {"generation_kwargs": {"max_new_tokens": 350}},
    }
)
```

### çºŒå¾Œ
æ­å–œï¼ŒæˆåŠŸæ§‹å»ºäº†ä¸€å€‹å¯ä»¥é è™•ç†ä¸åŒæ–‡ä»¶é¡å‹çš„ç´¢å¼•ç®¡é“ã€‚å»å§ï¼Œå°‡æ‰€æœ‰æ··äº‚çš„ç¾å¯¦ä¸–ç•Œæ•¸æ“šå°å…¥çš„å·¥ä½œæµç¨‹ä¸­ã€‚ğŸ’¥

å¦‚æœå–œæ­¡æœ¬æ•™ç¨‹ï¼Œå¯èƒ½é‚„æœƒå–œæ­¡ï¼š

[åºåˆ—åŒ– Haystack ç®¡é“](https://haystack.deepset.ai/docs/latest/tutorials/serialize_pipeline)##
[å‰µå»ºçš„ç¬¬ä¸€å€‹åŸºæ–¼æª¢ç´¢å¢å¼·çš„å•ç­”ç®¡é“](https://haystack.deepset.ai/docs/latest/tutorials/qa_rag)##

ä¿æŒé—œæ³¨æœ€æ–°çš„ Haystack å‹•æ…‹ï¼Œå¯ä»¥è¨»å†Šæˆ‘å€‘çš„æ–°èé€šè¨Šã€‚æ„Ÿè¬çš„é–±è®€ï¼

--- 

é€™å€‹æ•´ç†æä¾›äº†ä¸€å€‹å…¨é¢çš„æŒ‡å—ï¼Œå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ Haystack 2.0 æ§‹å»ºå’ŒæŸ¥è©¢ä¸€å€‹èƒ½è™•ç†å¤šç¨®æ–‡ä»¶æ ¼å¼çš„ç´¢å¼•ç®¡é“ï¼Œä¸¦ä½¿ç”¨ RAG æ–¹æ³•é€²è¡ŒæŸ¥è©¢ã€‚