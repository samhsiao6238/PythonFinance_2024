{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [00:00<00:00, 1.15MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 274M/274M [00:27<00:00, 10.1MB/s] \n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 986k/986k [00:01<00:00, 978kB/s]\n",
      "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 272458/272458 [00:00<00:00, 354140.92 examples/s]\n",
      "Generating test split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 426988.09 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# è¼‰å…¥æ•¸æ“šé›†\n",
    "from datasets import load_dataset\n",
    "from haystack import Document\n",
    "\n",
    "# åŠ è¼‰ PubMedQA æ•¸æ“šé›†ï¼Œå–å‰ 1000 æ¢æ•¸æ“š\n",
    "dataset = load_dataset(\n",
    "    \"vblagoje/PubMedQA_instruction\",\n",
    "    split=\"train\"\n",
    ")\n",
    "dataset = dataset.select(range(1000))\n",
    "\n",
    "# æå–æ–‡ä»¶\n",
    "all_documents = [\n",
    "    Document(content=doc[\"context\"])\n",
    "    for doc in dataset\n",
    "]\n",
    "# æå–å•é¡Œ\n",
    "all_questions = [\n",
    "    doc[\"instruction\"]\n",
    "    for doc in dataset\n",
    "]\n",
    "# æå–çœŸå¯¦ç­”æ¡ˆ\n",
    "all_ground_truth_answers = [\n",
    "    doc[\"response\"]\n",
    "    for doc in dataset\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from haystack import Pipeline\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.document_stores.types import DuplicatePolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹ç´¢å¼•ç®¡é“\n",
    "indexing = Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹ `æ–‡ä»¶åµŒå…¥å™¨`\n",
    "document_embedder = SentenceTransformersDocumentEmbedder(\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# å»ºç«‹ `å…§å­˜æ–‡ä»¶å„²å­˜` å°è±¡\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "# ä½¿ç”¨å„²å­˜å°è±¡å»ºç«‹ `æ–‡ä»¶å¯«å…¥å™¨`\n",
    "document_writer = DocumentWriter(\n",
    "    document_store=document_store,\n",
    "    # é‡è¤‡æ™‚è·³é\n",
    "    policy=DuplicatePolicy.SKIP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ·»åŠ ç®¡é“å…ƒä»¶\n",
    "indexing.add_component(\n",
    "    instance=document_embedder,\n",
    "    name=\"document_embedder\"\n",
    ")\n",
    "indexing.add_component(\n",
    "    instance=document_writer,\n",
    "    name=\"document_writer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x33a517550>\n",
       "ğŸš… Components\n",
       "  - document_embedder: SentenceTransformersDocumentEmbedder\n",
       "  - document_writer: DocumentWriter\n",
       "ğŸ›¤ï¸ Connections\n",
       "  - document_embedder.documents -> document_writer.documents (List[Document])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# é€£æ¥ç®¡é“å…ƒä»¶ï¼šé€£æ¥åµŒå…¥å™¨å’Œå¯«å…¥å™¨\n",
    "indexing.connect(\n",
    "    \"document_embedder.documents\",\n",
    "    \"document_writer.documents\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samhsiao/Documents/PythonVenv/envHaystack/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:174: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v3 of SentenceTransformers.\n",
      "  warnings.warn(\n",
      "/Users/samhsiao/Documents/PythonVenv/envHaystack/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'document_writer': {'documents_written': 1000}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# åŸ·è¡Œç´¢å¼•ç®¡é“\n",
    "indexing.run(\n",
    "    {\"document_embedder\": {\"documents\": all_documents}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing.draw('ex15-1.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envHaystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
