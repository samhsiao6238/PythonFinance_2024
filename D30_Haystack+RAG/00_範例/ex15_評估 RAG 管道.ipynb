{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samhsiao/Documents/PythonVenv/envHaystack/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# è¼‰å…¥æ•¸æ“šé›†\n",
    "from datasets import load_dataset\n",
    "from haystack import Document\n",
    "\n",
    "# åŠ è¼‰ PubMedQA æ•¸æ“šé›†ï¼Œå–å‰ 1000 æ¢æ•¸æ“š\n",
    "dataset = load_dataset(\n",
    "    \"vblagoje/PubMedQA_instruction\",\n",
    "    split=\"train\"\n",
    ")\n",
    "dataset = dataset.select(range(1000))\n",
    "\n",
    "# æå–æ–‡ä»¶\n",
    "all_documents = [\n",
    "    Document(content=doc[\"context\"])\n",
    "    for doc in dataset\n",
    "]\n",
    "# æå–å•é¡Œ\n",
    "all_questions = [\n",
    "    doc[\"instruction\"]\n",
    "    for doc in dataset\n",
    "]\n",
    "# æå–çœŸå¯¦ç­”æ¡ˆ\n",
    "all_ground_truth_answers = [\n",
    "    doc[\"response\"]\n",
    "    for doc in dataset\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from haystack import Pipeline\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.document_stores.types import DuplicatePolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹ç´¢å¼•ç®¡é“\n",
    "indexing = Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹ `æ–‡ä»¶åµŒå…¥å™¨`\n",
    "document_embedder = SentenceTransformersDocumentEmbedder(\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# å»ºç«‹ `å…§å­˜æ–‡ä»¶å„²å­˜` å°è±¡\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "# ä½¿ç”¨å„²å­˜å°è±¡å»ºç«‹ `æ–‡ä»¶å¯«å…¥å™¨`\n",
    "document_writer = DocumentWriter(\n",
    "    document_store=document_store,\n",
    "    # é‡è¤‡æ™‚è·³é\n",
    "    policy=DuplicatePolicy.SKIP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ·»åŠ ç®¡é“å…ƒä»¶\n",
    "indexing.add_component(\n",
    "    instance=document_embedder,\n",
    "    name=\"document_embedder\"\n",
    ")\n",
    "indexing.add_component(\n",
    "    instance=document_writer,\n",
    "    name=\"document_writer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x32a64dcc0>\n",
       "ğŸš… Components\n",
       "  - document_embedder: SentenceTransformersDocumentEmbedder\n",
       "  - document_writer: DocumentWriter\n",
       "ğŸ›¤ï¸ Connections\n",
       "  - document_embedder.documents -> document_writer.documents (List[Document])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# é€£æ¥ç®¡é“å…ƒä»¶ï¼šé€£æ¥åµŒå…¥å™¨å’Œå¯«å…¥å™¨\n",
    "indexing.connect(\n",
    "    \"document_embedder.documents\",\n",
    "    \"document_writer.documents\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samhsiao/Documents/PythonVenv/envHaystack/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:174: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v3 of SentenceTransformers.\n",
      "  warnings.warn(\n",
      "/Users/samhsiao/Documents/PythonVenv/envHaystack/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:06<00:00,  4.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'document_writer': {'documents_written': 1000}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# åŸ·è¡Œç´¢å¼•ç®¡é“\n",
    "indexing.run(\n",
    "    {\"document_embedder\": {\"documents\": all_documents}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing.draw('ex15-1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# è¼‰å…¥ç’°å¢ƒè®Šæ•¸\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "# è¨­ç½® OpenAI API é‡‘é‘°\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.builders import AnswerBuilder, PromptBuilder\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šç¾©ç”Ÿæˆç­”æ¡ˆçš„æ¨¡æ¿\n",
    "template = \"\"\"\n",
    "        æ‚¨å¿…é ˆåƒ…æ ¹æ“šçµ¦å®šçš„ä¸Šä¸‹æ–‡è³‡è¨Šå›ç­”ä»¥ä¸‹å•é¡Œã€‚\n",
    "\n",
    "        ä¸Šä¸‹æ–‡:\n",
    "        {% for document in documents %}\n",
    "            {{ document.content }}\n",
    "        {% endfor %}\n",
    "\n",
    "        å•é¡Œ: {{question}}\n",
    "        ç­”æ¡ˆ:\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹ RAG ç®¡é“\n",
    "rag_pipeline = Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline.add_component(\n",
    "    \"query_embedder\", \n",
    "    SentenceTransformersTextEmbedder(\n",
    "        model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# ä½¿ç”¨å¤šèªè¨€æ”¯æŒçš„åµŒå…¥æ¨¡å‹\n",
    "# rag_pipeline.add_component(\n",
    "#     \"query_embedder\",\n",
    "#     SentenceTransformersTextEmbedder(\n",
    "#         model=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "#     )\n",
    "# )\n",
    "\n",
    "rag_pipeline.add_component(\n",
    "    \"retriever\",\n",
    "    InMemoryEmbeddingRetriever(document_store, top_k=3)\n",
    ")\n",
    "rag_pipeline.add_component(\n",
    "    \"prompt_builder\",\n",
    "    PromptBuilder(template=template)\n",
    ")\n",
    "rag_pipeline.add_component(\n",
    "    \"generator\",\n",
    "    OpenAIGenerator(model=\"gpt-4-turbo\")\n",
    ")\n",
    "rag_pipeline.add_component(\n",
    "    \"answer_builder\",\n",
    "    AnswerBuilder()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x391f2d570>\n",
       "ğŸš… Components\n",
       "  - query_embedder: SentenceTransformersTextEmbedder\n",
       "  - retriever: InMemoryEmbeddingRetriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - generator: OpenAIGenerator\n",
       "  - answer_builder: AnswerBuilder\n",
       "ğŸ›¤ï¸ Connections\n",
       "  - query_embedder.embedding -> retriever.query_embedding (List[float])\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - retriever.documents -> answer_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> generator.prompt (str)\n",
       "  - generator.replies -> answer_builder.replies (List[str])\n",
       "  - generator.meta -> answer_builder.meta (List[Dict[str, Any]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# é€£æ¥ç®¡é“çš„çµ„ä»¶\n",
    "rag_pipeline.connect(\n",
    "    \"query_embedder\", \"retriever.query_embedding\"\n",
    ")\n",
    "rag_pipeline.connect(\n",
    "    \"retriever\", \"prompt_builder.documents\"\n",
    ")\n",
    "rag_pipeline.connect(\n",
    "    \"prompt_builder\", \"generator\"\n",
    ")\n",
    "rag_pipeline.connect(\n",
    "    \"generator.replies\", \"answer_builder.replies\"\n",
    ")\n",
    "rag_pipeline.connect(\n",
    "    \"generator.meta\", \"answer_builder.meta\"\n",
    ")\n",
    "rag_pipeline.connect(\n",
    "    \"retriever\", \"answer_builder.documents\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.75it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, high levels of procalcitonin in the early phase after pediatric liver transplantation indicate a poor postoperative outcome. Patients with high procalcitonin levels on postoperative day 2 were observed to have higher International Normalized Ratio values on postoperative day 5 and suffered more often from primary graft non-function. Additionally, these patients experienced longer stays in the pediatric intensive care unit and required prolonged mechanical ventilation. These indications collectively suggest a correlation between early postoperative elevations in procalcitonin and compromised postoperative recovery.\n"
     ]
    }
   ],
   "source": [
    "# å•é¡Œ\n",
    "question = \"Do high levels of procalcitonin in the early phase after pediatric liver transplantation indicate poor postoperative outcome?\"\n",
    "# question = \"å°å…’è‚ç§»æ¤è¡“å¾Œæ—©æœŸé™éˆ£ç´ åŸé«˜æ˜¯å¦è¡¨ç¤ºè¡“å¾Œæ•ˆæœä¸ä½³ï¼Ÿ\"\n",
    "\n",
    "# é‹è¡Œç®¡é“\n",
    "response = rag_pipeline.run(\n",
    "    {\n",
    "        \"query_embedder\": {\"text\": question},\n",
    "        \"prompt_builder\": {\"question\": question},\n",
    "        \"answer_builder\": {\"query\": question}\n",
    "    }\n",
    ")\n",
    "# è¼¸å‡º\n",
    "print(response[\"answer_builder\"][\"answers\"][0].data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envHaystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
