{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 載入環境變數\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "# 假如沒有找到環境變數就手動輸入\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from haystack import Document\n",
    "\n",
    "# 加載數據集\n",
    "dataset = load_dataset(\n",
    "    \"bilgeyucel/seven-wonders\", split=\"train\"\n",
    ")\n",
    "docs = [\n",
    "    Document(content=doc[\"content\"],\n",
    "    meta=doc[\"meta\"]) for doc in dataset\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "\n",
    "# 初始化內存文件儲存\n",
    "document_store = InMemoryDocumentStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samhsiao/Documents/PythonVenv/envHaystack/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:174: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v3 of SentenceTransformers.\n",
      "  warnings.warn(\n",
      "/Users/samhsiao/Documents/PythonVenv/envHaystack/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e02f38ad6b47b4add4ae0d693e0f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "\n",
    "# 初始化 `文件嵌入器`\n",
    "# 將整個文檔嵌入到一個向量表示中，以捕捉文檔整體的語義信息\n",
    "doc_embedder = SentenceTransformersDocumentEmbedder(\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "# 加載嵌入器，這是一種優化手段，用於預先加載和初始化資源密集型組件\n",
    "# 可確保系統在運行時能迅速響應並保持高效的運行狀態\n",
    "# 可有效避免首次運行的延遲問題，提升整體系統的性能和穩定性\n",
    "doc_embedder.warm_up()\n",
    "# 將文檔轉換成嵌入\n",
    "docs_with_embeddings = doc_embedder.run(docs)\n",
    "# 將嵌入寫到 document_store 中\n",
    "document_store.write_documents(\n",
    "    docs_with_embeddings[\"documents\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "\n",
    "# 建立 `文本` 嵌入器\n",
    "text_embedder = SentenceTransformersTextEmbedder(\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "\n",
    "# 建立 `內存嵌入檢索器`\n",
    "retriever = InMemoryEmbeddingRetriever(document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.generators import OpenAIGenerator\n",
    "\n",
    "# 初始化 OpenAI 生成器\n",
    "generator = OpenAIGenerator(model=\"gpt-4-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "# 定義模板提示\n",
    "template = \"\"\"\n",
    "根據以下信息，回答問題。\n",
    "\n",
    "上下文:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "問題: {{question}}\n",
    "答案:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化提示生成器\n",
    "prompt_builder = PromptBuilder(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "\n",
    "# 初始化管道\n",
    "basic_rag_pipeline = Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加組件到管道\n",
    "basic_rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "basic_rag_pipeline.add_component(\"retriever\", retriever)\n",
    "basic_rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "basic_rag_pipeline.add_component(\"llm\", generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 連接組件\n",
    "# 將 `text_embedder` 的 `embedding` 輸出連接到 `retriever` 的 `query_embedding` 輸入\n",
    "basic_rag_pipeline.connect(\n",
    "    \"text_embedder.embedding\",\n",
    "    \"retriever.query_embedding\"\n",
    ")\n",
    "# 因為 `prompt_builder` 有兩個輸入 `documents` 和 `question`\n",
    "# 而這裡顯式連接了 `retriever` 到 `prompt_builder` 的 `documents`\n",
    "basic_rag_pipeline.connect(\n",
    "    \"retriever\",\n",
    "    \"prompt_builder.documents\"\n",
    ")\n",
    "# 將 `prompt_builder` 連接到 `llm`\n",
    "basic_rag_pipeline.connect(\n",
    "    \"prompt_builder\",\n",
    "    \"llm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.draw_pipeline import draw_and_display\n",
    "\n",
    "draw_and_display(basic_rag_pipeline, \"ex03_1_pipe.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 這僅僅是提問的範例供作參考\n",
    "'''\n",
    "Rhodes 雕像是什麼樣子的？\n",
    "巴比倫花園在哪裡？\n",
    "人們為什麼要建造吉薩大金字塔？\n",
    "人們為什麼參觀阿耳忒彌斯神殿？\n",
    "羅德島巨像的重要性是什麼？\n",
    "摩索拉斯墓發生了什麼事？\n",
    "羅德島巨像是怎麼崩潰的？\n",
    "'''\n",
    "# 提問\n",
    "question = \"人們為什麼參觀阿耳忒彌斯神殿？\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = basic_rag_pipeline.run({\n",
    "    \"text_embedder\": {\"text\": question},\n",
    "    \"prompt_builder\": {\"question\": question}\n",
    "})\n",
    "\n",
    "# 輸出答案\n",
    "print(response[\"llm\"][\"replies\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envHaystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
