{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¿å­˜ OpenAI API Key ç‚ºç’°å¢ƒè®Šé‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# è¼‰å…¥ç’°å¢ƒè®Šæ•¸\n",
    "load_dotenv()\n",
    "# å…©å€‹ API çš„å¯†é‘°\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samhsiao/Documents/PythonVenv/envHaystack/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'replies': [ChatMessage(content='è‡ªç„¶èªè¨€è™•ç†ï¼ˆNLPï¼‰æ˜¯ä¸€å€‘è³‡è¨Šç§‘æŠ€é ˜åŸŸï¼Œè‡´åŠ›æ–¼è®“è¨ˆç®—æ©Ÿèƒ½å¤ ç†è§£ã€è§£é‡‹ã€æ“ä½œå’Œç”Ÿæˆäººé¡èªè¨€ã€‚è¿™é¡¹æŠ€æœ¯æ¶‰åŠèªè¨€å­¸ã€è¨ˆç®—æ©Ÿç§‘å­¸å’Œäººå·¥æ™ºæ…§çš„äº¤å‰ç™¼å±•ã€‚', role=<ChatRole.ASSISTANT: 'assistant'>, name=None, meta={'model': 'gpt-4-turbo-2024-04-09', 'index': 0, 'finish_reason': 'stop', 'usage': {'completion_tokens': 96, 'prompt_tokens': 67, 'total_tokens': 163}})]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "\n",
    "# å‰µå»ºç³»çµ±æ¶ˆæ¯å’Œç”¨æˆ¶æ¶ˆæ¯çš„ ChatMessage å°è±¡\n",
    "messages = [\n",
    "    ChatMessage.from_system(\n",
    "        \"å³ä½¿æŸäº›è¼¸å…¥è³‡æ–™æ¡ç”¨å…¶ä»–èªè¨€ï¼Œä¹Ÿå§‹çµ‚ä»¥ç¹é«”ä¸­æ–‡å›æ‡‰ã€‚\"\n",
    "    ),\n",
    "    ChatMessage.from_user(\n",
    "        \"ä»€éº¼æ˜¯è‡ªç„¶èªè¨€è™•ç†ï¼Ÿè¦ç°¡æ½”ã€‚\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# åˆå§‹åŒ– OpenAIChatGenerator\n",
    "chat_generator = OpenAIChatGenerator(model=\"gpt-4-turbo\")\n",
    "# å‚³å…¥æ¶ˆæ¯ä¸¦é‹è¡Œ\n",
    "chat_generator.run(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è‡ªç„¶èªè¨€è™•ç†æ˜¯äººå·¥æ™®éå’Œèªè¨€å­¸é ˜åŸŸçš„ä¸€éƒ¨åˆ†ï¼Œå®ƒå¹«åŠ©è¨ˆç®—æ©Ÿç†è§£ã€è§£é‡‹ã€æ“ä½œå’Œç”Ÿæˆäººé¡èªè¨€ã€‚"
     ]
    }
   ],
   "source": [
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.components.generators.utils import print_streaming_chunk\n",
    "\n",
    "# ä½¿ç”¨æµå¼å›èª¿å‡½æ•¸åˆå§‹åŒ– OpenAIChatGenerator\n",
    "chat_generator = OpenAIChatGenerator(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    streaming_callback=print_streaming_chunk\n",
    ")\n",
    "# å‚³å…¥æ¶ˆæ¯ä¸¦é‹è¡Œ\n",
    "response = chat_generator.run(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samhsiao/Documents/PythonVenv/envHaystack/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:174: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v3 of SentenceTransformers.\n",
      "  warnings.warn(\n",
      "/Users/samhsiao/Documents/PythonVenv/envHaystack/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  2.00s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'doc_writer': {'documents_written': 5}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline, Document\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "\n",
    "# å‰µå»ºæ–‡ä»¶\n",
    "documents = [\n",
    "    Document(content=\"æˆ‘çš„åå­—æ˜¯ Jeanï¼Œæˆ‘ä½åœ¨ Parisã€‚\"),\n",
    "    Document(content=\"æˆ‘çš„åå­—æ˜¯ Markï¼Œæˆ‘ä½åœ¨ Berlinã€‚\"),\n",
    "    Document(content=\"æˆ‘çš„åå­—æ˜¯ Giorgioï¼Œæˆ‘ä½åœ¨ Romeã€‚\"),\n",
    "    Document(content=\"æˆ‘çš„åå­—æ˜¯ Martaï¼Œæˆ‘ä½åœ¨ Madridã€‚\"),\n",
    "    Document(content=\"æˆ‘çš„åå­—æ˜¯ Harryï¼Œæˆ‘ä½åœ¨ Londonã€‚\"),\n",
    "]\n",
    "\n",
    "# åˆå§‹åŒ–å…§å­˜æ–‡ä»¶å„²å­˜\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "# å‰µå»ºç´¢å¼•ç®¡é“\n",
    "indexing_pipeline = Pipeline()\n",
    "indexing_pipeline.add_component(\n",
    "    instance=SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\"), name=\"doc_embedder\"\n",
    ")\n",
    "indexing_pipeline.add_component(\n",
    "    instance=DocumentWriter(document_store=document_store),\n",
    "    name=\"doc_writer\"\n",
    ")\n",
    "\n",
    "# é€£æ¥åµŒå…¥å™¨å’Œæ–‡ä»¶å¯«å…¥å™¨\n",
    "indexing_pipeline.connect(\n",
    "    \"doc_embedder.documents\",\n",
    "    \"doc_writer.documents\"\n",
    ")\n",
    "\n",
    "# é‹è¡Œç®¡é“\n",
    "indexing_pipeline.run({\n",
    "    \"doc_embedder\": {\"documents\": documents}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x325298a30>\n",
       "ğŸš… Components\n",
       "  - embedder: SentenceTransformersTextEmbedder\n",
       "  - retriever: InMemoryEmbeddingRetriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: OpenAIGenerator\n",
       "ğŸ›¤ï¸ Connections\n",
       "  - embedder.embedding -> retriever.query_embedding (List[float])\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "\n",
    "# å®šç¾©æç¤ºæ¨¡æ¿\n",
    "template = \"\"\"\n",
    "æ ¹æ“šçµ¦å®šçš„ä¸Šä¸‹æ–‡å›ç­”å•é¡Œã€‚\n",
    "\n",
    "ä¸Šä¸‹æ–‡:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "å•é¡Œ: {{ question }}\n",
    "ç­”æ¡ˆ:\n",
    "\"\"\"\n",
    "\n",
    "# å‰µå»º RAG ç®¡é“\n",
    "rag_pipe = Pipeline()\n",
    "rag_pipe.add_component(\n",
    "    \"embedder\",\n",
    "    SentenceTransformersTextEmbedder(\n",
    "        model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    ")\n",
    "rag_pipe.add_component(\n",
    "    \"retriever\",\n",
    "    InMemoryEmbeddingRetriever(\n",
    "        document_store=document_store\n",
    "    )\n",
    ")\n",
    "rag_pipe.add_component(\n",
    "    \"prompt_builder\",\n",
    "    PromptBuilder(\n",
    "        template=template\n",
    "    )\n",
    ")\n",
    "rag_pipe.add_component(\n",
    "    \"llm\",\n",
    "    OpenAIGenerator(model=\"gpt-4-turbo\")\n",
    ")\n",
    "\n",
    "# é€£æ¥çµ„ä»¶\n",
    "rag_pipe.connect(\n",
    "    \"embedder.embedding\",\n",
    "    \"retriever.query_embedding\"\n",
    ")\n",
    "rag_pipe.connect(\n",
    "    \"retriever\",\n",
    "    \"prompt_builder.documents\"\n",
    ")\n",
    "rag_pipe.connect(\n",
    "    \"prompt_builder\",\n",
    "    \"llm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'llm': {'replies': ['Mark ä½åœ¨ Berlinã€‚'],\n",
       "  'meta': [{'model': 'gpt-4-turbo-2024-04-09',\n",
       "    'index': 0,\n",
       "    'finish_reason': 'stop',\n",
       "    'usage': {'completion_tokens': 7,\n",
       "     'prompt_tokens': 127,\n",
       "     'total_tokens': 134}}]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Mark ä½åœ¨å“ªè£¡ï¼Ÿ\"\n",
    "rag_pipe.run({\n",
    "    \"embedder\": {\"text\": query},\n",
    "    \"prompt_builder\": {\"question\": query}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline_func(query: str):\n",
    "    result = rag_pipe.run({\n",
    "        \"embedder\": {\"text\": query},\n",
    "        \"prompt_builder\": {\"question\": query}\n",
    "    })\n",
    "    return {\"reply\": result[\"llm\"][\"replies\"][0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEATHER_INFO = {\n",
    "    \"Berlin\": {\n",
    "        \"weather\": \"mostly sunny\", \"temperature\": 7, \"unit\": \"celsius\"\n",
    "    },\n",
    "    \"Paris\": {\n",
    "        \"weather\": \"mostly cloudy\", \"temperature\": 8, \"unit\": \"celsius\"\n",
    "    },\n",
    "    \"Rome\": {\n",
    "        \"weather\": \"sunny\", \"temperature\": 14, \"unit\": \"celsius\"\n",
    "    },\n",
    "    \"Madrid\": {\n",
    "        \"weather\": \"sunny\", \"temperature\": 10, \"unit\": \"celsius\"\n",
    "    },\n",
    "    \"London\": {\n",
    "        \"weather\": \"cloudy\", \"temperature\": 9, \"unit\": \"celsius\"\n",
    "    },\n",
    "}\n",
    "\n",
    "def get_current_weather(location: str):\n",
    "    if location in WEATHER_INFO:\n",
    "        return WEATHER_INFO[location]\n",
    "    else:\n",
    "        # å›é€€æ•¸æ“š\n",
    "        return {\n",
    "            \"weather\": \"sunny\",\n",
    "            \"temperature\": 21.8,\n",
    "            \"unit\": \"fahrenheit\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"rag_pipeline_func\",\n",
    "            \"description\": \"ç²å–æœ‰é—œäººå€‘å±…ä½åœ°é»çš„ä¿¡æ¯\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"æœå°‹ä¸­ä½¿ç”¨çš„æŸ¥è©¢ã€‚å¾ç”¨æˆ¶çš„æ¶ˆæ¯ä¸­æ¨æ–·å‡ºé€™ä¸€é»ã€‚å®ƒæ‡‰è©²æ˜¯ä¸€å€‹å•é¡Œæˆ–ä¸€å€‹é™³è¿°ã€‚\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"å–å¾—ç•¶å‰å¤©æ°£\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"åŸå¸‚å’Œå·ï¼Œä¾‹å¦‚åŠ å·èˆŠé‡‘å±±\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'replies': [ChatMessage(content='[{\"index\": 0, \"id\": \"call_2ARyzeivzPqS0ETx3jVHt4ct\", \"function\": {\"arguments\": \"{\\\\\"query\\\\\":\\\\\"Where does Mark live?\\\\\"}\", \"name\": \"rag_pipeline_func\"}, \"type\": \"function\"}]', role=<ChatRole.ASSISTANT: 'assistant'>, name=None, meta={'model': 'gpt-4-turbo-2024-04-09', 'index': 0, 'finish_reason': 'tool_calls', 'usage': {}})]}\n"
     ]
    }
   ],
   "source": [
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.components.generators.utils import print_streaming_chunk\n",
    "\n",
    "# å‰µå»ºæ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«ç³»çµ±æ¶ˆæ¯å’Œç”¨æˆ¶æŸ¥è©¢\n",
    "messages = [\n",
    "    ChatMessage.from_system(\n",
    "        \"ä¸è¦å‡è¨­å°‡å“ªäº›å€¼æ’å…¥å‡½æ•¸ä¸­ã€‚å¦‚æœç”¨æˆ¶è¦æ±‚ä¸æ˜ç¢ºï¼Œè«‹è¦æ±‚æ¾„æ¸…ã€‚\"\n",
    "    ),\n",
    "    ChatMessage.from_user(\"ä½ èƒ½å‘Šè¨´æˆ‘ Mark ä½åœ¨å“ªè£¡å—ï¼Ÿ\"),\n",
    "]\n",
    "\n",
    "# åˆå§‹åŒ– OpenAIChatGenerator\n",
    "chat_generator = OpenAIChatGenerator(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    streaming_callback=print_streaming_chunk\n",
    ")\n",
    "# å‚³å…¥æ¶ˆæ¯å’Œå·¥å…·åˆ—è¡¨ä¸¦é‹è¡Œ\n",
    "response = chat_generator.run(\n",
    "    messages=messages,\n",
    "    generation_kwargs={\"tools\": tools}\n",
    ")\n",
    "# è¼¸å‡ºæŸ¥çœ‹\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envHaystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
