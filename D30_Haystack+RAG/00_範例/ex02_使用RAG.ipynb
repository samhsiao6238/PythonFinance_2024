{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samhsiao/Documents/PythonVenv/envHaystack/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "\n",
    "# åˆå§‹åŒ–å…§å­˜æ–‡ä»¶å„²å­˜\n",
    "document_store = InMemoryDocumentStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46.0/46.0 [00:00<00:00, 50.6kB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 119k/119k [00:01<00:00, 80.4kB/s]\n",
      "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 151/151 [00:00<00:00, 14080.48 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from haystack import Document\n",
    "\n",
    "# åŠ è¼‰æ•¸æ“šé›†\n",
    "dataset = load_dataset(\"bilgeyucel/seven-wonders\", split=\"train\")\n",
    "docs = [Document(content=doc[\"content\"], meta=doc[\"meta\"]) for doc in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samhsiao/Documents/PythonVenv/envHaystack/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "\n",
    "# åˆå§‹åŒ–æ–‡ä»¶åµŒå…¥å™¨\n",
    "doc_embedder = SentenceTransformersDocumentEmbedder(\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "doc_embedder.warm_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å‰µå»ºæ–‡ä»¶åµŒå…¥ä¸¦å¯«å…¥æ–‡ä»¶å„²å­˜\n",
    "docs_with_embeddings = doc_embedder.run(docs)\n",
    "document_store.write_documents(docs_with_embeddings[\"documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "\n",
    "# åˆå§‹åŒ–æ–‡æœ¬åµŒå…¥å™¨\n",
    "text_embedder = SentenceTransformersTextEmbedder(\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "\n",
    "# åˆå§‹åŒ–å…§å­˜åµŒå…¥æª¢ç´¢å™¨\n",
    "retriever = InMemoryEmbeddingRetriever(document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "# å®šç¾©æ¨¡æ¿æç¤º\n",
    "template = \"\"\"\n",
    "æ ¹æ“šä»¥ä¸‹ä¿¡æ¯ï¼Œå›ç­”å•é¡Œã€‚\n",
    "æƒ…å¢ƒ:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "å•é¡Œ: {{question}}\n",
    "å›ç­”:\n",
    "\"\"\"\n",
    "\n",
    "# åˆå§‹åŒ–æç¤ºç”Ÿæˆå™¨\n",
    "prompt_builder = PromptBuilder(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key found in environment variable.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "\n",
    "# è¨­ç½® OpenAI API Key\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key:\")\n",
    "    print(\"OpenAI API key set to environment variable.\")\n",
    "else:\n",
    "    print(\"OpenAI API key found in environment variable.\")\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ– OpenAI ç”Ÿæˆå™¨\n",
    "generator = OpenAIGenerator(model=\"gpt-4-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x36fb05ff0>\n",
       "ğŸš… Components\n",
       "  - text_embedder: SentenceTransformersTextEmbedder\n",
       "  - retriever: InMemoryEmbeddingRetriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: OpenAIGenerator\n",
       "ğŸ›¤ï¸ Connections\n",
       "  - text_embedder.embedding -> retriever.query_embedding (List[float])\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "\n",
    "# åˆå§‹åŒ–ç®¡é“\n",
    "basic_rag_pipeline = Pipeline()\n",
    "\n",
    "# æ·»åŠ æ¨¡çµ„åˆ°ç®¡é“\n",
    "basic_rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "basic_rag_pipeline.add_component(\"retriever\", retriever)\n",
    "basic_rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "basic_rag_pipeline.add_component(\"llm\", generator)\n",
    "\n",
    "# é€£æ¥æ¨¡çµ„\n",
    "basic_rag_pipeline.connect(\n",
    "    \"text_embedder.embedding\",\n",
    "    \"retriever.query_embedding\"\n",
    ")\n",
    "basic_rag_pipeline.connect(\n",
    "    \"retriever\",\n",
    "    \"prompt_builder.documents\"\n",
    ")\n",
    "basic_rag_pipeline.connect(\n",
    "    \"prompt_builder\",\n",
    "    \"llm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "äººå€‘åƒè§€é˜¿è€³å¿’å½Œæ–¯ç¥æ®¿çš„åŸå› å¤šæ¨£ã€‚é¦–å…ˆï¼Œé€™åº§ç¥æ®¿æ˜¯ä¸€å€‹é‡è¦çš„å®—æ•™åœ°æ¨™ï¼Œä¾›å¥‰è‘—å¥³ç¥é˜¿è€³å¿’å½Œæ–¯ï¼Œå¸å¼•äº†è¨±å¤šè™”èª çš„æœè–è€…å‰ä¾†åƒæ‹œå’Œç»ç¥­ã€‚å…¶æ¬¡ï¼Œç¥æ®¿æœ¬èº«çš„å»ºç¯‰å’Œè—è¡“åƒ¹å€¼ä¹Ÿå¸å¼•äº†ä¸å°‘éŠå®¢å’Œå­¸è€…ï¼Œä¾‹å¦‚ç¥æ®¿çš„è±å¯Œç´°ç¯€å’Œç²¾ç·»é›•åˆ»ã€‚æ­¤å¤–ï¼Œç¥æ®¿é‚„æä¾›äº†åº‡è­·ï¼Œå°æ–¼é€ƒé¿è¿«å®³æˆ–æ‡²ç½°çš„äººä¾†èªªæ˜¯ä¸€å€‹é¿é›£æ‰€ï¼Œé€™é …åŠŸèƒ½ä¹Ÿä½¿å¾—è¨±å¤šå°‹æ±‚ä¿è­·çš„äººå£«å‰ä¾†ã€‚æœ€å¾Œï¼Œè¨±å¤šå•†äººã€åœ‹ç‹å’Œè§€å…‰å®¢ä¹Ÿæœƒé€ è¨ªæ­¤åœ°ï¼Œä»–å€‘å¯èƒ½æ˜¯å‡ºæ–¼å°ç¥æ®¿çš„å¥½å¥‡æˆ–è€…æ–‡åŒ–æ—…éŠçš„ç›®çš„ã€‚å› æ­¤ï¼Œé˜¿è€³å¿’å½Œæ–¯ç¥æ®¿æˆç‚ºäº†ä¸€å€‹çµåˆå®—æ•™ã€æ–‡åŒ–å’Œæ­·å²çš„å¤šåŠŸèƒ½æ™¯é»ã€‚\n"
     ]
    }
   ],
   "source": [
    "# æå•\n",
    "'''\n",
    "Rhodes é›•åƒæ˜¯ä»€éº¼æ¨£å­çš„ï¼Ÿ\n",
    "å·´æ¯”å€«èŠ±åœ’åœ¨å“ªè£¡ï¼Ÿ\n",
    "äººå€‘ç‚ºä»€éº¼è¦å»ºé€ å‰è–©å¤§é‡‘å­—å¡”ï¼Ÿ\n",
    "äººå€‘ç‚ºä»€éº¼åƒè§€é˜¿è€³å¿’å½Œæ–¯ç¥æ®¿ï¼Ÿ\n",
    "ç¾…å¾·å³¶å·¨åƒçš„é‡è¦æ€§æ˜¯ä»€éº¼ï¼Ÿ\n",
    "æ‘©ç´¢æ‹‰æ–¯å¢“ç™¼ç”Ÿäº†ä»€éº¼äº‹ï¼Ÿ\n",
    "ç¾…å¾·å³¶å·¨åƒæ˜¯æ€éº¼å´©æ½°çš„ï¼Ÿ\n",
    "'''\n",
    "question = \"äººå€‘ç‚ºä»€éº¼åƒè§€é˜¿è€³å¿’å½Œæ–¯ç¥æ®¿ï¼Ÿ\"\n",
    "\n",
    "response = basic_rag_pipeline.run({\n",
    "    \"text_embedder\": {\"text\": question},\n",
    "    \"prompt_builder\": {\"question\": question}\n",
    "})\n",
    "\n",
    "# è¼¸å‡ºç­”æ¡ˆ\n",
    "print(response[\"llm\"][\"replies\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envHaystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
