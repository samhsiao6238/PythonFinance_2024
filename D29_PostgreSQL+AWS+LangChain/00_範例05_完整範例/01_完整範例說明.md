# é«˜éšæ©Ÿå™¨äºº

_ä½¿ç”¨ PostgreSQL ä½œç‚ºå‘é‡å„²å­˜_

<br>

## ä¸€èˆ¬å¥—ä»¶

1. Streamlitã€‚

2. PyPDF2ï¼šç”¨æ–¼è™•ç† PDF æ–‡ä»¶ã€‚

3. LangChainï¼š_å¾ŒçºŒå°‡è©³ç´°èªªæ˜_ã€‚

4. boto3ï¼šç”¨æ–¼èˆ‡ AWS æœå‹™é€²è¡Œäº’å‹•çš„ SDKï¼Œæ”¯æŒæ“ä½œ S3ã€DynamoDBã€EC2 ç­‰å¤šç¨® AWS æœå‹™ã€‚

5. tempfileï¼šç”¨æ–¼å»ºç«‹è‡¨æ™‚æ–‡ä»¶å’Œç›®éŒ„ï¼Œæä¾›äº†ä¸€å€‹å®‰å…¨çš„æ–¹å¼ä¾†å»ºç«‹è‡¨æ™‚æ–‡ä»¶ï¼Œé€™äº›æ–‡ä»¶åœ¨ä½¿ç”¨å¾Œå¯ä»¥è‡ªå‹•åˆªé™¤ã€‚

6. timeï¼šæä¾›æ™‚é–“ç›¸é—œçš„åŠŸèƒ½ï¼Œæ”¯æŒç²å–ç•¶å‰æ™‚é–“ã€é€²è¡Œæ™‚é–“è¨ˆç®—ã€æ¨¡æ“¬å»¶é²ç­‰æ“ä½œã€‚

7. hashlibï¼šç”¨æ–¼ç”Ÿæˆå“ˆå¸Œå€¼å’Œé€²è¡ŒåŠ å¯†æ“ä½œï¼Œæ”¯æŒå¤šç¨®å“ˆå¸Œç®—æ³•ï¼Œå¦‚ MD5ã€SHA-1ã€SHA-256 ç­‰ï¼Œç”¨æ–¼ç”Ÿæˆæ•¸æ“šçš„å”¯ä¸€æ¨™è­˜ç¬¦ã€‚

8. secretsï¼šç”¨æ–¼ç”Ÿæˆå®‰å…¨çš„éš¨æ©Ÿæ•¸å’Œå¯†ç¢¼ï¼Œæä¾›äº†æ›´é«˜å®‰å…¨æ€§çš„éš¨æ©Ÿæ•¸ç”Ÿæˆæ–¹æ³•ï¼Œé©ç”¨æ–¼åŠ å¯†å¯†é‘°ã€éš¨æ©Ÿæ¨™è­˜ç¬¦ç­‰å ´åˆã€‚

9. loggingï¼šæä¾›è¨˜éŒ„å’Œè·Ÿè¹¤æ‡‰ç”¨é‹è¡Œéç¨‹ä¸­ç™¼ç”Ÿçš„äº‹ä»¶ï¼Œæ”¯æŒå¤šç¨®æ—¥èªŒç´šåˆ¥ï¼ˆå¦‚ DEBUGã€INFOã€WARNINGã€ERRORã€CRITICALï¼‰ï¼Œä¾¿æ–¼é€²è¡Œæ‡‰ç”¨çš„æ•…éšœæ’é™¤å’Œæ€§èƒ½åˆ†æã€‚

<br>

## LangChain

1. vectorstores.pgvectorï¼šä½¿ç”¨ pgvector é€²è¡Œå‘é‡å„²å­˜ï¼Œæ”¯æŒé«˜æ•ˆçš„å‘é‡æª¢ç´¢æ“ä½œã€‚

2. memory.ConversationBufferMemoryï¼šç”¨æ–¼ç®¡ç†å°è©±çš„å…§å­˜ï¼Œä»¥ä¾¿èƒ½å¤ è¿½è¹¤å°è©±ä¸Šä¸‹æ–‡ã€‚

3. chains.ConversationalRetrievalChainï¼šç”¨æ–¼å»ºç«‹ä¸€å€‹åŸºæ–¼æª¢ç´¢çš„å°è©±éˆã€‚

4. text_splitter.RecursiveCharacterTextSplitterï¼šç”¨æ–¼å°‡é•·æ–‡æœ¬åˆ†å‰²æˆæ›´å°çš„æ–‡æœ¬å¡Šï¼Œä»¥ä¾¿æ›´æœ‰æ•ˆåœ°é€²è¡Œè™•ç†å’Œæª¢ç´¢ã€‚

5. llms.bedrock.Bedrockï¼šç”¨æ–¼èˆ‡ Bedrock LLM é€²è¡Œäº’å‹•ï¼Œæ”¯æŒä¸åŒçš„ LLM æ¨¡å‹ã€‚

6. embeddings.BedrockEmbeddingsï¼šç”¨æ–¼ç”Ÿæˆæ–‡æœ¬çš„åµŒå…¥è¡¨ç¤ºï¼Œä»¥ä¾¿åœ¨å‘é‡å„²å­˜ä¸­ä½¿ç”¨ã€‚

7. document_loaders.S3FileLoaderï¼šç”¨æ–¼å¾ S3 ä¸­è¼‰å…¥æ–‡ä»¶ã€‚

8. document_loaders.csv_loader.CSVLoaderï¼šç”¨æ–¼è¼‰å…¥å’Œè™•ç† CSV æ–‡ä»¶ã€‚

9. document_loaders.YoutubeLoaderï¼šç”¨æ–¼å¾ YouTube è¼‰å…¥å’Œè™•ç†å­—å¹•æˆ–è½‰éŒ„æ–‡æœ¬ã€‚

10. document_loaders.UnstructuredPowerPointLoaderï¼šç”¨æ–¼è™•ç†å’Œè¼‰å…¥ PowerPoint æ–‡ä»¶ã€‚

11. document_loaders.Docx2txtLoaderï¼šç”¨æ–¼è™•ç†å’Œè¼‰å…¥ Word æ–‡ä»¶ã€‚

12. memory.PostgresChatMessageHistoryï¼šç”¨æ–¼ç®¡ç†å’Œå„²å­˜å°è©±æ­·å²çš„ PostgreSQL è¨˜éŒ„ã€‚

<br>

## æ­¥é©Ÿ

1. å› ç‚ºä½¿ç”¨äº†å¤šç¨®å¥—ä»¶å¦‚å‰è¿°ï¼ŒåŸºæ–¼ç‰ˆæœ¬ä¾è³´èˆ‡è¡çªè€ƒé‡ï¼Œå»ºè­°å»ºç«‹æ–°çš„è™›æ“¬ç’°å¢ƒä¾†é‹è¡Œå°ˆæ¡ˆï¼Œé€™è£¡æˆ‘æ¸¬è©¦çš„æ˜¯ç’°å¢ƒåç¨±æ˜¯ `env0604`ã€‚

<br>

2. å®‰è£å¥—ä»¶ã€‚

    ```bash
    pip install -r requirements.txt
    ```

<br>

3. å¯æŸ¥çœ‹ `requirements.txt` æ–‡ä»¶ä¸­å„å¥—ä»¶çš„æŒ‡å®šç‰ˆæœ¬ã€‚

    ```bash
    SQLAlchemy==2.0.19
    streamlit==1.12.0
    streamlit-chat==0.1.1
    langchain==0.0.312
    boto3==1.28.61
    botocore==1.31.61
    altair==4.0.0
    pydantic==1.10.9
    psycopg==3.1.10
    psycopg-binary==3.1.10
    psycopg2-binary==2.9.6
    pgvector==0.2.3
    fake-useragent==1.3.0
    beautifulsoup4==4.12.2
    PyPDF2==3.0.1
    youtube-transcript-api
    unstructured
    python-pptx
    unstructured[pdf]
    python-dotenv==1.0.0
    ```

<br>

4. å»ºç«‹ `.env` æ–‡ä»¶ç®¡ç†æ•æ„Ÿè³‡è¨Šï¼Œä¸¦ç¢ºèªæ‰€æœ‰å¯†é‘°çš†å·²å¯«å…¥ã€‚

    ```json
    PGVECTOR_DRIVER='psycopg2'
    PGVECTOR_USER=<è‡ªå·±çš„è³‡æ–™åº«å¸³è™Ÿ>
    PGVECTOR_PASSWORD=<è‡ªå·±çš„è³‡æ–™åº«å¯†ç¢¼>
    PGVECTOR_HOST='localhost'
    PGVECTOR_PORT=5432
    PGVECTOR_DATABASE=<è¦ä½¿ç”¨çš„è³‡æ–™åº«åç¨±>
    ```

<br>

5. åœ¨è…³æœ¬ä¸­ä½¿ç”¨é€™äº›ç’°å¢ƒåƒæ•¸ã€‚

    ```python
    PGVECTOR_DRIVER = os.getenv('PGVECTOR_DRIVER')
    PGVECTOR_USER = os.getenv('PGVECTOR_USER')
    PGVECTOR_PASSWORD = os.getenv('PGVECTOR_PASSWORD')
    PGVECTOR_HOST = 'localhost'
    PGVECTOR_PORT = '5432'
    PGVECTOR_DATABASE = 'mydatabase'
    ```

<br>

6. _ç‰¹åˆ¥æ³¨æ„_ï¼Œå› ç‚ºæˆ‘èª¿ç”¨ `os.getenv()` åœ¨è…³æœ¬æœ€é–‹å§‹è™•å–å¾—ç’°å¢ƒåƒæ•¸ï¼Œæ‰€ä»¥ä¹Ÿè¦åœ¨è…³æœ¬æœ€é–‹å§‹è™•èª¿ç”¨ `load_dotenv()`ï¼›è‹¥æ¡ç”¨åŸå§‹ç¯„ä¾‹çš„æ–¹å¼ä½¿ç”¨ `os.environ.get()`ï¼Œå‰‡å¯ä»¥åœ¨ `if __name__ == '__main__'` å€å¡Šå†èª¿ç”¨ `load_dotenv()` ä¾†è¼‰å…¥ç’°å¢ƒåƒæ•¸ã€‚

<br>

7. å•Ÿå‹•å¾Œåœ¨çµ‚ç«¯æ©Ÿæœƒé¡¯ç¤ºã€‚

    ![](images/img_01.png)

<br>

8. ç¤ºç¯„è¼‰å…¥ä¸€å€‹ PDFï¼Œé»æ“Š `Process`ã€‚

    ![](images/img_03.png)

<br>

9. å‡ºç¾éŒ¯èª¤ã€‚

    ```bash
    å–å¾—å‘é‡å„²å­˜ç™¼ç”ŸéŒ¯èª¤ï¼šError raised by inference endpoint: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.
    ```

<br>

10. ç¶“æŸ¥ç•¶å‰è…³æœ¬é è¨­ä½¿ç”¨çš„æ˜¯ `v1`ï¼Œå°šæœªå–å¾— `AWS` çš„è¨±å¯ã€‚

    ```python
    embeddings = BedrockEmbeddings(
        model_id="amazon.titan-embed-text-v1",
        region_name="us-east-1"
    )
    ```

<br>

11. é€²å…¥ AWS ç”³è«‹ `v2`ï¼Œé€™å€‹æ¨¡å‹æœƒç«‹å³å–å¾—æˆæ¬Šï¼Œç„¡éœ€ç­‰å¾…ã€‚

    ![](images/img_02.png)

<br>

12. æ”¹å¯«è…³æœ¬ã€‚

    ```python
    embeddings = BedrockEmbeddings(
        model_id="amazon.titan-embed-text-v2",
        region_name="us-east-1"
    )
    ```

<br>

13. å†æ¬¡é‹è¡Œç™¼ç”ŸéŒ¯èª¤ã€‚

    ```bash
    å–å¾—å‘é‡å„²å­˜ç™¼ç”ŸéŒ¯èª¤ï¼šError raised by inference endpoint: An error occurred (ValidationException) when calling the InvokeModel operation: The provided model identifier is invalid.
    ```

<br>

14. é€éä¹‹å‰çš„åŠŸèƒ½è…³æœ¬æŸ¥è©¢æ¨¡å‹ ID æ‡‰è©²æ˜¯ `v2:0`

    ```python
    model_id="amazon.titan-embed-text-v2:0"
    ```

<br>

15. ä¿®æ”¹å¾Œé‹è¡Œé‚„æ˜¯å‡ºéŒ¯ã€‚

    ```bash
    å–å¾—å‘é‡å„²å­˜ç™¼ç”ŸéŒ¯èª¤ï¼šA string literal cannot contain NUL (0x00) characters.
    ```

<br>

16. é€™æ˜¯å› ç‚ºæä¾›çš„ PDF æ–‡æœ¬ä¸­å­˜åœ¨ `NUL å­—ä¸²ï¼ˆ0x00ï¼‰`ï¼Œé€™æœƒå°è‡´ç³»çµ±ç„¡æ³•æ­£å¸¸è™•ç†é€™äº›æ•¸æ“šï¼Œå› ç‚ºä½¿ç”¨ `PGVector.from_texts` æˆ– `PGVector` æ™‚ï¼Œé€™ç¨®å­—ä¸²æœƒå°è‡´ç„¡æ³•å„²å­˜æˆ–è™•ç†æ–‡æœ¬æ•¸æ“šï¼Œéœ€è¦åœ¨è®€å–å’Œè™•ç† PDF æ–‡ä»¶æ™‚éæ¿¾æ‰é€™äº› NUL å­—ä¸²ï¼›ä»¥ä¸‹ä¿®æ”¹ `get_pdf_text` ä»¥åŠ `get_text_chunks` å‡½æ•¸ä»¥åŠ å…¥éæ¿¾ NUL å­—ä¸²çš„é‚è¼¯ã€‚

    ```python
    # get_pdf_text
    def get_pdf_text(pdf_docs):
        text = ""
        for pdf in pdf_docs:
            pdf_reader = PdfReader(pdf)
            for page in pdf_reader.pages:
                # text += page.extract_text()
                # æ”¹ç”¨ page_textï¼Œå¾Œé¢å†å‚³å›
                page_text = page.extract_text()
                # éæ¿¾æ‰ NUL å­—ä¸²
                if page_text:
                    text += page_text.replace('\x00', '')
        return text


    # get_text_chunks
    def get_text_chunks(text):
        # ç¢ºä¿åœ¨åˆ†å‰²æ–‡æœ¬å¡Šå‰éæ¿¾æ‰ NUL å­—ä¸²
        cleaned_text = text.replace('\x00', '')
        text_splitter = RecursiveCharacterTextSplitter(
            separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""],
            chunk_size=512,
            chunk_overlap=103,
            length_function=len,
        )
        chunks = text_splitter.split_text(cleaned_text)
        return chunks
    ```

<br>

17. å†æ¬¡æäº¤ `PDF` æ–‡ä»¶å¾Œæ­£ç¢ºè®€å–ï¼Œåœ¨å´é‚Šæ¬„å¯è¼¸å…¥è¦æå•çš„å•é¡Œã€‚

    ![](images/img_04.png)

<br>

18. ä¸‹æ–¹æœƒé¡¯ç¤ºç­”æ¡ˆã€‚

    ![](images/img_05.png)

<br>

## å®Œæ•´è…³æœ¬

1. ç¨‹å¼ç¢¼ã€‚
    ```python
    import streamlit as st
    from PyPDF2 import PdfReader
    from langchain.vectorstores.pgvector import PGVector
    from langchain.memory import ConversationBufferMemory
    from langchain.chains import ConversationalRetrievalChain
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    from langchain.llms.bedrock import Bedrock
    from langchain.embeddings import BedrockEmbeddings
    from langchain.document_loaders import S3FileLoader
    from langchain.document_loaders.csv_loader import CSVLoader
    from langchain.document_loaders import YoutubeLoader
    from langchain.document_loaders import UnstructuredPowerPointLoader
    from langchain.document_loaders import Docx2txtLoader
    from langchain.memory import PostgresChatMessageHistory
    import boto3
    import tempfile
    import time
    import hashlib
    import secrets
    import os
    from dotenv import load_dotenv
    import logging

    # è¼‰å…¥ç’°å¢ƒè®Šæ•¸
    load_dotenv()
    # æ³¨æ„ï¼Œ`environ.get` æˆ– `os.getenv` å…©è€…åœ¨æœ¬è³ªä¸Šæ˜¯æœ‰å·®ç•°çš„
    # ä½†æˆ‘åå‘ç¨‹å¼ç¢¼æ•´æ½”ï¼Œæ‰€ä»¥åœ¨ç¨‹åºä¸€é–‹å§‹ä¹‹è™•å°±è¼‰å…¥ `load_dotenv()`
    # é€™æ¨£çš„è¼‰å…¥æ–¹å¼ä½¿ç”¨ `environ.get` æˆ– `os.getenv` ä¸¦ç„¡å·®ç•°
    PGVECTOR_DRIVER = os.getenv("PGVECTOR_DRIVER")
    PGVECTOR_USER = os.getenv("PGVECTOR_USER")
    PGVECTOR_PASSWORD = os.getenv("PGVECTOR_PASSWORD")
    PGVECTOR_HOST = "localhost"
    PGVECTOR_PORT = "5432"
    PGVECTOR_DATABASE = "mydatabase"

    logging.getLogger("botocore").setLevel(logging.ERROR)


    def debug_01():
        # æª¢æŸ¥è³‡æ–™åº«çš„ URI æ˜¯å¦æ­£ç¢º
        CONNECTION_STRING = f"://{PGVECTOR_USER}:{PGVECTOR_PASSWORD}@{PGVECTOR_HOST}:{PGVECTOR_PORT}/{PGVECTOR_DATABASE}"
        # ç¢ºä¿æ­£ç¢ºè¼¸å‡ºé€£æ¥å­—ä¸²ï¼Œä¾¿æ–¼æª¢æŸ¥
        print(f"CONNECTION_STRING: {CONNECTION_STRING}")


    def styled_header(text):
        header_html = f"""
        <div style="background-color:#4CAF50;text-align:center;padding:10px">
        <h1 style="color:white;text-align:center;">{text}</h1>
        </div>
        """
        return header_html


    def styled_subheader(
        text,
        font_size="24px",
        color="#8A2BE2",
        background_color="#f0e5ff"
    ):
        subheader_html = f"""
        <div style="box-shadow:0 2px 10px #ddd; padding: 5px;"
        " background-color: {background_color};"
        " border-radius: 5px; margin: 10px 0; text-align: center;">
            <h3 style="color: {color}; font-size: {font_size};"
            " margin: 0;">{text}</h3>
        </div>
        """
        return subheader_html


    def generate_session_id():
        t = int(time.time() * 1000)
        r = secrets.randbelow(1000000)
        return hashlib.md5(
            bytes(str(t) + str(r), "utf-8"), usedforsecurity=False
        ).hexdigest()


    def get_pdf_text(pdf_docs):
        text = ""
        for pdf in pdf_docs:
            pdf_reader = PdfReader(pdf)
            for page in pdf_reader.pages:
                # text += page.extract_text()
                # æ”¹ç”¨ page_textï¼Œå¾Œé¢å†å‚³å›
                page_text = page.extract_text()
                # éæ¿¾æ‰ NUL å­—ä¸²
                if page_text:
                    text += page_text.replace('\x00', '')
        return text


    def get_text_chunks(text):
        # ç¢ºä¿åœ¨åˆ†å‰²æ–‡æœ¬å¡Šå‰éæ¿¾æ‰ NUL å­—ä¸²
        cleaned_text = text.replace('\x00', '')
        text_splitter = RecursiveCharacterTextSplitter(
            separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""],
            chunk_size=512,
            chunk_overlap=103,
            length_function=len,
        )
        # chunks = text_splitter.split_text(text)
        chunks = text_splitter.split_text(cleaned_text)
        return chunks


    def get_vectorstore(text_chunks):
        embeddings = BedrockEmbeddings(
            model_id="amazon.titan-embed-text-v2:0",
            # é è¨­æ˜¯ `-2`ï¼Œé€™è£¡æ”¹ä¸€ä¸‹
            region_name="us-east-1"
        )
        try:
            if text_chunks is None:
                return PGVector(
                    connection_string=CONNECTION_STRING,
                    embedding_function=embeddings,
                )
            return PGVector.from_texts(
                texts=text_chunks,
                embedding=embeddings,
                connection_string=CONNECTION_STRING
            )
        except Exception as e:
            # åŸæœ¬çš„è…³æœ¬æ˜¯å¼•ç™¼éŒ¯èª¤
            # raise e
            # æ”¹ç‚ºè¼¸å‡ºéŒ¯èª¤çœ‹ä¸€ä¸‹
            print(f'å–å¾—å‘é‡å„²å­˜ç™¼ç”ŸéŒ¯èª¤ï¼š{e}')


    def get_bedrock_llm(selected_llm):
        print(f"[INFO] Selected LLM is : {selected_llm}")
        if selected_llm in [
            "anthropic.claude-v2",
            "anthropic.claude-v1",
            "anthropic.claude-instant-v1",
        ]:
            llm = Bedrock(
                model_id=selected_llm,
                model_kwargs={"max_tokens_to_sample": 4096}
            )

        elif selected_llm in [
            "amazon.titan-tg1-large",
            "amazon.titan-text-express-v1",
            "amazon.titan-text-lite-v1",
        ]:
            llm = Bedrock(
                model_id=selected_llm,
                model_kwargs={
                    "maxTokenCount": 4096,
                    "stopSequences": [],
                    "temperature": 0,
                    "topP": 1,
                },
            )
        else:
            raise ValueError(f"Unsupported LLM: {selected_llm}")

        return llm


    def get_conversation_chain(vectorstore, selected_llm):
        # è¨»è§£æ‰
        # llm = Bedrock(
        #     model_id="anthropic.claude-instant-v1",
        #     region_name="us-west-2"
        # )
        llm = get_bedrock_llm(selected_llm)
        _connection_string = CONNECTION_STRING.replace(
            "+psycopg2", "").replace(":5432", "")
        message_history = PostgresChatMessageHistory(
            connection_string=_connection_string, session_id=generate_session_id()
        )
        memory = ConversationBufferMemory(
            memory_key="chat_history",
            chat_memory=message_history,
            return_source_documents=True,
            return_messages=True,
        )
        conversation_chain = ConversationalRetrievalChain.from_llm(
            llm=llm, retriever=vectorstore.as_retriever(), memory=memory
        )
        return conversation_chain


    def color_text(text, color="black"):
        return f'<span style="color:{color}">{text}</span>'


    bot_template = "ğŸ¤– BOT : {0}"
    user_template = "ğŸ‘¤ USER : {0}"


    def handle_userinput(user_question):
        bot_template = "ğŸ¤– BOT : {0}"
        user_template = "ğŸ‘¤ USER : {0}"
        try:
            response = st.session_state.conversation({"question": user_question})
            st.markdown(
                color_text(
                    user_template.format(response["question"]),
                    color="blue"
                ),
                unsafe_allow_html=True,
            )
            st.markdown(
                color_text(
                    bot_template.format(response["answer"]),
                    color="green"
                ),
                unsafe_allow_html=True,
            )
            print("Response", response)
        except ValueError as e:
            st.write(e)
            st.write("ğŸ˜ æŠ±æ­‰ï¼Œè«‹æ›å€‹æ–¹å¼å†å•ä¸€æ¬¡ã€‚")
            return
        st.session_state.chat_history = response["chat_history"]
        for i, message in enumerate(st.session_state.chat_history):
            if i % 2 == 0:
                st.markdown(
                    color_text(
                        user_template.format(message.content),
                        color="blue"
                    ),
                    unsafe_allow_html=True,
                )

            else:
                st.markdown(
                    color_text(
                        bot_template.format(message.content),
                        color="green"
                    ),
                    unsafe_allow_html=True,
                )


    def main():
        # Updated header styling
        st.markdown(
            styled_header(
                "Unified AI Q&A: Harnessing pgvector, Amazon Aurora"
                " & Amazon Bedrock ğŸ“šğŸ¦œ"
            ),
            unsafe_allow_html=True,
        )

        options = [
            "ğŸ“„ PDFs",
            "â˜ï¸ S3 Bucket",
            "ğŸ“º Youtube",
            "ğŸ“‘ CSV", "ğŸ–¼ï¸ PPT",
            "ğŸ“ Word"
        ]
        # ä½¿ç”¨å–®é¸æŒ‰éˆ•è€Œä¸æ˜¯é¸æ“‡æ¡†
        st.markdown(
            styled_subheader("ğŸ“Œ Select a source ğŸ“Œ"),
            unsafe_allow_html=True
        )
        selected_source = st.radio("", options)

        # æ·»åŠ  LLM é¸å–®å…ƒä»¶
        st.markdown(
            styled_subheader("ğŸ¤– Select the LLM ğŸ¤–"),
            unsafe_allow_html=True
        )
        llm_options = [
            "anthropic.claude-v2",
            "anthropic.claude-instant-v1",
            "amazon.titan-tg1-large",
            "amazon.titan-text-express-v1",
            "amazon.titan-text-lite-v1",
        ]

        selected_llm = st.radio("Choose an LLM", options=llm_options)

        # PDF
        if selected_source == "ğŸ“„ PDFs":
            pdf_docs = st.file_uploader(
                "ğŸ“¥ Upload your PDFs here:",
                type="pdf",
                accept_multiple_files=True
            )
            if st.button("ğŸ”„ Process"):
                with st.spinner("ğŸ”§ Processing..."):
                    raw_text = get_pdf_text(pdf_docs)
                    text_chunks = get_text_chunks(raw_text)
                    vectorstore = get_vectorstore(text_chunks)
                    if vectorstore is None:
                        st.write("Failed to initialize vector store.")
                        return
                    st.session_state.conversation = get_conversation_chain(
                        vectorstore, selected_llm
                    )
        elif selected_source == "â˜ï¸ S3 Bucket":
            s3_client = boto3.client("s3")
            # é€™äº›ç‰©ä»¶å„²å­˜åœ¨ aurora-genai-2023 å„²å­˜æ¡¶ä¸­ã€‚è¼¸å…¥é©ç•¶çš„å„²å­˜æ¡¶åç¨±
            response = s3_client.list_objects_v2(
                # å°‡å„²å­˜æ¡¶åç¨±è®Šæ›´ç‚ºè‡ªå·±çš„å„²å­˜æ¡¶åç¨±
                Bucket="aurora-genai-2023",
                Prefix="documentEmbeddings/"
            )
            document_keys = [
                obj["Key"].split("/")[1]
                for obj in response["Contents"]
            ][1:]
            user_input = st.selectbox(
                "Select an S3 document and click on 'Process'",
                document_keys
            )
            if st.button("Process"):
                with st.spinner("Processing"):
                    prefix = "documentEmbeddings/" + user_input
                    loader = S3FileLoader("aurora-genai-2023", prefix)
                    docs = loader.load()
                    for i in docs:
                        text_chunks = get_text_chunks(i.page_content)
                        vectorstore = get_vectorstore(text_chunks)
                        if vectorstore is None:
                            st.write("Failed to initialize vector store.")
                            return
                    st.session_state.conversation = get_conversation_chain(
                        vectorstore, selected_llm
                    )
        elif selected_source == "ğŸ“‘ CSV":
            csv_docs = st.file_uploader(
                "Upload your CSV here and click on 'Process'",
                type="csv",
                accept_multiple_files=False,
            )
            if st.button("Process"):
                with st.spinner("Processing"):
                    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
                        tmp_file.write(csv_docs.getvalue())
                        tmp_file_path = tmp_file.name
                    loader = CSVLoader(
                        file_path=tmp_file_path,
                        encoding="utf-8",
                        csv_args={"delimiter": ","},
                    )
                    docs = loader.load()
                    for i in docs:
                        text_chunks = get_text_chunks(i.page_content)
                        vectorstore = get_vectorstore(text_chunks)
                        if vectorstore is None:
                            st.write("Failed to initialize vector store.")
                            return
                    st.session_state.conversation = get_conversation_chain(
                        vectorstore, selected_llm
                    )
        elif selected_source == "ğŸ“º Youtube":
            user_input = st.text_input("è¼¸å…¥ YouTube é€£çµä¸¦é»æ“Šã€ŒProcessã€")
            if st.button("Process"):
                with st.spinner("Processing"):
                    loader = YoutubeLoader.from_youtube_url(user_input)
                    transcript = loader.load()
                    for i in transcript:
                        text_chunks = get_text_chunks(i.page_content)
                        vectorstore = get_vectorstore(text_chunks)
                        if vectorstore is None:
                            st.write("ç„¡æ³•åˆå§‹åŒ–å‘é‡å„²å­˜ã€‚")
                            return
                    st.session_state.conversation = get_conversation_chain(
                        vectorstore, selected_llm
                    )

        elif selected_source == "ğŸ–¼ï¸ PPT":
            ppt_docs = st.file_uploader(
                "åœ¨æ­¤ä¸Šå‚³æ‚¨çš„ PPTï¼Œç„¶å¾ŒæŒ‰ä¸€ä¸‹ã€ŒProcessã€",
                type=["ppt", "pptx"],
                accept_multiple_files=False,
            )
            if st.button("Process"):
                with st.spinner("Processing"):
                    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
                        tmp_file.write(ppt_docs.getvalue())
                        tmp_file_path = tmp_file.name
                    loader = UnstructuredPowerPointLoader(tmp_file_path)
                    docs = loader.load()
                    for i in docs:
                        text_chunks = get_text_chunks(i.page_content)
                        vectorstore = get_vectorstore(text_chunks)
                        if vectorstore is None:
                            st.write("ç„¡æ³•åˆå§‹åŒ–å‘é‡å„²å­˜ã€‚")
                            return
                    st.session_state.conversation = get_conversation_chain(
                        vectorstore, selected_llm
                    )

        elif selected_source == "ğŸ“ Word":
            word_docs = st.file_uploader(
                "åœ¨æ­¤è™•ä¸Šå‚³æ‚¨çš„ Word æ–‡ä»¶ï¼Œç„¶å¾ŒæŒ‰ä¸€ä¸‹ã€ŒProcessã€",
                type=["docx"],
                accept_multiple_files=False,
            )
            if st.button("Process"):
                with st.spinner("Processing"):
                    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
                        tmp_file.write(word_docs.getvalue())
                        tmp_file_path = tmp_file.name
                    loader = Docx2txtLoader(tmp_file_path)
                    docs = loader.load()
                    for i in docs:
                        text_chunks = get_text_chunks(i.page_content)
                        vectorstore = get_vectorstore(text_chunks)
                        if vectorstore is None:
                            st.write("ç„¡æ³•åˆå§‹åŒ–å‘é‡å„²å­˜ã€‚")
                            return
                    st.session_state.conversation = get_conversation_chain(
                        vectorstore, selected_llm
                    )

        st.sidebar.header("ğŸ—£ï¸ èˆ‡æ©Ÿå™¨äººèŠå¤©")
        user_question = st.sidebar.text_input("ğŸ’¬ è©¢å•æœ‰é—œä½ æ‰€æä¾›æ•¸æ“šçš„å•é¡Œï¼š")
        if user_question:
            handle_userinput(user_question)

        if "conversation" not in st.session_state:
            st.session_state.conversation = get_conversation_chain(
                get_vectorstore(None), selected_llm
            )
        if "chat_history" not in st.session_state:
            st.session_state.chat_history = None


    # è¼¸å…¥è³‡æ–™åº«åç¨±
    if __name__ == "__main__":
        # è‹¥åœ¨ `__main__` ä¸­è¼‰å…¥å‰‡å¿…é ˆä½¿ç”¨ `environ.get` ä¾†è®€å–ä¸¦å¯«å…¥ç’°å¢ƒåƒæ•¸
        # load_dotenv()

        CONNECTION_STRING = PGVector.connection_string_from_db_params(
            driver=PGVECTOR_DRIVER,
            user=PGVECTOR_USER,
            password=PGVECTOR_PASSWORD,
            host=PGVECTOR_HOST,
            port=PGVECTOR_PORT,
            database=PGVECTOR_DATABASE,
        )

        main()
    ```

<br>

___

_END_