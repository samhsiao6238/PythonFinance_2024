# é«˜éšæ©Ÿå™¨äºº

_ä½¿ç”¨ PostgreSQL ä½œç‚ºå‘é‡å„²å­˜ã€ä½¿ç”¨ Anthropic æ¨¡å‹_

<br>

## é‹ä½œéç¨‹

_é€™å€‹å°ˆæ¡ˆæ˜¯ä¸€å€‹ `Streamlit æ‡‰ç”¨`ï¼Œä½¿ç”¨ `PostgreSQL` å’Œ `pgvector` é€²è¡Œ `å‘é‡å„²å­˜` å’Œ `å‘é‡æª¢ç´¢`ï¼Œä¸¦ä¸”åˆ©ç”¨ `AWS çš„ Anthropic æ¨¡å‹` ä¾†å›ç­”ç”¨æˆ¶çš„å•é¡Œã€‚_

<br>

1. åœ¨ `æ•¸æ“šæ¸…æ´—` éƒ¨åˆ†ï¼Œä½¿ç”¨ `PyPDF2` è®€å– PDF æ–‡ä»¶ï¼Œæå–ä¸¦éæ¿¾æ‰ NUL å­—ä¸²ï¼›å¦å¤–ï¼Œä½¿ç”¨ `RecursiveCharacterTextSplitter` å°‡æ–‡æœ¬åˆ†å‰²æˆæ›´å°çš„æ–‡æœ¬å¡Šï¼Œä»¥ä¾¿æ›´æœ‰æ•ˆåœ°é€²è¡Œè™•ç†å’Œæª¢ç´¢ã€‚

<br>

2. åœ¨ `ç”ŸæˆåµŒå…¥å‘é‡` éƒ¨åˆ†ï¼Œä½¿ç”¨ `BedrockEmbeddings` ç”Ÿæˆæ–‡æœ¬åµŒå…¥å‘é‡ï¼Œä¸¦ä½¿ç”¨ `PGVector` å°‡åµŒå…¥å‘é‡å„²å­˜åˆ° `PostgreSQL` ä¸­ï¼›ç‰¹åˆ¥æ³¨æ„ï¼Œç›¸åŒçš„æ–‡ä»¶æ¯æ¬¡é€²è¡Œè™•ç†ç”Ÿæˆçš„å‘é‡å„²å­˜å¯èƒ½æœƒæœ‰æ‰€ä¸åŒï¼Œå› ç‚ºåµŒå…¥æ¨¡å‹å’Œè™•ç†éç¨‹ä¸­çš„éš¨æ©Ÿæ€§æœƒå½±éŸ¿çµæœã€‚

<br>

3. åœ¨ `é•·æœŸè¨˜æ†¶` éƒ¨åˆ†ï¼Œä½¿ç”¨ `ConversationBufferMemory` å’Œ `PostgresChatMessageHistory` ç®¡ç†å’Œå„²å­˜å°è©±æ­·å²ï¼›å¦å¤–ï¼Œä½¿ç”¨ `ConversationalRetrievalChain` å»ºç«‹åŸºæ–¼æª¢ç´¢çš„å°è©±éˆã€‚

<br>

4. åœ¨ `ç”Ÿæˆå›ç­”` éƒ¨åˆ†ï¼Œä½¿ç”¨æª¢ç´¢åˆ°çš„æ–‡æœ¬å‘é‡ä½œç‚ºä¸Šä¸‹æ–‡ï¼Œé€šéé¸æ“‡çš„ LLM æ¨¡å‹å¦‚ `anthropic.claude-v2` ç”Ÿæˆè‡ªç„¶èªè¨€å›ç­”ã€‚

<br>

## ä½¿ç”¨å¥—ä»¶

_æœ¬å°ˆæ¡ˆå°‡ä½¿ç”¨åˆ°ä»¥ä¸‹çš„å¥—ä»¶_

<br>

1. Streamlitã€‚

2. PyPDF2ï¼šç”¨æ–¼è™•ç† PDF æ–‡ä»¶ã€‚

3. LangChainï¼š_å¾ŒçºŒå°‡è©³ç´°èªªæ˜_ã€‚

4. boto3ï¼šç”¨æ–¼èˆ‡ AWS æœå‹™é€²è¡Œäº’å‹•çš„ SDKï¼Œæ”¯æŒæ“ä½œ S3ã€DynamoDBã€EC2 ç­‰å¤šç¨® AWS æœå‹™ã€‚

5. tempfileï¼šç”¨æ–¼å»ºç«‹è‡¨æ™‚æ–‡ä»¶å’Œç›®éŒ„ï¼Œæä¾›äº†ä¸€å€‹å®‰å…¨çš„æ–¹å¼ä¾†å»ºç«‹è‡¨æ™‚æ–‡ä»¶ï¼Œé€™äº›æ–‡ä»¶åœ¨ä½¿ç”¨å¾Œå¯ä»¥è‡ªå‹•åˆªé™¤ã€‚

6. timeï¼šæä¾›æ™‚é–“ç›¸é—œçš„åŠŸèƒ½ï¼Œæ”¯æŒå–å¾—ç•¶å‰æ™‚é–“ã€é€²è¡Œæ™‚é–“è¨ˆç®—ã€æ¨¡æ“¬å»¶é²ç­‰æ“ä½œã€‚

7. hashlibï¼šç”¨æ–¼ç”Ÿæˆå“ˆå¸Œå€¼å’Œé€²è¡ŒåŠ å¯†æ“ä½œï¼Œæ”¯æŒå¤šç¨®å“ˆå¸Œç®—æ³•ï¼Œå¦‚ MD5ã€SHA-1ã€SHA-256 ç­‰ï¼Œç”¨æ–¼ç”Ÿæˆæ•¸æ“šçš„å”¯ä¸€æ¨™è­˜ç¬¦ã€‚

8. secretsï¼šç”¨æ–¼ç”Ÿæˆå®‰å…¨çš„éš¨æ©Ÿæ•¸å’Œå¯†ç¢¼ï¼Œæä¾›äº†æ›´é«˜å®‰å…¨æ€§çš„éš¨æ©Ÿæ•¸ç”Ÿæˆæ–¹æ³•ï¼Œé©ç”¨æ–¼åŠ å¯†å¯†é‘°ã€éš¨æ©Ÿæ¨™è­˜ç¬¦ç­‰å ´åˆã€‚

9. loggingï¼šæä¾›è¨˜éŒ„å’Œè·Ÿè¹¤æ‡‰ç”¨é‹è¡Œéç¨‹ä¸­ç™¼ç”Ÿçš„äº‹ä»¶ï¼Œæ”¯æŒå¤šç¨®æ—¥èªŒç´šåˆ¥ï¼ˆå¦‚ DEBUGã€INFOã€WARNINGã€ERRORã€CRITICALï¼‰ï¼Œä¾¿æ–¼é€²è¡Œæ‡‰ç”¨çš„æ•…éšœæ’é™¤å’Œæ€§èƒ½åˆ†æã€‚

<br>

## LangChain æ¨¡çµ„æˆ–é¡

_æœ¬å°ˆæ¡ˆå°‡ä½¿ç”¨åˆ°çš„ LangChain æ¨¡çµ„æˆ–é¡å¦‚ä¸‹ï¼Œå…¶ä¸­ vectorstores.pgvector æ˜¯æ¨¡çµ„_

<br>

1. vectorstores.pgvectorï¼šä½¿ç”¨ pgvector é€²è¡Œå‘é‡å„²å­˜ï¼Œæ”¯æŒé«˜æ•ˆçš„å‘é‡æª¢ç´¢æ“ä½œã€‚

2. memory.ConversationBufferMemoryï¼šç”¨æ–¼ç®¡ç†å°è©±çš„å…§å­˜ï¼Œä»¥ä¾¿èƒ½å¤ è¿½è¹¤å°è©±ä¸Šä¸‹æ–‡ã€‚

3. chains.ConversationalRetrievalChainï¼šç”¨æ–¼å»ºç«‹ä¸€å€‹åŸºæ–¼æª¢ç´¢çš„å°è©±éˆã€‚

4. text_splitter.RecursiveCharacterTextSplitterï¼šç”¨æ–¼å°‡é•·æ–‡æœ¬åˆ†å‰²æˆæ›´å°çš„æ–‡æœ¬å¡Šï¼Œä»¥ä¾¿æ›´æœ‰æ•ˆåœ°é€²è¡Œè™•ç†å’Œæª¢ç´¢ã€‚

5. llms.bedrock.Bedrockï¼šç”¨æ–¼èˆ‡ Bedrock LLM é€²è¡Œäº’å‹•ï¼Œæ”¯æŒä¸åŒçš„ LLM æ¨¡å‹ã€‚

6. embeddings.BedrockEmbeddingsï¼šç”¨æ–¼ç”Ÿæˆæ–‡æœ¬çš„åµŒå…¥è¡¨ç¤ºï¼Œä»¥ä¾¿åœ¨å‘é‡å„²å­˜ä¸­ä½¿ç”¨ã€‚

7. document_loaders.S3FileLoaderï¼šç”¨æ–¼å¾ S3 ä¸­è¼‰å…¥æ–‡ä»¶ã€‚

8. document_loaders.csv_loader.CSVLoaderï¼šç”¨æ–¼è¼‰å…¥å’Œè™•ç† CSV æ–‡ä»¶ã€‚

9. document_loaders.YoutubeLoaderï¼šç”¨æ–¼å¾ YouTube è¼‰å…¥å’Œè™•ç†å­—å¹•æˆ–è½‰éŒ„æ–‡æœ¬ã€‚

10. document_loaders.UnstructuredPowerPointLoaderï¼šç”¨æ–¼è™•ç†å’Œè¼‰å…¥ PowerPoint æ–‡ä»¶ã€‚

11. document_loaders.Docx2txtLoaderï¼šç”¨æ–¼è™•ç†å’Œè¼‰å…¥ Word æ–‡ä»¶ã€‚

12. memory.PostgresChatMessageHistoryï¼šç”¨æ–¼ç®¡ç†å’Œå„²å­˜å°è©±æ­·å²çš„ PostgreSQL è¨˜éŒ„ã€‚

<br>

## æº–å‚™å·¥ä½œ

1. æœ¬å°ˆæ¡ˆä½¿ç”¨äº†å¤šç¨®å¥—ä»¶ï¼Œé¿å…ç‰ˆæœ¬è¡çªï¼Œå»ºè­°å»ºç«‹æ–°çš„è™›æ“¬ç’°å¢ƒä¾†é‹è¡Œå°ˆæ¡ˆï¼›é€™è£¡æ²¿ç”¨å‰é¢è³‡æ–™åº«åŸºæœ¬æ“ä½œæ™‚å»ºç«‹çš„ `envPSLC`ï¼›ä»¥ä¸‹å„é»æŒ‡ä»¤åƒ…ä½œæç¤ºï¼Œç¨‹åºä¸å†è´…è¿°ã€‚

    ```bash
    python -m venv envPSLC
    ```

<br>

2. å•Ÿå‹•è™›æ“¬ç’°å¢ƒï¼Œæˆ–å¯«å…¥ `.zshrc`ã€‚

    ```bash
    source /Users/samhsiao/Documents/PythonVenv/envPSLC/bin/activate
    ```

<br>

3. å»ºç«‹ä¸¦é€²å…¥å°ˆæ¡ˆè³‡æ–™å¤¾ã€‚ 

    ```bash
    cd ~/Desktop && mkdir _exPSLC_ && cd _exPSLC_
    ```

<br>

4. å»ºç«‹ä¸»è…³æœ¬ã€å¥—ä»¶ç®¡ç†æ–‡ä»¶ã€ç’°å¢ƒè®Šæ•¸ç®¡ç†æ–‡ä»¶ã€åŸå§‹æª”æ§åˆ¶æ–‡ä»¶ï¼›è‹¥æ²¿ç”¨ä¹‹å‰è³‡æ–™å¤¾ï¼Œåƒ…éœ€å»ºç«‹å‰å…©é …ã€‚

    ```bash
    touch app.py requirements.txt .env .gitignore
    
    # è‹¥æ²¿ç”¨ä¹‹å‰è³‡æ–™å¤¾ï¼Œåƒ…éœ€å»ºç«‹å‰å…©é …
    touch app.py requirements.txt
    ```

<br>

5. å•Ÿå‹• VSCodeã€‚

    ```bash
    code .
    ```

<br>

6. åœ¨ `.gitignore` æ–‡ä»¶ä¸­å¯«å…¥ `.env`ã€‚

    ```bash
    .env
    ```

<br>

## å®‰è£å¥—ä»¶

1. ç·¨è¼¯ `requirements.txt` æ–‡ä»¶ï¼Œä¸¦æŒ‡å®šå„å¥—ä»¶çš„ç‰ˆæœ¬ã€‚

    ```bash
    SQLAlchemy==2.0.19
    streamlit==1.12.0
    streamlit-chat==0.1.1
    langchain==0.0.312
    boto3==1.28.61
    botocore==1.31.61
    altair==4.0.0
    pydantic==1.10.9
    psycopg==3.1.10
    psycopg-binary==3.1.10
    psycopg2-binary==2.9.6
    pgvector==0.2.3
    fake-useragent==1.3.0
    beautifulsoup4==4.12.2
    PyPDF2==3.0.1
    youtube-transcript-api
    unstructured
    python-pptx
    unstructured[pdf]
    python-dotenv==1.0.0
    ```

<br>

2. å…ˆä¸»å‹•æ›´æ–° pipã€‚

    ```bash
    pip install --upgrade pip
    ````

<br>

3. åœ¨é€™äº›å¥—ä»¶ä¸­ï¼Œä»æœ‰éƒ¨åˆ†æœƒè‡ªå‹•ä½¿ç”¨éæ™‚çš„ `setup.py install` æ–¹æ³•é€²è¡Œå®‰è£ï¼Œè€Œä¸æ˜¯ä»¥ `PEP 517/518 æ¨™æº–` ä½¿ç”¨ `pyproject.toml` æ–‡ä»¶ï¼Œé€™å°å› æ–¼å¥—ä»¶çš„è¨­ç½®ï¼Œæ‰€ä»¥åœ¨å®‰è£æ™‚åŠ å…¥åƒæ•¸ `--use-pep517`ï¼›è«‹ç¢ºå¯¦è§€å¯Ÿå®‰è£éç¨‹ç„¡éŒ¯èª¤è¨Šæ¯ã€‚

    ```bash
    pip install --use-pep517 -r requirements.txt
    ```

<br>

## å»ºç«‹ç’°å¢ƒè®Šæ•¸

1. ç·¨è¼¯ `.env` æ–‡ä»¶ç®¡ç†æ•æ„Ÿè³‡è¨Šï¼Œä¸¦ç¢ºèªæ‰€æœ‰å¯†é‘°çš†å·²å¯«å…¥ï¼›èˆ‡ä¹‹å‰ç›¸åŒï¼Œä¸¦ç„¡æ·»åŠ é …ç›®ã€‚

    ```json
    PGVECTOR_DRIVER='psycopg2'
    PGVECTOR_USER=<è‡ªå·±çš„è³‡æ–™åº«å¸³è™Ÿ>
    PGVECTOR_PASSWORD=<è‡ªå·±çš„è³‡æ–™åº«å¯†ç¢¼>
    PGVECTOR_HOST='localhost'
    PGVECTOR_PORT=5432
    PGVECTOR_DATABASE=<è¦ä½¿ç”¨çš„è³‡æ–™åº«åç¨±>
    ```

<br>

2. åœ¨è…³æœ¬ä¸­ä½¿ç”¨é€™äº›ç’°å¢ƒåƒæ•¸ã€‚

    ```python
    PGVECTOR_DRIVER = os.getenv('PGVECTOR_DRIVER')
    PGVECTOR_USER = os.getenv('PGVECTOR_USER')
    PGVECTOR_PASSWORD = os.getenv('PGVECTOR_PASSWORD')
    PGVECTOR_HOST = os.getenv('PGVECTOR_HOST')
    PGVECTOR_PORT = os.getenv('PGVECTOR_PORT')
    PGVECTOR_DATABASE = os.getenv('PGVECTOR_DATABASE')
    ```

<br>

3. _ç‰¹åˆ¥æ³¨æ„_ï¼Œå› ç‚ºä½¿ç”¨ `os.getenv()` åœ¨è…³æœ¬æœ€é–‹å§‹è™•å–å¾—ç’°å¢ƒåƒæ•¸ï¼Œæ‰€ä»¥ä¹Ÿè¦åœ¨è…³æœ¬æœ€é–‹å§‹è™•èª¿ç”¨ `load_dotenv()` ä»¥è¼‰å…¥ç’°å¢ƒè®Šæ•¸ï¼›è‹¥ä½¿ç”¨ `os.environ.get()`ï¼Œå‰‡å¯ä»¥åœ¨ `if __name__ == '__main__'` å€å¡Šå†èª¿ç”¨ `load_dotenv()` ä¾†è¼‰å…¥ç’°å¢ƒåƒæ•¸ã€‚

<br>

## os.getenv() vs os.environ.get()

_å…©è€…çš„å·®ç•°åœ¨æ–¼è¼‰å…¥ç’°å¢ƒè®Šæ•¸çš„æ™‚æ©Ÿå’Œæ–¹å¼_

<br>

1. `os.getenv()` åœ¨èª¿ç”¨æ™‚æœƒç›´æ¥æœå°‹ç’°å¢ƒè®Šæ•¸ï¼Œå› æ­¤å¿…é ˆåœ¨è…³æœ¬ä¸€é–‹å§‹èª¿ç”¨ `load_dotenv()` ä¾†è¼‰å…¥ç’°å¢ƒè®Šæ•¸ï¼Œå¦å‰‡ `os.getenv()` å°‡ç„¡æ³•ç²å–æ­£ç¢ºçš„å€¼ã€‚

<br>

2. `os.environ.get()` æœå°‹çš„æ˜¯ç•¶å‰ç’°å¢ƒä¸­çš„è®Šæ•¸ï¼Œå¯ä»¥åœ¨ä»»ä½•æ™‚å€™æœå°‹ï¼Œåªè¦åœ¨æœå°‹ä¹‹å‰ç’°å¢ƒè®Šæ•¸å·²ç¶“è¢«è¼‰å…¥åˆ° os.environ ä¸­ã€‚å› æ­¤ï¼Œå¯ä»¥åœ¨è…³æœ¬é‹è¡Œéç¨‹ä¸­çš„ä»»ä½•åœ°æ–¹è¼‰å…¥ç’°å¢ƒè®Šæ•¸ã€‚

<br>

## å°ˆæ¡ˆé–‹ç™¼

1. ç·¨è¼¯ä¸»è…³æœ¬ `app.py`ï¼Œé¿å…ä½”ç”¨ç¯‡å¹…ï¼Œè«‹æ»‘å‹•åˆ°è¬›ç¾©æœ€ä¸‹æ–¹è¤‡è£½ï¼›ç·¨è¼¯å®Œæˆé€²è¡Œå•Ÿç”¨ã€‚

    ```bash
    streamlit run app.py
    ```

<br>

2. å•Ÿå‹•å¾Œåœ¨çµ‚ç«¯æ©Ÿæœƒé¡¯ç¤ºã€‚

    ![](images/img_01.png)

<br>

3. ç¤ºç¯„è¼‰å…¥ä¸€å€‹ PDFï¼Œé»æ“Š `Process`ã€‚

    ![](images/img_03.png)

<br>

4. å‡ºç¾éŒ¯èª¤ã€‚

    ```bash
    å–å¾—å‘é‡å„²å­˜ç™¼ç”ŸéŒ¯èª¤ï¼šError raised by inference endpoint: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.
    ```

<br>

5. ç¶“æŸ¥ç•¶å‰è…³æœ¬é è¨­ä½¿ç”¨çš„æ˜¯ `v1`ï¼Œå°šæœªå–å¾— `AWS` çš„è¨±å¯ã€‚

    ```python
    embeddings = BedrockEmbeddings(
        model_id="amazon.titan-embed-text-v1",
        region_name="us-east-1"
    )
    ```

<br>

6. é€²å…¥ AWS ç”³è«‹ `v2`ï¼Œé€™å€‹æ¨¡å‹æœƒç«‹å³å–å¾—æˆæ¬Šï¼Œç„¡éœ€ç­‰å¾…ã€‚

    ![](images/img_02.png)

<br>

7. æ”¹å¯«è…³æœ¬ã€‚

    ```python
    embeddings = BedrockEmbeddings(
        model_id="amazon.titan-embed-text-v2",
        region_name="us-east-1"
    )
    ```

<br>

8. å†æ¬¡é‹è¡Œç™¼ç”ŸéŒ¯èª¤ã€‚

    ```bash
    å–å¾—å‘é‡å„²å­˜ç™¼ç”ŸéŒ¯èª¤ï¼šError raised by inference endpoint: An error occurred (ValidationException) when calling the InvokeModel operation: The provided model identifier is invalid.
    ```

<br>

9. é€éä¹‹å‰çš„åŠŸèƒ½è…³æœ¬æŸ¥è©¢æ¨¡å‹ ID æ‡‰è©²æ˜¯ `v2:0`

    ```python
    model_id="amazon.titan-embed-text-v2:0"
    ```

<br>

10. ä¿®æ”¹å¾Œé‹è¡Œé‚„æ˜¯å‡ºéŒ¯ã€‚

    ```bash
    å–å¾—å‘é‡å„²å­˜ç™¼ç”ŸéŒ¯èª¤ï¼šA string literal cannot contain NUL (0x00) characters.
    ```

<br>

11. é€™æ˜¯å› ç‚ºæä¾›çš„ PDF æ–‡æœ¬ä¸­å­˜åœ¨ `NUL å­—ä¸²ï¼ˆ0x00ï¼‰`ï¼Œé€™æœƒå°è‡´ç³»çµ±ç„¡æ³•æ­£å¸¸è™•ç†é€™äº›æ•¸æ“šï¼Œå› ç‚ºä½¿ç”¨ `PGVector.from_texts` æˆ– `PGVector` æ™‚ï¼Œé€™ç¨®å­—ä¸²æœƒå°è‡´ç„¡æ³•å„²å­˜æˆ–è™•ç†æ–‡æœ¬æ•¸æ“šï¼Œéœ€è¦åœ¨è®€å–å’Œè™•ç† PDF æ–‡ä»¶æ™‚éæ¿¾æ‰é€™äº› NUL å­—ä¸²ï¼›ä»¥ä¸‹ä¿®æ”¹ `get_pdf_text` ä»¥åŠ `get_text_chunks` å‡½æ•¸ä»¥åŠ å…¥éæ¿¾ NUL å­—ä¸²çš„é‚è¼¯ã€‚

    ```python
    # get_pdf_text
    def get_pdf_text(pdf_docs):
        text = ""
        for pdf in pdf_docs:
            pdf_reader = PdfReader(pdf)
            for page in pdf_reader.pages:
                # text += page.extract_text()
                # æ”¹ç”¨ page_textï¼Œå¾Œé¢å†å‚³å›
                page_text = page.extract_text()
                # éæ¿¾æ‰ NUL å­—ä¸²
                if page_text:
                    text += page_text.replace('\x00', '')
        return text


    # get_text_chunks
    def get_text_chunks(text):
        # ç¢ºä¿åœ¨åˆ†å‰²æ–‡æœ¬å¡Šå‰éæ¿¾æ‰ NUL å­—ä¸²
        cleaned_text = text.replace('\x00', '')
        text_splitter = RecursiveCharacterTextSplitter(
            separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""],
            chunk_size=512,
            chunk_overlap=103,
            length_function=len,
        )
        chunks = text_splitter.split_text(cleaned_text)
        return chunks
    ```

<br>

12. å†æ¬¡æäº¤ `PDF` æ–‡ä»¶å¾Œæ­£ç¢ºè®€å–ï¼Œåœ¨å´é‚Šæ¬„å¯è¼¸å…¥è¦æå•çš„å•é¡Œã€‚

    ![](images/img_04.png)

<br>

13. ä¸‹æ–¹æœƒé¡¯ç¤ºç­”æ¡ˆã€‚

    ![](images/img_05.png)

<br>

## å®Œæ•´è…³æœ¬

1. ç¨‹å¼ç¢¼ã€‚

    ```python
    import streamlit as st
    from PyPDF2 import PdfReader
    from langchain.vectorstores.pgvector import PGVector
    from langchain.memory import ConversationBufferMemory
    from langchain.chains import ConversationalRetrievalChain
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    from langchain.llms.bedrock import Bedrock
    from langchain.embeddings import BedrockEmbeddings
    from langchain.document_loaders import S3FileLoader
    from langchain.document_loaders.csv_loader import CSVLoader
    from langchain.document_loaders import YoutubeLoader
    from langchain.document_loaders import UnstructuredPowerPointLoader
    from langchain.document_loaders import Docx2txtLoader
    from langchain.memory import PostgresChatMessageHistory
    import boto3
    import tempfile
    import time
    import hashlib
    import secrets
    import os
    from dotenv import load_dotenv
    import logging

    # è¼‰å…¥ç’°å¢ƒè®Šæ•¸
    load_dotenv()
    # æ³¨æ„ï¼Œ`environ.get` æˆ– `os.getenv` å…©è€…åœ¨æœ¬è³ªä¸Šæ˜¯æœ‰å·®ç•°çš„
    # ä½†æˆ‘åå‘ç¨‹å¼ç¢¼æ•´æ½”ï¼Œæ‰€ä»¥åœ¨ç¨‹åºä¸€é–‹å§‹ä¹‹è™•å°±è¼‰å…¥ `load_dotenv()`
    # é€™æ¨£çš„è¼‰å…¥æ–¹å¼ä½¿ç”¨ `environ.get` æˆ– `os.getenv` ä¸¦ç„¡å·®ç•°
    PGVECTOR_DRIVER = os.getenv("PGVECTOR_DRIVER")
    PGVECTOR_USER = os.getenv("PGVECTOR_USER")
    PGVECTOR_PASSWORD = os.getenv("PGVECTOR_PASSWORD")
    PGVECTOR_HOST = os.getenv("PGVECTOR_HOST")
    PGVECTOR_PORT = os.getenv("PGVECTOR_PORT")
    PGVECTOR_DATABASE = os.getenv("PGVECTOR_DATABASE")
    #
    logging.getLogger("botocore").setLevel(logging.ERROR)


    # é€™å‡½æ•¸åƒ…ä½œç‚ºåœ¨æœ‰é€£ç·šéŒ¯èª¤æ™‚æª¢æ¸¬ä¹‹ç”¨ï¼Œæ‡‰ç”¨ä¸­ä¸¦ç„¡èª¿ç”¨
    def debug_01():
        # æª¢æŸ¥è³‡æ–™åº«çš„ URI æ˜¯å¦æ­£ç¢ºï¼›é€™è£¡å› ç‚ºå¤ªé•·ï¼Œæ‰€ä»¥é€²è¡Œæ‘ºè¡Œ
        CONNECTION_STRING = f"://{PGVECTOR_USER}:{PGVECTOR_PASSWORD}"
        f"@{PGVECTOR_HOST}:{PGVECTOR_PORT}/{PGVECTOR_DATABASE}"
        # ç¢ºä¿æ­£ç¢ºè¼¸å‡ºé€£æ¥å­—ä¸²ï¼Œä¾¿æ–¼æª¢æŸ¥
        print(f"CONNECTION_STRING: {CONNECTION_STRING}")


    # å®šç¾©æ‡‰ç”¨çš„æ¨™é¡Œï¼Œå‚³å…¥å­—ä¸²
    def styled_header(text):
        header_html = f"""
        <div style="background-color:#4CAF50;text-align:center;padding:10px">
        <h1 style="color:white;text-align:center;">{text}</h1>
        </div>
        """
        return header_html


    # å®šç¾©å­æ¨™é¡Œï¼šå‚³å…¥å­—ä¸²ï¼Œå…¶ä»–åƒæ•¸æœ‰é è¨­å€¼
    def styled_subheader(
        text,
        font_size="24px",
        color="#8A2BE2",
        background_color="#f0e5ff"
    ):
        subheader_html = f"""
        <div style="box-shadow:0 2px 10px #ddd; padding: 5px;"
        " background-color: {background_color};"
        " border-radius: 5px; margin: 10px 0; text-align: center;">
            <h3 style="color: {color}; font-size: {font_size};"
            " margin: 0;">{text}</h3>
        </div>
        """
        return subheader_html


    def generate_session_id():
        t = int(time.time() * 1000)
        r = secrets.randbelow(1000000)
        return hashlib.md5(
            bytes(str(t) + str(r), "utf-8"),
            usedforsecurity=False
        ).hexdigest()


    def get_pdf_text(pdf_docs):
        text = ""
        for pdf in pdf_docs:
            pdf_reader = PdfReader(pdf)
            for page in pdf_reader.pages:
                # text += page.extract_text()
                # æ”¹ç”¨ page_textï¼Œå¾Œé¢å†å‚³å›
                page_text = page.extract_text()
                # éæ¿¾æ‰ NUL å­—ä¸²
                if page_text:
                    text += page_text.replace('\x00', '')
        return text


    def get_text_chunks(text):
        # ç¢ºä¿åœ¨åˆ†å‰²æ–‡æœ¬å¡Šå‰éæ¿¾æ‰ NUL å­—ä¸²
        cleaned_text = text.replace('\x00', '')
        text_splitter = RecursiveCharacterTextSplitter(
            separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""],
            chunk_size=512,
            chunk_overlap=103,
            length_function=len,
        )
        # chunks = text_splitter.split_text(text)
        chunks = text_splitter.split_text(cleaned_text)
        return chunks


    def get_vectorstore(text_chunks):
        embeddings = BedrockEmbeddings(
            model_id="amazon.titan-embed-text-v2:0",
            # é è¨­æ˜¯ `-2`ï¼Œé€™è£¡æ”¹ä¸€ä¸‹
            region_name="us-east-1"
        )
        try:
            if text_chunks is None:
                return PGVector(
                    connection_string=CONNECTION_STRING,
                    embedding_function=embeddings,
                )
            return PGVector.from_texts(
                texts=text_chunks,
                embedding=embeddings,
                connection_string=CONNECTION_STRING
            )
        except Exception as e:
            # åŸæœ¬çš„è…³æœ¬æ˜¯å¼•ç™¼éŒ¯èª¤
            # raise e
            # æ”¹ç‚ºè¼¸å‡ºéŒ¯èª¤çœ‹ä¸€ä¸‹
            print(f'å–å¾—å‘é‡å„²å­˜ç™¼ç”ŸéŒ¯èª¤ï¼š{e}')


    def get_bedrock_llm(selected_llm):
        print(f"[INFO] Selected LLM is : {selected_llm}")
        if selected_llm in [
            "anthropic.claude-v2",
            "anthropic.claude-v1",
            "anthropic.claude-instant-v1",
        ]:
            llm = Bedrock(
                model_id=selected_llm,
                model_kwargs={"max_tokens_to_sample": 4096}
            )

        elif selected_llm in [
            "amazon.titan-tg1-large",
            "amazon.titan-text-express-v1",
            "amazon.titan-text-lite-v1",
        ]:
            llm = Bedrock(
                model_id=selected_llm,
                model_kwargs={
                    "maxTokenCount": 4096,
                    "stopSequences": [],
                    "temperature": 0,
                    "topP": 1,
                },
            )
        else:
            raise ValueError(f"Unsupported LLM: {selected_llm}")

        return llm


    def get_conversation_chain(vectorstore, selected_llm):
        # è¨»è§£æ‰
        # llm = Bedrock(
        #     model_id="anthropic.claude-instant-v1",
        #     region_name="us-west-2"
        # )
        llm = get_bedrock_llm(selected_llm)
        _connection_string = CONNECTION_STRING.replace(
            "+psycopg2", "").replace(":5432", "")
        message_history = PostgresChatMessageHistory(
            connection_string=_connection_string, session_id=generate_session_id()
        )
        memory = ConversationBufferMemory(
            memory_key="chat_history",
            chat_memory=message_history,
            return_source_documents=True,
            return_messages=True,
        )
        conversation_chain = ConversationalRetrievalChain.from_llm(
            llm=llm, retriever=vectorstore.as_retriever(), memory=memory
        )
        return conversation_chain


    def color_text(text, color="black"):
        return f'<span style="color:{color}">{text}</span>'


    bot_template = "ğŸ¤– BOT : {0}"
    user_template = "ğŸ‘¤ USER : {0}"


    def handle_userinput(user_question):
        bot_template = "ğŸ¤– BOT : {0}"
        user_template = "ğŸ‘¤ USER : {0}"
        try:
            response = st.session_state.conversation({"question": user_question})
            st.markdown(
                color_text(
                    user_template.format(response["question"]),
                    color="blue"
                ),
                unsafe_allow_html=True,
            )
            st.markdown(
                color_text(
                    bot_template.format(response["answer"]),
                    color="green"
                ),
                unsafe_allow_html=True,
            )
            print("Response", response)
        except ValueError as e:
            st.write(e)
            st.write("ğŸ˜ æŠ±æ­‰ï¼Œè«‹æ›å€‹æ–¹å¼å†å•ä¸€æ¬¡ã€‚")
            return
        st.session_state.chat_history = response["chat_history"]
        for i, message in enumerate(st.session_state.chat_history):
            if i % 2 == 0:
                st.markdown(
                    color_text(
                        user_template.format(message.content),
                        color="blue"
                    ),
                    unsafe_allow_html=True,
                )

            else:
                st.markdown(
                    color_text(
                        bot_template.format(message.content),
                        color="green"
                    ),
                    unsafe_allow_html=True,
                )


    def main():
        # æ›´æ–°æ¨™é¡Œæ¨£å¼
        st.markdown(
            styled_header(
                "AI å•ç­”ç³»çµ±ï¼šä½¿ç”¨ pgvector, Amazon Aurora"
                " & Amazon Bedrock ğŸ“šğŸ¦œ"
            ),
            # å…è¨±åœ¨ markdown å­—ä¸²ä¸­ä½¿ç”¨ HTML ä»£ç¢¼
            unsafe_allow_html=True
        )

        # ä¾†æºå½¢å¼åˆ—è¡¨
        options = [
            "ğŸ“„ PDFs",
            "â˜ï¸ S3 Bucket",
            "ğŸ“º Youtube",
            "ğŸ“‘ CSV", "ğŸ–¼ï¸ PPT",
            "ğŸ“ Word"
        ]
        # ä½¿ç”¨å–®é¸æŒ‰éˆ•è€Œä¸æ˜¯é¸æ“‡æ¡†
        st.markdown(
            styled_subheader("ğŸ“Œ é¸æ“‡ä¸€å€‹ä¾†æº ğŸ“Œ"),
            # å…è¨±åœ¨ markdown å­—ä¸²ä¸­ä½¿ç”¨ HTML ä»£ç¢¼
            unsafe_allow_html=True
        )

        # ç¶²é å…ƒä»¶ï¼Œé¸æ“‡ä¾†æº
        selected_source = st.radio("", options)

        # æ·»åŠ  LLM é¸å–®å…ƒä»¶
        st.markdown(
            styled_subheader("ğŸ¤– é¸æ“‡ä¸€å€‹æ¨¡å‹ ğŸ¤–"),
            unsafe_allow_html=True
        )

        # æ¨¡å‹åˆ—è¡¨
        llm_options = [
            "anthropic.claude-v2",
            "anthropic.claude-instant-v1",
            "amazon.titan-tg1-large",
            "amazon.titan-text-express-v1",
            "amazon.titan-text-lite-v1",
        ]

        # ç¶²é å…ƒä»¶ï¼Œé¸æ“‡æ¨¡å‹ï¼šé€™å€‹ radio ç‰¹åˆ¥åŠ ä¸Šåƒæ•¸ï¼Œåƒ…åƒ…æ˜¯ç”¨ä¾†å°æ¯”å‰ä¸€å€‹
        selected_llm = st.radio("Choose an LLM", options=llm_options)

        # PDF
        if selected_source == "ğŸ“„ PDFs":
            pdf_docs = st.file_uploader(
                "ğŸ“¥ é€™è£¡ä¸Šå‚³ PDF æ–‡ä»¶ï¼š",
                type="pdf",
                accept_multiple_files=True
            )
            if st.button("ğŸ”„ é€²è¡Œ"):
                with st.spinner("ğŸ”§ é€²è¡Œä¸­ ..."):
                    raw_text = get_pdf_text(pdf_docs)
                    text_chunks = get_text_chunks(raw_text)
                    vectorstore = get_vectorstore(text_chunks)
                    if vectorstore is None:
                        st.write("åˆå§‹åŒ–å‘é‡å„²å­˜å¤±æ•—ã€‚")
                        return
                    st.session_state.conversation = get_conversation_chain(
                        vectorstore, selected_llm
                    )
        elif selected_source == "â˜ï¸ S3 Bucket":
            s3_client = boto3.client("s3")
            # é€™äº›ç‰©ä»¶å„²å­˜åœ¨ aurora-genai-2023 å„²å­˜æ¡¶ä¸­
            # è¼¸å…¥é©ç•¶çš„å„²å­˜æ¡¶åç¨±
            response = s3_client.list_objects_v2(
                # å°‡å„²å­˜æ¡¶åç¨±è®Šæ›´ç‚ºè‡ªå·±çš„å„²å­˜æ¡¶åç¨±
                Bucket="aurora-genai-2023",
                Prefix="documentEmbeddings/"
            )
            document_keys = [
                obj["Key"].split("/")[1]
                for obj in response["Contents"]
            ][1:]
            user_input = st.selectbox(
                "Select an S3 document and click on 'Process'",
                document_keys
            )
            if st.button("Process"):
                with st.spinner("Processing"):
                    prefix = "documentEmbeddings/" + user_input
                    loader = S3FileLoader("aurora-genai-2023", prefix)
                    docs = loader.load()
                    for i in docs:
                        text_chunks = get_text_chunks(i.page_content)
                        vectorstore = get_vectorstore(text_chunks)
                        if vectorstore is None:
                            st.write("Failed to initialize vector store.")
                            return
                    st.session_state.conversation = get_conversation_chain(
                        vectorstore, selected_llm
                    )
        elif selected_source == "ğŸ“‘ CSV":
            csv_docs = st.file_uploader(
                "Upload your CSV here and click on 'Process'",
                type="csv",
                accept_multiple_files=False,
            )
            if st.button("Process"):
                with st.spinner("Processing"):
                    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
                        tmp_file.write(csv_docs.getvalue())
                        tmp_file_path = tmp_file.name
                    loader = CSVLoader(
                        file_path=tmp_file_path,
                        encoding="utf-8",
                        csv_args={"delimiter": ","},
                    )
                    docs = loader.load()
                    for i in docs:
                        text_chunks = get_text_chunks(i.page_content)
                        vectorstore = get_vectorstore(text_chunks)
                        if vectorstore is None:
                            st.write("Failed to initialize vector store.")
                            return
                    st.session_state.conversation = get_conversation_chain(
                        vectorstore, selected_llm
                    )
        elif selected_source == "ğŸ“º Youtube":
            user_input = st.text_input("è¼¸å…¥ YouTube é€£çµä¸¦é»æ“Šã€ŒProcessã€")
            if st.button("Process"):
                with st.spinner("Processing"):
                    loader = YoutubeLoader.from_youtube_url(user_input)
                    transcript = loader.load()
                    for i in transcript:
                        text_chunks = get_text_chunks(i.page_content)
                        vectorstore = get_vectorstore(text_chunks)
                        if vectorstore is None:
                            st.write("ç„¡æ³•åˆå§‹åŒ–å‘é‡å„²å­˜ã€‚")
                            return
                    st.session_state.conversation = get_conversation_chain(
                        vectorstore, selected_llm
                    )

        elif selected_source == "ğŸ–¼ï¸ PPT":
            ppt_docs = st.file_uploader(
                "åœ¨æ­¤ä¸Šå‚³æ‚¨çš„ PPTï¼Œç„¶å¾ŒæŒ‰ä¸€ä¸‹ã€ŒProcessã€",
                type=["ppt", "pptx"],
                accept_multiple_files=False,
            )
            if st.button("Process"):
                with st.spinner("Processing"):
                    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
                        tmp_file.write(ppt_docs.getvalue())
                        tmp_file_path = tmp_file.name
                    loader = UnstructuredPowerPointLoader(tmp_file_path)
                    docs = loader.load()
                    for i in docs:
                        text_chunks = get_text_chunks(i.page_content)
                        vectorstore = get_vectorstore(text_chunks)
                        if vectorstore is None:
                            st.write("ç„¡æ³•åˆå§‹åŒ–å‘é‡å„²å­˜ã€‚")
                            return
                    st.session_state.conversation = get_conversation_chain(
                        vectorstore, selected_llm
                    )

        elif selected_source == "ğŸ“ Word":
            word_docs = st.file_uploader(
                "åœ¨æ­¤è™•ä¸Šå‚³æ‚¨çš„ Word æ–‡ä»¶ï¼Œç„¶å¾ŒæŒ‰ä¸€ä¸‹ã€ŒProcessã€",
                type=["docx"],
                accept_multiple_files=False,
            )
            if st.button("Process"):
                with st.spinner("Processing"):
                    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
                        tmp_file.write(word_docs.getvalue())
                        tmp_file_path = tmp_file.name
                    loader = Docx2txtLoader(tmp_file_path)
                    docs = loader.load()
                    for i in docs:
                        text_chunks = get_text_chunks(i.page_content)
                        vectorstore = get_vectorstore(text_chunks)
                        if vectorstore is None:
                            st.write("ç„¡æ³•åˆå§‹åŒ–å‘é‡å„²å­˜ã€‚")
                            return
                    st.session_state.conversation = get_conversation_chain(
                        vectorstore, selected_llm
                    )

        st.sidebar.header("ğŸ—£ï¸ èˆ‡æ©Ÿå™¨äººèŠå¤©")
        user_question = st.sidebar.text_input("ğŸ’¬ è©¢å•æœ‰é—œä½ æ‰€æä¾›æ•¸æ“šçš„å•é¡Œï¼š")
        if user_question:
            handle_userinput(user_question)

        if "conversation" not in st.session_state:
            st.session_state.conversation = get_conversation_chain(
                get_vectorstore(None), selected_llm
            )
        if "chat_history" not in st.session_state:
            st.session_state.chat_history = None


    # è¼¸å…¥è³‡æ–™åº«åç¨±
    if __name__ == "__main__":
        # è‹¥åœ¨ `__main__` ä¸­è¼‰å…¥å‰‡å¿…é ˆä½¿ç”¨ `environ.get` ä¾†è®€å–ä¸¦å¯«å…¥ç’°å¢ƒåƒæ•¸
        # load_dotenv()

        CONNECTION_STRING = PGVector.connection_string_from_db_params(
            driver=PGVECTOR_DRIVER,
            user=PGVECTOR_USER,
            password=PGVECTOR_PASSWORD,
            host=PGVECTOR_HOST,
            port=PGVECTOR_PORT,
            database=PGVECTOR_DATABASE,
        )

        main()

    ```

<br>

___

_END_